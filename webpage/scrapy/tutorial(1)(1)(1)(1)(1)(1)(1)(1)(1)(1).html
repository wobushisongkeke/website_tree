<!DOCTYPE html><!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]--><!--[if gt IE 8]><!--><html xmlns="http://www.w3.org/1999/xhtml" class=" js flexbox canvas canvastext webgl no-touch geolocation postmessage websqldatabase indexeddb hashchange history draganddrop websockets rgba hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients cssreflections csstransforms csstransforms3d csstransitions fontface generatedcontent video audio localstorage sessionstorage webworkers applicationcache svg inlinesvg smil svgclippaths" lang="en" style=""><!--<![endif]--><head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Scrapy Tutorial — Scrapy 0.20.2 documentation</title>
  

  
  

  
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic|Roboto+Slab:400,700|Inconsolata:400,700" rel="stylesheet" type="text/css" />

  
  
    

  

  
  

  
    <link rel="stylesheet" href="https://media.readthedocs.org/css/sphinx_rtd_theme.css" type="text/css" />
  
    <link rel="stylesheet" href="https://media.readthedocs.org/css/readthedocs-doc-embed.css" type="text/css" />
  
    <link rel="top" title="Scrapy 0.20.2 documentation" href="../index.html" />
        <link rel="next" title="Examples" href="examples.html" />
        <link rel="prev" title="Installation guide" href="install.html" />
 
<!-- RTD Extra Head -->



  
  <!-- 
  Always link to the latest version, as canonical.
  http://docs.readthedocs.org/en/latest/canonical.html
  -->
  <link rel="canonical" href="http://doc.scrapy.org/en/latest/intro/tutorial.html" />
  

<script type="text/javascript" async="" src="https://ssl.google-analytics.com/ga.js"></script><script type="text/javascript">
  // This is included here because other places don't have access to the pagename variable.
  var READTHEDOCS_DATA = {
    project: "scrapy",
    version: "0.20",
    language: "en",
    page: "intro/tutorial",
    theme: "sphinx_rtd_theme",
    docroot: "/docs/",
    source_suffix: ".rst",
    api_host: "https://readthedocs.org",
    commit: "a19c880a17f606d999e836567d9f0e7286e136c6"
  }
  // Old variables
  var doc_version = "0.20";
  var doc_slug = "scrapy";
  var page_name = "intro/tutorial";
  var html_theme = "sphinx_rtd_theme";
</script>
<!-- RTD Analytics Code -->
<!-- Included in the header because you don't have a footer block. -->
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-17997319-1']);
  _gaq.push(['_trackPageview']);

  // User Analytics Code
  _gaq.push(['user._setAccount', 'UA-10231918-2']);
  _gaq.push(['user._trackPageview']);
  // End User Analytics Code


  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<!-- end RTD Analytics Code -->
<!-- end RTD <extrahead> -->


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document" style="">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side"><div class="wy-side-scroll"><div class="wy-side-nav-search">
        
          <a href="../index.html" class="fa fa-home"> Scrapy</a>
        
        <div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
      </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
        
            <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html"><span class="toctree-expand"></span>Scrapy at a glance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="overview.html#pick-a-website">Pick a website</a></li>
<li class="toctree-l2"><a class="reference internal" href="overview.html#define-the-data-you-want-to-scrape">Define the data you want to scrape</a></li>
<li class="toctree-l2"><a class="reference internal" href="overview.html#write-a-spider-to-extract-the-data">Write a Spider to extract the data</a></li>
<li class="toctree-l2"><a class="reference internal" href="overview.html#run-the-spider-to-extract-the-data">Run the spider to extract the data</a></li>
<li class="toctree-l2"><a class="reference internal" href="overview.html#review-scraped-data">Review scraped data</a></li>
<li class="toctree-l2"><a class="reference internal" href="overview.html#what-else">What else?</a></li>
<li class="toctree-l2"><a class="reference internal" href="overview.html#what-s-next">What’s next?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="install.html"><span class="toctree-expand"></span>Installation guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="install.html#pre-requisites">Pre-requisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="install.html#installing-scrapy">Installing Scrapy</a></li>
<li class="toctree-l2"><a class="reference internal" href="install.html#platform-specific-installation-notes">Platform specific installation notes</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href=""><span class="toctree-expand"></span>Scrapy Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#creating-a-project">Creating a project</a></li>
<li class="toctree-l2"><a class="reference internal" href="#defining-our-item">Defining our Item</a></li>
<li class="toctree-l2"><a class="reference internal" href="#our-first-spider">Our first Spider</a></li>
<li class="toctree-l2"><a class="reference internal" href="#storing-the-scraped-data">Storing the scraped data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#next-steps">Next steps</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/commands.html"><span class="toctree-expand"></span>Command line tool</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/commands.html#default-structure-of-scrapy-projects">Default structure of Scrapy projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/commands.html#using-the-scrapy-tool">Using the <tt class="docutils literal"><span class="pre">scrapy</span></tt> tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/commands.html#available-tool-commands">Available tool commands</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/commands.html#custom-project-commands">Custom project commands</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/items.html"><span class="toctree-expand"></span>Items</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/items.html#declaring-items">Declaring Items</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/items.html#item-fields">Item Fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/items.html#working-with-items">Working with Items</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/items.html#extending-items">Extending Items</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/items.html#item-objects">Item objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/items.html#field-objects">Field objects</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/spiders.html"><span class="toctree-expand"></span>Spiders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/spiders.html#spider-arguments">Spider arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/spiders.html#built-in-spiders-reference">Built-in spiders reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/link-extractors.html"><span class="toctree-expand"></span>Link Extractors</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/link-extractors.html#module-scrapy.contrib.linkextractors">Built-in link extractors reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/selectors.html"><span class="toctree-expand"></span>Selectors</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/selectors.html#using-selectors">Using selectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/selectors.html#module-scrapy.selector">Built-in Selectors reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/loaders.html"><span class="toctree-expand"></span>Item Loaders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/loaders.html#using-item-loaders-to-populate-items">Using Item Loaders to populate items</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/loaders.html#input-and-output-processors">Input and Output processors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/loaders.html#declaring-item-loaders">Declaring Item Loaders</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/loaders.html#declaring-input-and-output-processors">Declaring Input and Output Processors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/loaders.html#item-loader-context">Item Loader Context</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/loaders.html#itemloader-objects">ItemLoader objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/loaders.html#reusing-and-extending-item-loaders">Reusing and extending Item Loaders</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/loaders.html#module-scrapy.contrib.loader.processor">Available built-in processors</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/shell.html"><span class="toctree-expand"></span>Scrapy shell</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/shell.html#launch-the-shell">Launch the shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/shell.html#using-the-shell">Using the shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/shell.html#example-of-shell-session">Example of shell session</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/shell.html#invoking-the-shell-from-spiders-to-inspect-responses">Invoking the shell from spiders to inspect responses</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/item-pipeline.html"><span class="toctree-expand"></span>Item Pipeline</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/item-pipeline.html#writing-your-own-item-pipeline">Writing your own item pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/item-pipeline.html#item-pipeline-example">Item pipeline example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/item-pipeline.html#activating-an-item-pipeline-component">Activating an Item Pipeline component</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/feed-exports.html"><span class="toctree-expand"></span>Feed exports</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/feed-exports.html#serialization-formats">Serialization formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/feed-exports.html#storages">Storages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/feed-exports.html#storage-uri-parameters">Storage URI parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/feed-exports.html#storage-backends">Storage backends</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/feed-exports.html#settings">Settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/link-extractors.html"><span class="toctree-expand"></span>Link Extractors</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/link-extractors.html#module-scrapy.contrib.linkextractors">Built-in link extractors reference</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/logging.html"><span class="toctree-expand"></span>Logging</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/logging.html#log-levels">Log levels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/logging.html#how-to-set-the-log-level">How to set the log level</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/logging.html#how-to-log-messages">How to log messages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/logging.html#logging-from-spiders">Logging from Spiders</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/logging.html#module-scrapy.log">scrapy.log module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/logging.html#logging-settings">Logging settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/stats.html"><span class="toctree-expand"></span>Stats Collection</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/stats.html#common-stats-collector-uses">Common Stats Collector uses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/stats.html#available-stats-collectors">Available Stats Collectors</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/email.html"><span class="toctree-expand"></span>Sending e-mail</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/email.html#quick-example">Quick example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/email.html#mailsender-class-reference">MailSender class reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/email.html#mail-settings">Mail settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/telnetconsole.html"><span class="toctree-expand"></span>Telnet Console</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/telnetconsole.html#how-to-access-the-telnet-console">How to access the telnet console</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/telnetconsole.html#available-variables-in-the-telnet-console">Available variables in the telnet console</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/telnetconsole.html#telnet-console-usage-examples">Telnet console usage examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/telnetconsole.html#telnet-console-signals">Telnet Console signals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/telnetconsole.html#telnet-settings">Telnet settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/webservice.html"><span class="toctree-expand"></span>Web Service</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/webservice.html#web-service-resources">Web service resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/webservice.html#web-service-settings">Web service settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/webservice.html#writing-a-web-service-resource">Writing a web service resource</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/webservice.html#examples-of-web-service-resources">Examples of web service resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/webservice.html#example-of-web-service-client">Example of web service client</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html"><span class="toctree-expand"></span>Frequently Asked Questions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-does-scrapy-compare-to-beautifulsoup-or-lxml">How does Scrapy compare to BeautifulSoup or lxml?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-python-versions-does-scrapy-support">What Python versions does Scrapy support?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#does-scrapy-work-with-python-3">Does Scrapy work with Python 3?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#did-scrapy-steal-x-from-django">Did Scrapy “steal” X from Django?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#does-scrapy-work-with-http-proxies">Does Scrapy work with HTTP proxies?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-can-i-scrape-an-item-with-attributes-in-different-pages">How can I scrape an item with attributes in different pages?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapy-crashes-with-importerror-no-module-named-win32api">Scrapy crashes with: ImportError: No module named win32api</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-can-i-simulate-a-user-login-in-my-spider">How can I simulate a user login in my spider?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#does-scrapy-crawl-in-breadth-first-or-depth-first-order">Does Scrapy crawl in breadth-first or depth-first order?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#my-scrapy-crawler-has-memory-leaks-what-can-i-do">My Scrapy crawler has memory leaks. What can I do?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-can-i-make-scrapy-consume-less-memory">How can I make Scrapy consume less memory?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#can-i-use-basic-http-authentication-in-my-spiders">Can I use Basic HTTP Authentication in my spiders?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#why-does-scrapy-download-pages-in-english-instead-of-my-native-language">Why does Scrapy download pages in English instead of my native language?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#where-can-i-find-some-example-scrapy-projects">Where can I find some example Scrapy projects?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#can-i-run-a-spider-without-creating-a-project">Can I run a spider without creating a project?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-get-filtered-offsite-request-messages-how-can-i-fix-them">I get “Filtered offsite request” messages. How can I fix them?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-is-the-recommended-way-to-deploy-a-scrapy-crawler-in-production">What is the recommended way to deploy a Scrapy crawler in production?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#can-i-use-json-for-large-exports">Can I use JSON for large exports?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#can-i-return-twisted-deferreds-from-signal-handlers">Can I return (Twisted) deferreds from signal handlers?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-does-the-response-status-code-999-means">What does the response status code 999 means?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#can-i-call-pdb-set-trace-from-my-spiders-to-debug-them">Can I call <tt class="docutils literal"><span class="pre">pdb.set_trace()</span></tt> from my spiders to debug them?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#simplest-way-to-dump-all-my-scraped-items-into-a-json-csv-xml-file">Simplest way to dump all my scraped items into a JSON/CSV/XML file?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-s-this-huge-cryptic-viewstate-parameter-used-in-some-forms">What’s this huge cryptic <tt class="docutils literal"><span class="pre">__VIEWSTATE</span></tt> parameter used in some forms?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-s-the-best-way-to-parse-big-xml-csv-data-feeds">What’s the best way to parse big XML/CSV data feeds?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#does-scrapy-manage-cookies-automatically">Does Scrapy manage cookies automatically?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-can-i-see-the-cookies-being-sent-and-received-from-scrapy">How can I see the cookies being sent and received from Scrapy?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-can-i-instruct-a-spider-to-stop-itself">How can I instruct a spider to stop itself?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-can-i-prevent-my-scrapy-bot-from-getting-banned">How can I prevent my Scrapy bot from getting banned?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#should-i-use-spider-arguments-or-settings-to-configure-my-spider">Should I use spider arguments or settings to configure my spider?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-m-scraping-a-xml-document-and-my-xpath-selector-doesn-t-return-any-items">I’m scraping a XML document and my XPath selector doesn’t return any items</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-m-getting-an-error-cannot-import-name-crawler">I’m getting an error: “cannot import name crawler”</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/debug.html"><span class="toctree-expand"></span>Debugging Spiders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/debug.html#parse-command">Parse Command</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/debug.html#scrapy-shell">Scrapy Shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/debug.html#open-in-browser">Open in browser</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/debug.html#logging">Logging</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/contracts.html"><span class="toctree-expand"></span>Spiders Contracts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/contracts.html#custom-contracts">Custom Contracts</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/practices.html"><span class="toctree-expand"></span>Common Practices</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/practices.html#run-scrapy-from-a-script">Run Scrapy from a script</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/practices.html#running-multiple-spiders-in-the-same-process">Running multiple spiders in the same process</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/practices.html#distributed-crawls">Distributed crawls</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/practices.html#avoiding-getting-banned">Avoiding getting banned</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/practices.html#dynamic-creation-of-item-classes">Dynamic Creation of Item Classes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/broad-crawls.html"><span class="toctree-expand"></span>Broad Crawls</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/broad-crawls.html#increase-concurrency">Increase concurrency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/broad-crawls.html#reduce-log-level">Reduce log level</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/broad-crawls.html#disable-cookies">Disable cookies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/broad-crawls.html#disable-retries">Disable retries</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/broad-crawls.html#reduce-download-timeout">Reduce download timeout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/broad-crawls.html#disable-redirects">Disable redirects</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/firefox.html"><span class="toctree-expand"></span>Using Firefox for scraping</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/firefox.html#caveats-with-inspecting-the-live-browser-dom">Caveats with inspecting the live browser DOM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/firefox.html#useful-firefox-add-ons-for-scraping">Useful Firefox add-ons for scraping</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/firebug.html"><span class="toctree-expand"></span>Using Firebug for scraping</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/firebug.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/firebug.html#getting-links-to-follow">Getting links to follow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/firebug.html#extracting-the-data">Extracting the data</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/leaks.html"><span class="toctree-expand"></span>Debugging memory leaks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/leaks.html#common-causes-of-memory-leaks">Common causes of memory leaks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/leaks.html#debugging-memory-leaks-with-trackref">Debugging memory leaks with <tt class="docutils literal"><span class="pre">trackref</span></tt></a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/leaks.html#debugging-memory-leaks-with-guppy">Debugging memory leaks with Guppy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/leaks.html#leaks-without-leaks">Leaks without leaks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/images.html"><span class="toctree-expand"></span>Downloading Item Images</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/images.html#using-the-images-pipeline">Using the Images Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/images.html#usage-example">Usage example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/images.html#enabling-your-images-pipeline">Enabling your Images Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/images.html#images-storage">Images Storage</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/images.html#additional-features">Additional features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/images.html#module-scrapy.contrib.pipeline.images">Implementing your custom Images Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/images.html#custom-images-pipeline-example">Custom Images pipeline example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/ubuntu.html">Ubuntu packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/scrapyd.html">Scrapyd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/autothrottle.html"><span class="toctree-expand"></span>AutoThrottle extension</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/autothrottle.html#design-goals">Design goals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/autothrottle.html#how-it-works">How it works</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/autothrottle.html#throttling-algorithm">Throttling algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/autothrottle.html#settings">Settings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/jobs.html"><span class="toctree-expand"></span>Jobs: pausing and resuming crawls</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/jobs.html#job-directory">Job directory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/jobs.html#how-to-use-it">How to use it</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/jobs.html#keeping-persistent-state-between-batches">Keeping persistent state between batches</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/jobs.html#persistence-gotchas">Persistence gotchas</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/djangoitem.html"><span class="toctree-expand"></span>DjangoItem</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/djangoitem.html#using-djangoitem">Using DjangoItem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/djangoitem.html#djangoitem-caveats">DjangoItem caveats</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/djangoitem.html#django-settings-set-up">Django settings set up</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/architecture.html"><span class="toctree-expand"></span>Architecture overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/architecture.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/architecture.html#components">Components</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/architecture.html#data-flow">Data flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/architecture.html#event-driven-networking">Event-driven networking</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/downloader-middleware.html"><span class="toctree-expand"></span>Downloader Middleware</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/downloader-middleware.html#activating-a-downloader-middleware">Activating a downloader middleware</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/downloader-middleware.html#writing-your-own-downloader-middleware">Writing your own downloader middleware</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/downloader-middleware.html#built-in-downloader-middleware-reference">Built-in downloader middleware reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/spider-middleware.html"><span class="toctree-expand"></span>Spider Middleware</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/spider-middleware.html#activating-a-spider-middleware">Activating a spider middleware</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/spider-middleware.html#writing-your-own-spider-middleware">Writing your own spider middleware</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/spider-middleware.html#built-in-spider-middleware-reference">Built-in spider middleware reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/extensions.html"><span class="toctree-expand"></span>Extensions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/extensions.html#extension-settings">Extension settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/extensions.html#loading-activating-extensions">Loading &amp; activating extensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/extensions.html#available-enabled-and-disabled-extensions">Available, enabled and disabled extensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/extensions.html#disabling-an-extension">Disabling an extension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/extensions.html#writing-your-own-extension">Writing your own extension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/extensions.html#built-in-extensions-reference">Built-in extensions reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/api.html"><span class="toctree-expand"></span>Core API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/api.html#crawler-api">Crawler API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/api.html#module-scrapy.settings">Settings API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/api.html#module-scrapy.signalmanager">Signals API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/api.html#stats-collector-api">Stats Collector API</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/request-response.html"><span class="toctree-expand"></span>Requests and Responses</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/request-response.html#request-objects">Request objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/request-response.html#request-meta-special-keys">Request.meta special keys</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/request-response.html#request-subclasses">Request subclasses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/request-response.html#response-objects">Response objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/request-response.html#response-subclasses">Response subclasses</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/settings.html"><span class="toctree-expand"></span>Settings</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/settings.html#designating-the-settings">Designating the settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/settings.html#populating-the-settings">Populating the settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/settings.html#how-to-access-settings">How to access settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/settings.html#rationale-for-setting-names">Rationale for setting names</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/settings.html#built-in-settings-reference">Built-in settings reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/signals.html"><span class="toctree-expand"></span>Signals</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/signals.html#deferred-signal-handlers">Deferred signal handlers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/signals.html#module-scrapy.signals">Built-in signals reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/exceptions.html"><span class="toctree-expand"></span>Exceptions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/exceptions.html#built-in-exceptions-reference">Built-in Exceptions reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../topics/exporters.html"><span class="toctree-expand"></span>Item Exporters</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../topics/exporters.html#using-item-exporters">Using Item Exporters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/exporters.html#serialization-of-item-fields">Serialization of item fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="../topics/exporters.html#built-in-item-exporters-reference">Built-in Item Exporters reference</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html"><span class="toctree-expand"></span>Release notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-12-09">0.20.2 (released 2013-12-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-11-28">0.20.1 (released 2013-11-28)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-11-08">0.20.0 (released 2013-11-08)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-10-10">0.18.4 (released 2013-10-10)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-10-03">0.18.3 (released 2013-10-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-09-03">0.18.2 (released 2013-09-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-08-27">0.18.1 (released 2013-08-27)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-08-09">0.18.0 (released 2013-08-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-05-30">0.16.5 (released 2013-05-30)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-01-23">0.16.4 (released 2013-01-23)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-12-07">0.16.3 (released 2012-12-07)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-11-09">0.16.2 (released 2012-11-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-10-26">0.16.1 (released 2012-10-26)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-10-18">0.16.0 (released 2012-10-18)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id1">0.14.4</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id2">0.14.3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id3">0.14.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id4">0.14.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id5">0.14</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id6">0.12</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id7">0.10</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id10">0.9</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id13">0.8</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id14">0.7</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html"><span class="toctree-expand"></span>Contributing to Scrapy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#reporting-bugs">Reporting bugs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#writing-patches">Writing patches</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#submitting-patches">Submitting patches</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#coding-style">Coding style</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#scrapy-contrib">Scrapy Contrib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#documentation-policies">Documentation policies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#tests">Tests</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html"><span class="toctree-expand"></span>Versioning and API Stability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../versioning.html#id1">Versioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../versioning.html#api-stability">API Stability</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../experimental/index.html"><span class="toctree-expand"></span>Experimental features</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../experimental/index.html#add-commands-using-external-libraries">Add commands using external libraries</a></li>
</ul>
</li>
</ul>

        
      </div><div id="rtd-dqlcwib3" class="ethical-rtd ethical-dark-theme"><div class="ethical-sidebar"><div class="ethical-content"><a href="https://readthedocs.org/sustainability/click/305/VdcaDv7jrV6S/" rel="nofollow" target="_blank" class="ethical-image-link"><img src="https://assets.readthedocs.org/sustainability/readthedocs-logo-fs8.png" /></a><div class="ethical-text"><a href="https://readthedocs.org/sustainability/click/305/VdcaDv7jrV6S/" rel="nofollow" target="_blank">Private repos and priority support<br />Try Read the Docs for Business Today!</a></div></div><div class="ethical-callout"><small><em><a href="https://readthedocs.org/sustainability/advertising/">Sponsored</a><span> · </span><a href="https://docs.readthedocs.io/en/latest/ethical-advertising.html">Ads served ethically</a></em></small></div></div></div></div>
      

      
       
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">Scrapy</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> »</li>
      
    <li>Scrapy Tutorial</li>
      <li class="wy-breadcrumbs-aside">
        
          <a href="https://github.com/scrapy/scrapy/blob/0.20/docs/intro/tutorial.rst" class="fa fa-github"> Edit on GitHub</a>
        
      </li>
  </ul>
  <hr />
</div>
          <div role="main" class="document"><div class="admonition warning"> <p class="first admonition-title">Note</p> <p class="last"> You are not reading the most recent version of this documentation. <a href="/en/1.6/intro/tutorial.html">1.6</a> is the latest version available.</p></div>
            
  <div class="section" id="scrapy-tutorial">
<span id="intro-tutorial"></span><h1>Scrapy Tutorial<a class="headerlink" href="#scrapy-tutorial" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, we’ll assume that Scrapy is already installed on your system.
If that’s not the case, see <a class="reference internal" href="install.html#intro-install"><em>Installation guide</em></a>.</p>
<p>We are going to use <a class="reference external" href="http://www.dmoz.org/">Open directory project (dmoz)</a> as
our example domain to scrape.</p>
<p>This tutorial will walk you through these tasks:</p>
<ol class="arabic simple">
<li>Creating a new Scrapy project</li>
<li>Defining the Items you will extract</li>
<li>Writing a <a class="reference internal" href="../topics/spiders.html#topics-spiders"><em>spider</em></a> to crawl a site and extract
<a class="reference internal" href="../topics/items.html#topics-items"><em>Items</em></a></li>
<li>Writing an <a class="reference internal" href="../topics/item-pipeline.html#topics-item-pipeline"><em>Item Pipeline</em></a> to store the
extracted Items</li>
</ol>
<p>Scrapy is written in <a class="reference external" href="http://www.python.org">Python</a>. If you’re new to the language you might want to
start by getting an idea of what the language is like, to get the most out of
Scrapy.  If you’re already familiar with other languages, and want to learn
Python quickly, we recommend <a class="reference external" href="http://learnpythonthehardway.org/book/">Learn Python The Hard Way</a>.  If you’re new to programming
and want to start with Python, take a look at <a class="reference external" href="http://wiki.python.org/moin/BeginnersGuide/NonProgrammers">this list of Python resources
for non-programmers</a>.</p>
<div class="section" id="creating-a-project">
<h2>Creating a project<a class="headerlink" href="#creating-a-project" title="Permalink to this headline">¶</a></h2>
<p>Before you start scraping, you will have set up a new Scrapy project. Enter a
directory where you’d like to store your code and then run:</p>
<div class="highlight-python"><div class="highlight"><pre>scrapy startproject tutorial
</pre></div>
</div>
<p>This will create a <tt class="docutils literal"><span class="pre">tutorial</span></tt> directory with the following contents:</p>
<div class="highlight-python"><div class="highlight"><pre>tutorial/
    scrapy.cfg
    tutorial/
        __init__.py
        items.py
        pipelines.py
        settings.py
        spiders/
            __init__.py
            ...
</pre></div>
</div>
<p>These are basically:</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">scrapy.cfg</span></tt>: the project configuration file</li>
<li><tt class="docutils literal"><span class="pre">tutorial/</span></tt>: the project’s python module, you’ll later import your code from
here.</li>
<li><tt class="docutils literal"><span class="pre">tutorial/items.py</span></tt>: the project’s items file.</li>
<li><tt class="docutils literal"><span class="pre">tutorial/pipelines.py</span></tt>: the project’s pipelines file.</li>
<li><tt class="docutils literal"><span class="pre">tutorial/settings.py</span></tt>: the project’s settings file.</li>
<li><tt class="docutils literal"><span class="pre">tutorial/spiders/</span></tt>: a directory where you’ll later put your spiders.</li>
</ul>
</div>
<div class="section" id="defining-our-item">
<h2>Defining our Item<a class="headerlink" href="#defining-our-item" title="Permalink to this headline">¶</a></h2>
<p><cite>Items</cite> are containers that will be loaded with the scraped data; they work
like simple python dicts but provide additional protecting against populating
undeclared fields, to prevent typos.</p>
<p>They are declared by creating an <a class="reference internal" href="../topics/items.html#scrapy.item.Item" title="scrapy.item.Item"><tt class="xref py py-class docutils literal"><span class="pre">scrapy.item.Item</span></tt></a> class and defining
its attributes as <a class="reference internal" href="../topics/items.html#scrapy.item.Field" title="scrapy.item.Field"><tt class="xref py py-class docutils literal"><span class="pre">scrapy.item.Field</span></tt></a> objects, like you will in an ORM
(don’t worry if you’re not familiar with ORMs, you will see that this is an
easy task).</p>
<p>We begin by modeling the item that we will use to hold the sites data obtained
from dmoz.org, as we want to capture the name, url and description of the
sites, we define fields for each of these three attributes. To do that, we edit
items.py, found in the <tt class="docutils literal"><span class="pre">tutorial</span></tt> directory. Our Item class looks like this:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.item</span> <span class="kn">import</span> <span class="n">Item</span><span class="p">,</span> <span class="n">Field</span>

<span class="k">class</span> <span class="nc">DmozItem</span><span class="p">(</span><span class="n">Item</span><span class="p">):</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">link</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">desc</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
</pre></div>
</div>
<p>This may seem complicated at first, but defining the item allows you to use other handy
components of Scrapy that need to know how your item looks like.</p>
</div>
<div class="section" id="our-first-spider">
<h2>Our first Spider<a class="headerlink" href="#our-first-spider" title="Permalink to this headline">¶</a></h2>
<p>Spiders are user-written classes used to scrape information from a domain (or group
of domains).</p>
<p>They define an initial list of URLs to download, how to follow links, and how
to parse the contents of those pages to extract <a class="reference internal" href="../topics/items.html#topics-items"><em>items</em></a>.</p>
<p>To create a Spider, you must subclass <a class="reference internal" href="../topics/spiders.html#scrapy.spider.BaseSpider" title="scrapy.spider.BaseSpider"><tt class="xref py py-class docutils literal"><span class="pre">scrapy.spider.BaseSpider</span></tt></a>, and
define the three main, mandatory, attributes:</p>
<ul>
<li><p class="first"><a class="reference internal" href="../topics/spiders.html#scrapy.spider.BaseSpider.name" title="scrapy.spider.BaseSpider.name"><tt class="xref py py-attr docutils literal"><span class="pre">name</span></tt></a>: identifies the Spider. It must be
unique, that is, you can’t set the same name for different Spiders.</p>
</li>
<li><p class="first"><a class="reference internal" href="../topics/spiders.html#scrapy.spider.BaseSpider.start_urls" title="scrapy.spider.BaseSpider.start_urls"><tt class="xref py py-attr docutils literal"><span class="pre">start_urls</span></tt></a>: is a list of URLs where the
Spider will begin to crawl from.  So, the first pages downloaded will be those
listed here. The subsequent URLs will be generated successively from data
contained in the start URLs.</p>
</li>
<li><p class="first"><a class="reference internal" href="../topics/spiders.html#scrapy.spider.BaseSpider.parse" title="scrapy.spider.BaseSpider.parse"><tt class="xref py py-meth docutils literal"><span class="pre">parse()</span></tt></a> is a method of the spider, which will
be called with the downloaded <a class="reference internal" href="../topics/request-response.html#scrapy.http.Response" title="scrapy.http.Response"><tt class="xref py py-class docutils literal"><span class="pre">Response</span></tt></a> object of each
start URL. The response is passed to the method as the first and only
argument.</p>
<p>This method is responsible for parsing the response data and extracting
scraped data (as scraped items) and more URLs to follow.</p>
<p>The <a class="reference internal" href="../topics/spiders.html#scrapy.spider.BaseSpider.parse" title="scrapy.spider.BaseSpider.parse"><tt class="xref py py-meth docutils literal"><span class="pre">parse()</span></tt></a> method is in charge of processing
the response and returning scraped data (as <a class="reference internal" href="../topics/items.html#scrapy.item.Item" title="scrapy.item.Item"><tt class="xref py py-class docutils literal"><span class="pre">Item</span></tt></a>
objects) and more URLs to follow (as <a class="reference internal" href="../topics/request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> objects).</p>
</li>
</ul>
<p>This is the code for our first Spider; save it in a file named
<tt class="docutils literal"><span class="pre">dmoz_spider.py</span></tt> under the <tt class="docutils literal"><span class="pre">tutorial/spiders</span></tt> directory:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.spider</span> <span class="kn">import</span> <span class="n">BaseSpider</span>

<span class="k">class</span> <span class="nc">DmozSpider</span><span class="p">(</span><span class="n">BaseSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">"dmoz"</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">"dmoz.org"</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/"</span><span class="p">,</span>
        <span class="s">"http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/"</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">"/"</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">body</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="crawling">
<h3>Crawling<a class="headerlink" href="#crawling" title="Permalink to this headline">¶</a></h3>
<p>To put our spider to work, go to the project’s top level directory and run:</p>
<div class="highlight-python"><div class="highlight"><pre>scrapy crawl dmoz
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">crawl</span> <span class="pre">dmoz</span></tt> command runs the spider for the <tt class="docutils literal"><span class="pre">dmoz.org</span></tt> domain. You
will get an output similar to this:</p>
<div class="highlight-python"><div class="highlight"><pre>2008-08-20 03:51:13-0300 [scrapy] INFO: Started project: dmoz
2008-08-20 03:51:13-0300 [tutorial] INFO: Enabled extensions: ...
2008-08-20 03:51:13-0300 [tutorial] INFO: Enabled downloader middlewares: ...
2008-08-20 03:51:13-0300 [tutorial] INFO: Enabled spider middlewares: ...
2008-08-20 03:51:13-0300 [tutorial] INFO: Enabled item pipelines: ...
2008-08-20 03:51:14-0300 [dmoz] INFO: Spider opened
2008-08-20 03:51:14-0300 [dmoz] DEBUG: Crawled &lt;http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/&gt; (referer: &lt;None&gt;)
2008-08-20 03:51:14-0300 [dmoz] DEBUG: Crawled &lt;http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&gt; (referer: &lt;None&gt;)
2008-08-20 03:51:14-0300 [dmoz] INFO: Spider closed (finished)
</pre></div>
</div>
<p>Pay attention to the lines containing <tt class="docutils literal"><span class="pre">[dmoz]</span></tt>, which corresponds to our
spider. You can see a log line for each URL defined in <tt class="docutils literal"><span class="pre">start_urls</span></tt>. Because
these URLs are the starting ones, they have no referrers, which is shown at the
end of the log line, where it says <tt class="docutils literal"><span class="pre">(referer:</span> <span class="pre">&lt;None&gt;)</span></tt>.</p>
<p>But more interesting, as our <tt class="docutils literal"><span class="pre">parse</span></tt> method instructs, two files have been
created: <em>Books</em> and <em>Resources</em>, with the content of both URLs.</p>
<div class="section" id="what-just-happened-under-the-hood">
<h4>What just happened under the hood?<a class="headerlink" href="#what-just-happened-under-the-hood" title="Permalink to this headline">¶</a></h4>
<p>Scrapy creates <a class="reference internal" href="../topics/request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">scrapy.http.Request</span></tt></a> objects for each URL in the
<tt class="docutils literal"><span class="pre">start_urls</span></tt> attribute of the Spider, and assigns them the <tt class="docutils literal"><span class="pre">parse</span></tt> method of
the spider as their callback function.</p>
<p>These Requests are scheduled, then executed, and
<a class="reference internal" href="../topics/request-response.html#scrapy.http.Response" title="scrapy.http.Response"><tt class="xref py py-class docutils literal"><span class="pre">scrapy.http.Response</span></tt></a> objects are returned and then fed back to the
spider, through the <a class="reference internal" href="../topics/spiders.html#scrapy.spider.BaseSpider.parse" title="scrapy.spider.BaseSpider.parse"><tt class="xref py py-meth docutils literal"><span class="pre">parse()</span></tt></a> method.</p>
</div>
</div>
<div class="section" id="extracting-items">
<h3>Extracting Items<a class="headerlink" href="#extracting-items" title="Permalink to this headline">¶</a></h3>
<div class="section" id="introduction-to-selectors">
<h4>Introduction to Selectors<a class="headerlink" href="#introduction-to-selectors" title="Permalink to this headline">¶</a></h4>
<p>There are several ways to extract data from web pages. Scrapy uses a mechanism
based on <a class="reference external" href="http://www.w3.org/TR/xpath">XPath</a> or <a class="reference external" href="http://www.w3.org/TR/selectors">CSS</a> expressions called <a class="reference internal" href="../topics/selectors.html#topics-selectors"><em>Scrapy Selectors</em></a>.  For more information about selectors and other extraction
mechanisms see the <a class="reference internal" href="../topics/selectors.html#topics-selectors"><em>Selectors documentation</em></a>.</p>
<p>Here are some examples of XPath expressions and their meanings:</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">/html/head/title</span></tt>: selects the <tt class="docutils literal"><span class="pre">&lt;title&gt;</span></tt> element, inside the <tt class="docutils literal"><span class="pre">&lt;head&gt;</span></tt>
element of a HTML document</li>
<li><tt class="docutils literal"><span class="pre">/html/head/title/text()</span></tt>: selects the text inside the aforementioned
<tt class="docutils literal"><span class="pre">&lt;title&gt;</span></tt> element.</li>
<li><tt class="docutils literal"><span class="pre">//td</span></tt>: selects all the <tt class="docutils literal"><span class="pre">&lt;td&gt;</span></tt> elements</li>
<li><tt class="docutils literal"><span class="pre">//div[@class="mine"]</span></tt>: selects all <tt class="docutils literal"><span class="pre">div</span></tt> elements which contain an
attribute <tt class="docutils literal"><span class="pre">class="mine"</span></tt></li>
</ul>
<p>These are just a couple of simple examples of what you can do with XPath, but
XPath expressions are indeed much more powerful. To learn more about XPath we
recommend <a class="reference external" href="http://www.w3schools.com/XPath/default.asp">this XPath tutorial</a>.</p>
<p>For working with XPaths, Scrapy provides a <a class="reference internal" href="../topics/selectors.html#scrapy.selector.Selector" title="scrapy.selector.Selector"><tt class="xref py py-class docutils literal"><span class="pre">Selector</span></tt></a>
class, it is instantiated with a <a class="reference internal" href="../topics/request-response.html#scrapy.http.HtmlResponse" title="scrapy.http.HtmlResponse"><tt class="xref py py-class docutils literal"><span class="pre">HtmlResponse</span></tt></a> or
<a class="reference internal" href="../topics/request-response.html#scrapy.http.XmlResponse" title="scrapy.http.XmlResponse"><tt class="xref py py-class docutils literal"><span class="pre">XmlResponse</span></tt></a> object as first argument.</p>
<p>You can see selectors as objects that represent nodes in the document
structure. So, the first instantiated selectors are associated to the root
node, or the entire document.</p>
<p>Selectors have four basic methods (click on the method to see the complete API
documentation).</p>
<ul class="simple">
<li><a class="reference internal" href="../topics/selectors.html#scrapy.selector.Selector.xpath" title="scrapy.selector.Selector.xpath"><tt class="xref py py-meth docutils literal"><span class="pre">xpath()</span></tt></a>: returns a list of selectors, each of
them representing the nodes selected by the xpath expression given as
argument.</li>
<li><a class="reference internal" href="../topics/selectors.html#scrapy.selector.Selector.css" title="scrapy.selector.Selector.css"><tt class="xref py py-meth docutils literal"><span class="pre">css()</span></tt></a>: returns a list of selectors, each of
them representing the nodes selected by the CSS expression given as argument.</li>
<li><a class="reference internal" href="../topics/selectors.html#scrapy.selector.Selector.extract" title="scrapy.selector.Selector.extract"><tt class="xref py py-meth docutils literal"><span class="pre">extract()</span></tt></a>: returns a unicode string with the
selected data.</li>
<li><a class="reference internal" href="../topics/selectors.html#scrapy.selector.Selector.re" title="scrapy.selector.Selector.re"><tt class="xref py py-meth docutils literal"><span class="pre">re()</span></tt></a>: returns a list of unicode strings
extracted by applying the regular expression given as argument.</li>
</ul>
</div>
<div class="section" id="trying-selectors-in-the-shell">
<h4>Trying Selectors in the Shell<a class="headerlink" href="#trying-selectors-in-the-shell" title="Permalink to this headline">¶</a></h4>
<p>To illustrate the use of Selectors we’re going to use the built-in <a class="reference internal" href="../topics/shell.html#topics-shell"><em>Scrapy
shell</em></a>, which also requires IPython (an extended Python console)
installed on your system.</p>
<p>To start a shell, you must go to the project’s top level directory and run:</p>
<div class="highlight-python"><div class="highlight"><pre>scrapy shell "http://www.dmoz.org/Computers/Programming/Languages/Python/Books/"
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Remember to always enclose urls with quotes when running Scrapy shell from
command-line, otherwise urls containing arguments (ie. <tt class="docutils literal"><span class="pre">&amp;</span></tt> character)
will not work.</p>
</div>
<p>This is what the shell looks like:</p>
<div class="highlight-python"><div class="highlight"><pre>[ ... Scrapy log here ... ]

[s] Available Scrapy objects:
[s] 2010-08-19 21:45:59-0300 [default] INFO: Spider closed (finished)
[s]   sel        &lt;Selector (http://www.dmoz.org/Computers/Programming/Languages/Python/Books/) xpath=None&gt;
[s]   item       Item()
[s]   request    &lt;GET http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&gt;
[s]   response   &lt;200 http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&gt;
[s]   spider     &lt;BaseSpider 'default' at 0x1b6c2d0&gt;
[s] Useful shortcuts:
[s]   shelp()           Print this help
[s]   fetch(req_or_url) Fetch a new request or URL and update shell objects
[s]   view(response)    View response in a browser

In [1]:
</pre></div>
</div>
<p>After the shell loads, you will have the response fetched in a local
<tt class="docutils literal"><span class="pre">response</span></tt> variable, so if you type <tt class="docutils literal"><span class="pre">response.body</span></tt> you will see the body
of the response, or you can type <tt class="docutils literal"><span class="pre">response.headers</span></tt> to see its headers.</p>
<p>The shell also pre-instantiate a selector for this response in variable <tt class="docutils literal"><span class="pre">sel</span></tt>,
the selector automatically chooses the best parsing rules (XML vs HTML) based
on response’s type.</p>
<p>So let’s try it:</p>
<div class="highlight-python"><div class="highlight"><pre>In [1]: sel.xpath('//title')
Out[1]: [&lt;Selector (title) xpath=//title&gt;]

In [2]: sel.xpath('//title').extract()
Out[2]: [u'&lt;title&gt;Open Directory - Computers: Programming: Languages: Python: Books&lt;/title&gt;']

In [3]: sel.xpath('//title/text()')
Out[3]: [&lt;Selector (text) xpath=//title/text()&gt;]

In [4]: sel.xpath('//title/text()').extract()
Out[4]: [u'Open Directory - Computers: Programming: Languages: Python: Books']

In [5]: sel.xpath('//title/text()').re('(\w+):')
Out[5]: [u'Computers', u'Programming', u'Languages', u'Python']
</pre></div>
</div>
</div>
<div class="section" id="extracting-the-data">
<h4>Extracting the data<a class="headerlink" href="#extracting-the-data" title="Permalink to this headline">¶</a></h4>
<p>Now, let’s try to extract some real information from those pages.</p>
<p>You could type <tt class="docutils literal"><span class="pre">response.body</span></tt> in the console, and inspect the source code to
figure out the XPaths you need to use. However, inspecting the raw HTML code
there could become a very tedious task. To make this an easier task, you can
use some Firefox extensions like Firebug. For more information see
<a class="reference internal" href="../topics/firebug.html#topics-firebug"><em>Using Firebug for scraping</em></a> and <a class="reference internal" href="../topics/firefox.html#topics-firefox"><em>Using Firefox for scraping</em></a>.</p>
<p>After inspecting the page source, you’ll find that the web sites information
is inside a <tt class="docutils literal"><span class="pre">&lt;ul&gt;</span></tt> element, in fact the <em>second</em> <tt class="docutils literal"><span class="pre">&lt;ul&gt;</span></tt> element.</p>
<p>So we can select each <tt class="docutils literal"><span class="pre">&lt;li&gt;</span></tt> element belonging to the sites list with this
code:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//ul/li'</span><span class="p">)</span>
</pre></div>
</div>
<p>And from them, the sites descriptions:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//ul/li/text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</pre></div>
</div>
<p>The sites titles:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//ul/li/a/text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</pre></div>
</div>
<p>And the sites links:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//ul/li/a/@href'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</pre></div>
</div>
<p>As we said before, each <tt class="docutils literal"><span class="pre">.xpath()</span></tt> call returns a list of selectors, so we can
concatenate further <tt class="docutils literal"><span class="pre">.xpath()</span></tt> calls to dig deeper into a node. We are going to use
that property here, so:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">sites</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//ul/li'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">site</span> <span class="ow">in</span> <span class="n">sites</span><span class="p">:</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">site</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'a/text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
    <span class="n">link</span> <span class="o">=</span> <span class="n">site</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'a/@href'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
    <span class="n">desc</span> <span class="o">=</span> <span class="n">site</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
    <span class="k">print</span> <span class="n">title</span><span class="p">,</span> <span class="n">link</span><span class="p">,</span> <span class="n">desc</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">For a more detailed description of using nested selectors, see
<a class="reference internal" href="../topics/selectors.html#topics-selectors-nesting-selectors"><em>Nesting selectors</em></a> and
<a class="reference internal" href="../topics/selectors.html#topics-selectors-relative-xpaths"><em>Working with relative XPaths</em></a> in the <a class="reference internal" href="../topics/selectors.html#topics-selectors"><em>Selectors</em></a>
documentation</p>
</div>
<p>Let’s add this code to our spider:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.spider</span> <span class="kn">import</span> <span class="n">BaseSpider</span>
<span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">Selector</span>

<span class="k">class</span> <span class="nc">DmozSpider</span><span class="p">(</span><span class="n">BaseSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">"dmoz"</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">"dmoz.org"</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/"</span><span class="p">,</span>
        <span class="s">"http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/"</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">sel</span> <span class="o">=</span> <span class="n">Selector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">sites</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//ul/li'</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">site</span> <span class="ow">in</span> <span class="n">sites</span><span class="p">:</span>
            <span class="n">title</span> <span class="o">=</span> <span class="n">site</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'a/text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
            <span class="n">link</span> <span class="o">=</span> <span class="n">site</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'a/@href'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
            <span class="n">desc</span> <span class="o">=</span> <span class="n">site</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
            <span class="k">print</span> <span class="n">title</span><span class="p">,</span> <span class="n">link</span><span class="p">,</span> <span class="n">desc</span>
</pre></div>
</div>
<p>Now try crawling the dmoz.org domain again and you’ll see sites being printed
in your output, run:</p>
<div class="highlight-python"><div class="highlight"><pre>scrapy crawl dmoz
</pre></div>
</div>
</div>
</div>
<div class="section" id="using-our-item">
<h3>Using our item<a class="headerlink" href="#using-our-item" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../topics/items.html#scrapy.item.Item" title="scrapy.item.Item"><tt class="xref py py-class docutils literal"><span class="pre">Item</span></tt></a> objects are custom python dicts; you can access the
values of their fields (attributes of the class we defined earlier) using the
standard dict syntax like:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">item</span> <span class="o">=</span> <span class="n">DmozItem</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">item</span><span class="p">[</span><span class="s">'title'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'Example title'</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">item</span><span class="p">[</span><span class="s">'title'</span><span class="p">]</span>
<span class="go">'Example title'</span>
</pre></div>
</div>
<p>Spiders are expected to return their scraped data inside
<a class="reference internal" href="../topics/items.html#scrapy.item.Item" title="scrapy.item.Item"><tt class="xref py py-class docutils literal"><span class="pre">Item</span></tt></a> objects. So, in order to return the data we’ve
scraped so far, the final code for our Spider would be like this:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.spider</span> <span class="kn">import</span> <span class="n">BaseSpider</span>
<span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">Selector</span>

<span class="kn">from</span> <span class="nn">tutorial.items</span> <span class="kn">import</span> <span class="n">DmozItem</span>

<span class="k">class</span> <span class="nc">DmozSpider</span><span class="p">(</span><span class="n">BaseSpider</span><span class="p">):</span>
   <span class="n">name</span> <span class="o">=</span> <span class="s">"dmoz"</span>
   <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">"dmoz.org"</span><span class="p">]</span>
   <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
       <span class="s">"http://www.dmoz.org/Computers/Programming/Languages/Python/Books/"</span><span class="p">,</span>
       <span class="s">"http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/"</span>
   <span class="p">]</span>

   <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
       <span class="n">sel</span> <span class="o">=</span> <span class="n">Selector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
       <span class="n">sites</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//ul/li'</span><span class="p">)</span>
       <span class="n">items</span> <span class="o">=</span> <span class="p">[]</span>
       <span class="k">for</span> <span class="n">site</span> <span class="ow">in</span> <span class="n">sites</span><span class="p">:</span>
           <span class="n">item</span> <span class="o">=</span> <span class="n">DmozItem</span><span class="p">()</span>
           <span class="n">item</span><span class="p">[</span><span class="s">'title'</span><span class="p">]</span> <span class="o">=</span> <span class="n">site</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'a/text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
           <span class="n">item</span><span class="p">[</span><span class="s">'link'</span><span class="p">]</span> <span class="o">=</span> <span class="n">site</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'a/@href'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
           <span class="n">item</span><span class="p">[</span><span class="s">'desc'</span><span class="p">]</span> <span class="o">=</span> <span class="n">site</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
           <span class="n">items</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
       <span class="k">return</span> <span class="n">items</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">You can find a fully-functional variant of this spider in the <a class="reference external" href="https://github.com/scrapy/dirbot">dirbot</a>
project available at <a class="reference external" href="https://github.com/scrapy/dirbot">https://github.com/scrapy/dirbot</a></p>
</div>
<p>Now doing a crawl on the dmoz.org domain yields <tt class="docutils literal"><span class="pre">DmozItem</span></tt>‘s:</p>
<div class="highlight-python"><div class="highlight"><pre>[dmoz] DEBUG: Scraped from &lt;200 http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&gt;
     {'desc': [u' - By David Mertz; Addison Wesley. Book in progress, full text, ASCII format. Asks for feedback. [author website, Gnosis Software, Inc.\n],
      'link': [u'http://gnosis.cx/TPiP/'],
      'title': [u'Text Processing in Python']}
[dmoz] DEBUG: Scraped from &lt;200 http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&gt;
     {'desc': [u' - By Sean McGrath; Prentice Hall PTR, 2000, ISBN 0130211192, has CD-ROM. Methods to build XML applications fast, Python tutorial, DOM and SAX, new Pyxie open source XML processing library. [Prentice Hall PTR]\n'],
      'link': [u'http://www.informit.com/store/product.aspx?isbn=0130211192'],
      'title': [u'XML Processing with Python']}
</pre></div>
</div>
</div>
</div>
<div class="section" id="storing-the-scraped-data">
<h2>Storing the scraped data<a class="headerlink" href="#storing-the-scraped-data" title="Permalink to this headline">¶</a></h2>
<p>The simplest way to store the scraped data is by using the <a class="reference internal" href="../topics/feed-exports.html#topics-feed-exports"><em>Feed exports</em></a>, with the following command:</p>
<div class="highlight-python"><div class="highlight"><pre>scrapy crawl dmoz -o items.json -t json
</pre></div>
</div>
<p>That will generate a <tt class="docutils literal"><span class="pre">items.json</span></tt> file containing all scraped items,
serialized in <a class="reference external" href="http://en.wikipedia.org/wiki/JSON">JSON</a>.</p>
<p>In small projects (like the one in this tutorial), that should be enough.
However, if you want to perform more complex things with the scraped items, you
can write an <a class="reference internal" href="../topics/item-pipeline.html#topics-item-pipeline"><em>Item Pipeline</em></a>. As with Items, a
placeholder file for Item Pipelines has been set up for you when the project is
created, in <tt class="docutils literal"><span class="pre">tutorial/pipelines.py</span></tt>. Though you don’t need to implement any item
pipeline if you just want to store the scraped items.</p>
</div>
<div class="section" id="next-steps">
<h2>Next steps<a class="headerlink" href="#next-steps" title="Permalink to this headline">¶</a></h2>
<p>This tutorial covers only the basics of Scrapy, but there’s a lot of other
features not mentioned here. Check the <a class="reference internal" href="overview.html#topics-whatelse"><em>What else?</em></a> section in
<a class="reference internal" href="overview.html#intro-overview"><em>Scrapy at a glance</em></a> chapter for a quick overview of the most important ones.</p>
<p>Then, we recommend you continue by playing with an example project (see
<a class="reference internal" href="examples.html#intro-examples"><em>Examples</em></a>), and then continue with the section
<a class="reference internal" href="../index.html#section-basics"><em>Basic concepts</em></a>.</p>
</div>
</div>


          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="examples.html" class="btn btn-neutral float-right" title="Examples">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="install.html" class="btn btn-neutral" title="Installation guide"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr /><div><div id="rtd-afleeq0s" class="ethical-rtd"></div></div>

  <div role="contentinfo">
    <p>
        © Copyright 2008-2013, Scrapy developers.
      Last updated on Sep 18, 2014.
    </p>
  </div>

  <a href="https://github.com/snide/sphinx_rtd_theme">Sphinx theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>
</footer>
        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: 0.20
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions"><!-- Inserted RTD Footer -->
<div class="injected">

  

      
      
      
      <dl>
        <dt>Versions</dt>
        
        
        <dd><a href="https://docs.scrapy.org/en/latest/intro/tutorial.html">latest</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.6/intro/tutorial.html">1.6</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.5/intro/tutorial.html">1.5</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.4/intro/tutorial.html">1.4</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.3/intro/tutorial.html">1.3</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.2/intro/tutorial.html">1.2</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.1/intro/tutorial.html">1.1</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.0/intro/tutorial.html">1.0</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.24/intro/tutorial.html">0.24</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.22/intro/tutorial.html">0.22</a></dd>
        
        
         <strong> 
        <dd><a href="https://docs.scrapy.org/en/0.20/intro/tutorial.html">0.20</a></dd>
         </strong> 
        
        
        <dd><a href="https://docs.scrapy.org/en/master/intro/tutorial.html">master</a></dd>
        
        
      </dl>
      
      

      
      
      <dl>
        <dt>Downloads</dt>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/pdf/0.20/">PDF</a></dd>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/htmlzip/0.20/">HTML</a></dd>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/epub/0.20/">Epub</a></dd>
        
      </dl>
      
      

      
      <dl>
        <!-- These are kept as relative links for internal installs that are http -->
        <dt>On Read the Docs</dt>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/">Project Home</a>
        </dd>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/builds/">Builds</a>
        </dd>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/downloads/">Downloads</a>
        </dd>
      </dl>
      

      

      
      <dl>
        <dt>On GitHub</dt>
        <dd>
          <a href="https://github.com/scrapy/scrapy/blob/0.20/docs/intro/tutorial.rst">View</a>
        </dd>
        
        <dd>
          <a href="https://github.com/scrapy/scrapy/edit/0.20/docs/intro/tutorial.rst">Edit</a>
        </dd>
        
      </dl>
      
      

      
      <dl>
        <dt>Search</dt>
        <dd>
          <div style="padding: 6px;">
            <form id="flyout-search-form" class="wy-form" target="_blank" action="//readthedocs.org/projects/scrapy/search/" method="get">
              <input type="text" name="q" placeholder="Search docs" />
              </form>
          </div>
        </dd>
      </dl>
      



      <hr />
      
        <small>
          <span>Hosted by <a href="https://readthedocs.org">Read the Docs</a></span>
          <span> · </span>
          <a href="https://docs.readthedocs.io/page/privacy-policy.html">Privacy Policy</a>
        </small>
      

      

</div>
</div>
  </div>



  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.20.2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-2.0.3.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-migrate-1.2.1.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/underscore.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/doctools.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/readthedocs-doc-embed.js"></script>

  

  
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   


<div id="rtd-0bha4e7p"></div></body></html>