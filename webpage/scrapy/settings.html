<!DOCTYPE html><!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]--><!--[if gt IE 8]><!--><html xmlns="http://www.w3.org/1999/xhtml" class=" js flexbox canvas canvastext webgl no-touch geolocation postmessage websqldatabase indexeddb hashchange history draganddrop websockets rgba hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients cssreflections csstransforms csstransforms3d csstransitions fontface generatedcontent video audio localstorage sessionstorage webworkers applicationcache svg inlinesvg smil svgclippaths" lang="en" style=""><!--<![endif]--><head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Settings — Scrapy 1.6.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Exceptions" href="exceptions.html" />
    <link rel="prev" title="Link Extractors" href="link-extractors.html" /> 

  
  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script type="text/javascript" async="" src="https://www.google-analytics.com/plugins/ua/linkid.js"></script><script type="text/javascript" async="" src="https://cdn.segment.com/analytics.js/v1/8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA/analytics.min.js"></script><script async="" src="https://www.google-analytics.com/analytics.js"></script><script src="../_static/js/modernizr.min.js"></script>


<!-- RTD Extra Head -->

<!-- 
Always link to the latest version, as canonical.
http://docs.readthedocs.org/en/latest/canonical.html
-->
<link rel="canonical" href="https://docs.scrapy.org/en/latest/topics/settings.html" />

<link rel="stylesheet" href="https://assets.readthedocs.org/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="text/javascript" src="../_static/readthedocs-data.js"></script>

<!-- Add page-specific data, which must exist in the page js, not global -->
<script type="text/javascript">
READTHEDOCS_DATA['page'] = 'topics/settings'
READTHEDOCS_DATA['source_suffix'] = '.rst'
</script>

<script type="text/javascript" src="https://assets.readthedocs.org/static/javascript/readthedocs-analytics.js"></script>

<!-- end RTD <extrahead> -->
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Scrapy
          

          
          </a>

          
            
            
            
              <div class="version">
                latest
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">First steps</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/overview.html">Scrapy at a glance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/install.html">Installation guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/tutorial.html">Scrapy Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/examples.html">Examples</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic concepts</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="commands.html">Command line tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="spiders.html">Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="selectors.html">Selectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="items.html">Items</a></li>
<li class="toctree-l1"><a class="reference internal" href="loaders.html">Item Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="shell.html">Scrapy shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="item-pipeline.html">Item Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="feed-exports.html">Feed exports</a></li>
<li class="toctree-l1"><a class="reference internal" href="request-response.html">Requests and Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="link-extractors.html">Link Extractors</a></li>
<li class="toctree-l1 current"><a class="reference internal current" href="#"><span class="toctree-expand"></span>Settings</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#designating-the-settings">Designating the settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="#populating-the-settings"><span class="toctree-expand"></span>Populating the settings</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#command-line-options">1. Command line options</a></li>
<li class="toctree-l3"><a class="reference internal" href="#settings-per-spider">2. Settings per-spider</a></li>
<li class="toctree-l3"><a class="reference internal" href="#project-settings-module">3. Project settings module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#default-settings-per-command">4. Default settings per-command</a></li>
<li class="toctree-l3"><a class="reference internal" href="#default-global-settings">5. Default global settings</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#how-to-access-settings">How to access settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="#rationale-for-setting-names">Rationale for setting names</a></li>
<li class="toctree-l2"><a class="reference internal" href="#built-in-settings-reference"><span class="toctree-expand"></span>Built-in settings reference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#aws-access-key-id">AWS_ACCESS_KEY_ID</a></li>
<li class="toctree-l3"><a class="reference internal" href="#aws-secret-access-key">AWS_SECRET_ACCESS_KEY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#aws-endpoint-url">AWS_ENDPOINT_URL</a></li>
<li class="toctree-l3"><a class="reference internal" href="#aws-use-ssl">AWS_USE_SSL</a></li>
<li class="toctree-l3"><a class="reference internal" href="#aws-verify">AWS_VERIFY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#aws-region-name">AWS_REGION_NAME</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bot-name">BOT_NAME</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concurrent-items">CONCURRENT_ITEMS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concurrent-requests">CONCURRENT_REQUESTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concurrent-requests-per-domain">CONCURRENT_REQUESTS_PER_DOMAIN</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concurrent-requests-per-ip">CONCURRENT_REQUESTS_PER_IP</a></li>
<li class="toctree-l3"><a class="reference internal" href="#default-item-class">DEFAULT_ITEM_CLASS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#default-request-headers">DEFAULT_REQUEST_HEADERS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#depth-limit">DEPTH_LIMIT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#depth-priority">DEPTH_PRIORITY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#depth-stats-verbose">DEPTH_STATS_VERBOSE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dnscache-enabled">DNSCACHE_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dnscache-size">DNSCACHE_SIZE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dns-timeout">DNS_TIMEOUT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloader">DOWNLOADER</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloader-httpclientfactory">DOWNLOADER_HTTPCLIENTFACTORY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloader-clientcontextfactory">DOWNLOADER_CLIENTCONTEXTFACTORY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloader-client-tls-method">DOWNLOADER_CLIENT_TLS_METHOD</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloader-middlewares">DOWNLOADER_MIDDLEWARES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloader-middlewares-base">DOWNLOADER_MIDDLEWARES_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloader-stats">DOWNLOADER_STATS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-delay">DOWNLOAD_DELAY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-handlers">DOWNLOAD_HANDLERS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-handlers-base">DOWNLOAD_HANDLERS_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-timeout">DOWNLOAD_TIMEOUT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-maxsize">DOWNLOAD_MAXSIZE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-warnsize">DOWNLOAD_WARNSIZE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-fail-on-dataloss">DOWNLOAD_FAIL_ON_DATALOSS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dupefilter-class">DUPEFILTER_CLASS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dupefilter-debug">DUPEFILTER_DEBUG</a></li>
<li class="toctree-l3"><a class="reference internal" href="#editor">EDITOR</a></li>
<li class="toctree-l3"><a class="reference internal" href="#extensions">EXTENSIONS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#extensions-base">EXTENSIONS_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#feed-tempdir">FEED_TEMPDIR</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ftp-passive-mode">FTP_PASSIVE_MODE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ftp-password">FTP_PASSWORD</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ftp-user">FTP_USER</a></li>
<li class="toctree-l3"><a class="reference internal" href="#item-pipelines">ITEM_PIPELINES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#item-pipelines-base">ITEM_PIPELINES_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-enabled">LOG_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-encoding">LOG_ENCODING</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-file">LOG_FILE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-format">LOG_FORMAT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-dateformat">LOG_DATEFORMAT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-level">LOG_LEVEL</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-stdout">LOG_STDOUT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-short-names">LOG_SHORT_NAMES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memdebug-enabled">MEMDEBUG_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memdebug-notify">MEMDEBUG_NOTIFY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memusage-enabled">MEMUSAGE_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memusage-limit-mb">MEMUSAGE_LIMIT_MB</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memusage-check-interval-seconds">MEMUSAGE_CHECK_INTERVAL_SECONDS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memusage-notify-mail">MEMUSAGE_NOTIFY_MAIL</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memusage-warning-mb">MEMUSAGE_WARNING_MB</a></li>
<li class="toctree-l3"><a class="reference internal" href="#newspider-module">NEWSPIDER_MODULE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#randomize-download-delay">RANDOMIZE_DOWNLOAD_DELAY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reactor-threadpool-maxsize">REACTOR_THREADPOOL_MAXSIZE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#redirect-max-times">REDIRECT_MAX_TIMES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#redirect-priority-adjust">REDIRECT_PRIORITY_ADJUST</a></li>
<li class="toctree-l3"><a class="reference internal" href="#retry-priority-adjust">RETRY_PRIORITY_ADJUST</a></li>
<li class="toctree-l3"><a class="reference internal" href="#robotstxt-obey">ROBOTSTXT_OBEY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scheduler">SCHEDULER</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scheduler-debug">SCHEDULER_DEBUG</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scheduler-disk-queue">SCHEDULER_DISK_QUEUE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scheduler-memory-queue">SCHEDULER_MEMORY_QUEUE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scheduler-priority-queue">SCHEDULER_PRIORITY_QUEUE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spider-contracts">SPIDER_CONTRACTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spider-contracts-base">SPIDER_CONTRACTS_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spider-loader-class">SPIDER_LOADER_CLASS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spider-loader-warn-only">SPIDER_LOADER_WARN_ONLY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spider-middlewares">SPIDER_MIDDLEWARES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spider-middlewares-base">SPIDER_MIDDLEWARES_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spider-modules">SPIDER_MODULES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stats-class">STATS_CLASS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stats-dump">STATS_DUMP</a></li>
<li class="toctree-l3"><a class="reference internal" href="#statsmailer-rcpts">STATSMAILER_RCPTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#telnetconsole-enabled">TELNETCONSOLE_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="#telnetconsole-port">TELNETCONSOLE_PORT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#templates-dir">TEMPLATES_DIR</a></li>
<li class="toctree-l3"><a class="reference internal" href="#urllength-limit">URLLENGTH_LIMIT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#user-agent">USER_AGENT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#settings-documented-elsewhere">Settings documented elsewhere:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">Exceptions</a></li>
</ul>
<p class="caption"><span class="caption-text">Built-in services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="stats.html">Stats Collection</a></li>
<li class="toctree-l1"><a class="reference internal" href="email.html">Sending e-mail</a></li>
<li class="toctree-l1"><a class="reference internal" href="telnetconsole.html">Telnet Console</a></li>
<li class="toctree-l1"><a class="reference internal" href="webservice.html">Web Service</a></li>
</ul>
<p class="caption"><span class="caption-text">Solving specific problems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="debug.html">Debugging Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="contracts.html">Spiders Contracts</a></li>
<li class="toctree-l1"><a class="reference internal" href="practices.html">Common Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="broad-crawls.html">Broad Crawls</a></li>
<li class="toctree-l1"><a class="reference internal" href="developer-tools.html">Using your browser’s Developer Tools for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="leaks.html">Debugging memory leaks</a></li>
<li class="toctree-l1"><a class="reference internal" href="media-pipeline.html">Downloading and processing files and images</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy.html">Deploying Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="autothrottle.html">AutoThrottle extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="jobs.html">Jobs: pausing and resuming crawls</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending Scrapy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="downloader-middleware.html">Downloader Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="spider-middleware.html">Spider Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="extensions.html">Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">Core API</a></li>
<li class="toctree-l1"><a class="reference internal" href="signals.html">Signals</a></li>
<li class="toctree-l1"><a class="reference internal" href="exporters.html">Item Exporters</a></li>
</ul>
<p class="caption"><span class="caption-text">All the rest</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html">Versioning and API Stability</a></li>
</ul>

            
          
        </div>
      <div id="rtd-hndvh6mg" class="ethical-rtd ethical-dark-theme"></div></div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Scrapy</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> »</li>
        
      <li>Settings</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/scrapy/scrapy/blob/origin/1.6/docs/topics/settings.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr />
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="settings">
<span id="topics-settings"></span><h1>Settings<a class="headerlink" href="#settings" title="Permalink to this headline">¶</a></h1>
<p>The Scrapy settings allows you to customize the behaviour of all Scrapy
components, including the core, extensions, pipelines and spiders themselves.</p>
<p>The infrastructure of the settings provides a global namespace of key-value mappings
that the code can use to pull configuration values from. The settings can be
populated through different mechanisms, which are described below.</p>
<p>The settings are also the mechanism for selecting the currently active Scrapy
project (in case you have many).</p>
<p>For a list of available built-in settings see: <a class="reference internal" href="#topics-settings-ref"><span class="std std-ref">Built-in settings reference</span></a>.</p>
<div class="section" id="designating-the-settings">
<span id="topics-settings-module-envvar"></span><h2>Designating the settings<a class="headerlink" href="#designating-the-settings" title="Permalink to this headline">¶</a></h2>
<p>When you use Scrapy, you have to tell it which settings you’re using. You can
do this by using an environment variable, <code class="docutils literal notranslate"><span class="pre">SCRAPY_SETTINGS_MODULE</span></code>.</p>
<p>The value of <code class="docutils literal notranslate"><span class="pre">SCRAPY_SETTINGS_MODULE</span></code> should be in Python path syntax, e.g.
<code class="docutils literal notranslate"><span class="pre">myproject.settings</span></code>. Note that the settings module should be on the
Python <a class="reference external" href="https://docs.python.org/2/tutorial/modules.html#the-module-search-path">import search path</a>.</p>
</div>
<div class="section" id="populating-the-settings">
<h2>Populating the settings<a class="headerlink" href="#populating-the-settings" title="Permalink to this headline">¶</a></h2>
<p>Settings can be populated using different mechanisms, each of which having a
different precedence. Here is the list of them in decreasing order of
precedence:</p>
<blockquote>
<div><ol class="arabic simple">
<li>Command line options (most precedence)</li>
<li>Settings per-spider</li>
<li>Project settings module</li>
<li>Default settings per-command</li>
<li>Default global settings (less precedence)</li>
</ol>
</div></blockquote>
<p>The population of these settings sources is taken care of internally, but a
manual handling is possible using API calls. See the
<a class="reference internal" href="api.html#topics-api-settings"><span class="std std-ref">Settings API</span></a> topic for reference.</p>
<p>These mechanisms are described in more detail below.</p>
<div class="section" id="command-line-options">
<h3>1. Command line options<a class="headerlink" href="#command-line-options" title="Permalink to this headline">¶</a></h3>
<p>Arguments provided by the command line are the ones that take most precedence,
overriding any other options. You can explicitly override one (or more)
settings using the <code class="docutils literal notranslate"><span class="pre">-s</span></code> (or <code class="docutils literal notranslate"><span class="pre">--set</span></code>) command line option.</p>
<p>Example:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>scrapy crawl myspider -s <span class="nv">LOG_FILE</span><span class="o">=</span>scrapy.log
</pre></div>
</div>
</div>
<div class="section" id="settings-per-spider">
<h3>2. Settings per-spider<a class="headerlink" href="#settings-per-spider" title="Permalink to this headline">¶</a></h3>
<p>Spiders (See the <a class="reference internal" href="spiders.html#topics-spiders"><span class="std std-ref">Spiders</span></a> chapter for reference) can define their
own settings that will take precedence and override the project ones. They can
do so by setting their <a class="reference internal" href="spiders.html#scrapy.spiders.Spider.custom_settings" title="scrapy.spiders.Spider.custom_settings"><code class="xref py py-attr docutils literal notranslate"><span class="pre">custom_settings</span></code></a> attribute:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>class MySpider<span class="o">(</span>scrapy.Spider<span class="o">)</span>:
    <span class="nv">name</span> <span class="o">=</span> <span class="s1">'myspider'</span>

    <span class="nv">custom_settings</span> <span class="o">=</span> <span class="o">{</span>
        <span class="s1">'SOME_SETTING'</span>: <span class="s1">'some value'</span>,
    <span class="o">}</span>
</pre></div>
</div>
</div>
<div class="section" id="project-settings-module">
<h3>3. Project settings module<a class="headerlink" href="#project-settings-module" title="Permalink to this headline">¶</a></h3>
<p>The project settings module is the standard configuration file for your Scrapy
project, it’s where most of your custom settings will be populated. For a
standard Scrapy project, this means you’ll be adding or changing the settings
in the <code class="docutils literal notranslate"><span class="pre">settings.py</span></code> file created for your project.</p>
</div>
<div class="section" id="default-settings-per-command">
<h3>4. Default settings per-command<a class="headerlink" href="#default-settings-per-command" title="Permalink to this headline">¶</a></h3>
<p>Each <a class="reference internal" href="commands.html"><span class="doc">Scrapy tool</span></a> command can have its own default
settings, which override the global default settings. Those custom command
settings are specified in the <code class="docutils literal notranslate"><span class="pre">default_settings</span></code> attribute of the command
class.</p>
</div>
<div class="section" id="default-global-settings">
<h3>5. Default global settings<a class="headerlink" href="#default-global-settings" title="Permalink to this headline">¶</a></h3>
<p>The global defaults are located in the <code class="docutils literal notranslate"><span class="pre">scrapy.settings.default_settings</span></code>
module and documented in the <a class="reference internal" href="#topics-settings-ref"><span class="std std-ref">Built-in settings reference</span></a> section.</p>
</div>
</div>
<div class="section" id="how-to-access-settings">
<h2>How to access settings<a class="headerlink" href="#how-to-access-settings" title="Permalink to this headline">¶</a></h2>
<p>In a spider, the settings are available through <code class="docutils literal notranslate"><span class="pre">self.settings</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">'myspider'</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'http://example.com'</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">"Existing settings: </span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">attributes</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The <code class="docutils literal notranslate"><span class="pre">settings</span></code> attribute is set in the base Spider class after the spider
is initialized.  If you want to use the settings before the initialization
(e.g., in your spider’s <code class="docutils literal notranslate"><span class="pre">__init__()</span></code> method), you’ll need to override the
<a class="reference internal" href="spiders.html#scrapy.spiders.Spider.from_crawler" title="scrapy.spiders.Spider.from_crawler"><code class="xref py py-meth docutils literal notranslate"><span class="pre">from_crawler()</span></code></a> method.</p>
</div>
<p>Settings can be accessed through the <a class="reference internal" href="api.html#scrapy.crawler.Crawler.settings" title="scrapy.crawler.Crawler.settings"><code class="xref py py-attr docutils literal notranslate"><span class="pre">scrapy.crawler.Crawler.settings</span></code></a>
attribute of the Crawler that is passed to <code class="docutils literal notranslate"><span class="pre">from_crawler</span></code> method in
extensions, middlewares and item pipelines:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyExtension</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_is_enabled</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">log_is_enabled</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">"log is enabled!"</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_crawler</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">crawler</span><span class="p">):</span>
        <span class="n">settings</span> <span class="o">=</span> <span class="n">crawler</span><span class="o">.</span><span class="n">settings</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">settings</span><span class="o">.</span><span class="n">getbool</span><span class="p">(</span><span class="s1">'LOG_ENABLED'</span><span class="p">))</span>
</pre></div>
</div>
<p>The settings object can be used like a dict (e.g.,
<code class="docutils literal notranslate"><span class="pre">settings['LOG_ENABLED']</span></code>), but it’s usually preferred to extract the setting
in the format you need it to avoid type errors, using one of the methods
provided by the <a class="reference internal" href="api.html#scrapy.settings.Settings" title="scrapy.settings.Settings"><code class="xref py py-class docutils literal notranslate"><span class="pre">Settings</span></code></a> API.</p>
</div>
<div class="section" id="rationale-for-setting-names">
<h2>Rationale for setting names<a class="headerlink" href="#rationale-for-setting-names" title="Permalink to this headline">¶</a></h2>
<p>Setting names are usually prefixed with the component that they configure. For
example, proper setting names for a fictional robots.txt extension would be
<code class="docutils literal notranslate"><span class="pre">ROBOTSTXT_ENABLED</span></code>, <code class="docutils literal notranslate"><span class="pre">ROBOTSTXT_OBEY</span></code>, <code class="docutils literal notranslate"><span class="pre">ROBOTSTXT_CACHEDIR</span></code>, etc.</p>
</div>
<div class="section" id="built-in-settings-reference">
<span id="topics-settings-ref"></span><h2>Built-in settings reference<a class="headerlink" href="#built-in-settings-reference" title="Permalink to this headline">¶</a></h2>
<p>Here’s a list of all available Scrapy settings, in alphabetical order, along
with their default values and the scope where they apply.</p>
<p>The scope, where available, shows where the setting is being used, if it’s tied
to any particular component. In that case the module of that component will be
shown, typically an extension, middleware or pipeline. It also means that the
component must be enabled in order for the setting to have any effect.</p>
<div class="section" id="aws-access-key-id">
<span id="std:setting-AWS_ACCESS_KEY_ID"></span><h3>AWS_ACCESS_KEY_ID<a class="headerlink" href="#aws-access-key-id" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
<p>The AWS access key used by code that requires access to <a class="reference external" href="https://aws.amazon.com/">Amazon Web services</a>,
such as the <a class="reference internal" href="feed-exports.html#topics-feed-storage-s3"><span class="std std-ref">S3 feed storage backend</span></a>.</p>
</div>
<div class="section" id="aws-secret-access-key">
<span id="std:setting-AWS_SECRET_ACCESS_KEY"></span><h3>AWS_SECRET_ACCESS_KEY<a class="headerlink" href="#aws-secret-access-key" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
<p>The AWS secret key used by code that requires access to <a class="reference external" href="https://aws.amazon.com/">Amazon Web services</a>,
such as the <a class="reference internal" href="feed-exports.html#topics-feed-storage-s3"><span class="std std-ref">S3 feed storage backend</span></a>.</p>
</div>
<div class="section" id="aws-endpoint-url">
<span id="std:setting-AWS_ENDPOINT_URL"></span><h3>AWS_ENDPOINT_URL<a class="headerlink" href="#aws-endpoint-url" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
<p>Endpoint URL used for S3-like storage, for example Minio or s3.scality.
Only supported with <code class="docutils literal notranslate"><span class="pre">botocore</span></code> library.</p>
</div>
<div class="section" id="aws-use-ssl">
<span id="std:setting-AWS_USE_SSL"></span><h3>AWS_USE_SSL<a class="headerlink" href="#aws-use-ssl" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
<p>Use this option if you want to disable SSL connection for communication with
S3 or S3-like storage. By default SSL will be used.
Only supported with <code class="docutils literal notranslate"><span class="pre">botocore</span></code> library.</p>
</div>
<div class="section" id="aws-verify">
<span id="std:setting-AWS_VERIFY"></span><h3>AWS_VERIFY<a class="headerlink" href="#aws-verify" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
<p>Verify SSL connection between Scrapy and S3 or S3-like storage. By default
SSL verification will occur. Only supported with <code class="docutils literal notranslate"><span class="pre">botocore</span></code> library.</p>
</div>
<div class="section" id="aws-region-name">
<span id="std:setting-AWS_REGION_NAME"></span><h3>AWS_REGION_NAME<a class="headerlink" href="#aws-region-name" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
<p>The name of the region associated with the AWS client.
Only supported with <code class="docutils literal notranslate"><span class="pre">botocore</span></code> library.</p>
</div>
<div class="section" id="bot-name">
<span id="std:setting-BOT_NAME"></span><h3>BOT_NAME<a class="headerlink" href="#bot-name" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">'scrapybot'</span></code></p>
<p>The name of the bot implemented by this Scrapy project (also known as the
project name). This will be used to construct the User-Agent by default, and
also for logging.</p>
<p>It’s automatically populated with your project name when you create your
project with the <a class="reference internal" href="commands.html#std:command-startproject"><code class="xref std std-command docutils literal notranslate"><span class="pre">startproject</span></code></a> command.</p>
</div>
<div class="section" id="concurrent-items">
<span id="std:setting-CONCURRENT_ITEMS"></span><h3>CONCURRENT_ITEMS<a class="headerlink" href="#concurrent-items" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">100</span></code></p>
<p>Maximum number of concurrent items (per response) to process in parallel in the
Item Processor (also known as the <a class="reference internal" href="item-pipeline.html#topics-item-pipeline"><span class="std std-ref">Item Pipeline</span></a>).</p>
</div>
<div class="section" id="concurrent-requests">
<span id="std:setting-CONCURRENT_REQUESTS"></span><h3>CONCURRENT_REQUESTS<a class="headerlink" href="#concurrent-requests" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">16</span></code></p>
<p>The maximum number of concurrent (ie. simultaneous) requests that will be
performed by the Scrapy downloader.</p>
</div>
<div class="section" id="concurrent-requests-per-domain">
<span id="std:setting-CONCURRENT_REQUESTS_PER_DOMAIN"></span><h3>CONCURRENT_REQUESTS_PER_DOMAIN<a class="headerlink" href="#concurrent-requests-per-domain" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">8</span></code></p>
<p>The maximum number of concurrent (ie. simultaneous) requests that will be
performed to any single domain.</p>
<p>See also: <a class="reference internal" href="autothrottle.html#topics-autothrottle"><span class="std std-ref">AutoThrottle extension</span></a> and its
<a class="reference internal" href="autothrottle.html#std:setting-AUTOTHROTTLE_TARGET_CONCURRENCY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">AUTOTHROTTLE_TARGET_CONCURRENCY</span></code></a> option.</p>
</div>
<div class="section" id="concurrent-requests-per-ip">
<span id="std:setting-CONCURRENT_REQUESTS_PER_IP"></span><h3>CONCURRENT_REQUESTS_PER_IP<a class="headerlink" href="#concurrent-requests-per-ip" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">0</span></code></p>
<p>The maximum number of concurrent (ie. simultaneous) requests that will be
performed to any single IP. If non-zero, the
<a class="reference internal" href="#std:setting-CONCURRENT_REQUESTS_PER_DOMAIN"><code class="xref std std-setting docutils literal notranslate"><span class="pre">CONCURRENT_REQUESTS_PER_DOMAIN</span></code></a> setting is ignored, and this one is
used instead. In other words, concurrency limits will be applied per IP, not
per domain.</p>
<p>This setting also affects <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_DELAY</span></code></a> and
<a class="reference internal" href="autothrottle.html#topics-autothrottle"><span class="std std-ref">AutoThrottle extension</span></a>: if <a class="reference internal" href="#std:setting-CONCURRENT_REQUESTS_PER_IP"><code class="xref std std-setting docutils literal notranslate"><span class="pre">CONCURRENT_REQUESTS_PER_IP</span></code></a>
is non-zero, download delay is enforced per IP, not per domain.</p>
</div>
<div class="section" id="default-item-class">
<span id="std:setting-DEFAULT_ITEM_CLASS"></span><h3>DEFAULT_ITEM_CLASS<a class="headerlink" href="#default-item-class" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">'scrapy.item.Item'</span></code></p>
<p>The default class that will be used for instantiating items in the <a class="reference internal" href="shell.html#topics-shell"><span class="std std-ref">the
Scrapy shell</span></a>.</p>
</div>
<div class="section" id="default-request-headers">
<span id="std:setting-DEFAULT_REQUEST_HEADERS"></span><h3>DEFAULT_REQUEST_HEADERS<a class="headerlink" href="#default-request-headers" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">'Accept'</span><span class="p">:</span> <span class="s1">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span><span class="p">,</span>
    <span class="s1">'Accept-Language'</span><span class="p">:</span> <span class="s1">'en'</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The default headers used for Scrapy HTTP Requests. They’re populated in the
<a class="reference internal" href="downloader-middleware.html#scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware" title="scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware"><code class="xref py py-class docutils literal notranslate"><span class="pre">DefaultHeadersMiddleware</span></code></a>.</p>
</div>
<div class="section" id="depth-limit">
<span id="std:setting-DEPTH_LIMIT"></span><h3>DEPTH_LIMIT<a class="headerlink" href="#depth-limit" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">0</span></code></p>
<p>Scope: <code class="docutils literal notranslate"><span class="pre">scrapy.spidermiddlewares.depth.DepthMiddleware</span></code></p>
<p>The maximum depth that will be allowed to crawl for any site. If zero, no limit
will be imposed.</p>
</div>
<div class="section" id="depth-priority">
<span id="std:setting-DEPTH_PRIORITY"></span><h3>DEPTH_PRIORITY<a class="headerlink" href="#depth-priority" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">0</span></code></p>
<p>Scope: <code class="docutils literal notranslate"><span class="pre">scrapy.spidermiddlewares.depth.DepthMiddleware</span></code></p>
<p>An integer that is used to adjust the request priority based on its depth:</p>
<ul class="simple">
<li>if zero (default), no priority adjustment is made from depth</li>
<li><strong>a positive value will decrease the priority, i.e. higher depth
requests will be processed later</strong> ; this is commonly used when doing
breadth-first crawls (BFO)</li>
<li>a negative value will increase priority, i.e., higher depth requests
will be processed sooner (DFO)</li>
</ul>
<p>See also: <a class="reference internal" href="../faq.html#faq-bfo-dfo"><span class="std std-ref">Does Scrapy crawl in breadth-first or depth-first order?</span></a> about tuning Scrapy for BFO or DFO.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This setting adjusts priority <strong>in the opposite way</strong> compared to
other priority settings <a class="reference internal" href="#std:setting-REDIRECT_PRIORITY_ADJUST"><code class="xref std std-setting docutils literal notranslate"><span class="pre">REDIRECT_PRIORITY_ADJUST</span></code></a>
and <a class="reference internal" href="#std:setting-RETRY_PRIORITY_ADJUST"><code class="xref std std-setting docutils literal notranslate"><span class="pre">RETRY_PRIORITY_ADJUST</span></code></a>.</p>
</div>
</div>
<div class="section" id="depth-stats-verbose">
<span id="std:setting-DEPTH_STATS_VERBOSE"></span><h3>DEPTH_STATS_VERBOSE<a class="headerlink" href="#depth-stats-verbose" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>Scope: <code class="docutils literal notranslate"><span class="pre">scrapy.spidermiddlewares.depth.DepthMiddleware</span></code></p>
<p>Whether to collect verbose depth stats. If this is enabled, the number of
requests for each depth is collected in the stats.</p>
</div>
<div class="section" id="dnscache-enabled">
<span id="std:setting-DNSCACHE_ENABLED"></span><h3>DNSCACHE_ENABLED<a class="headerlink" href="#dnscache-enabled" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>Whether to enable DNS in-memory cache.</p>
</div>
<div class="section" id="dnscache-size">
<span id="std:setting-DNSCACHE_SIZE"></span><h3>DNSCACHE_SIZE<a class="headerlink" href="#dnscache-size" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">10000</span></code></p>
<p>DNS in-memory cache size.</p>
</div>
<div class="section" id="dns-timeout">
<span id="std:setting-DNS_TIMEOUT"></span><h3>DNS_TIMEOUT<a class="headerlink" href="#dns-timeout" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">60</span></code></p>
<p>Timeout for processing of DNS queries in seconds. Float is supported.</p>
</div>
<div class="section" id="downloader">
<span id="std:setting-DOWNLOADER"></span><h3>DOWNLOADER<a class="headerlink" href="#downloader" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">'scrapy.core.downloader.Downloader'</span></code></p>
<p>The downloader to use for crawling.</p>
</div>
<div class="section" id="downloader-httpclientfactory">
<span id="std:setting-DOWNLOADER_HTTPCLIENTFACTORY"></span><h3>DOWNLOADER_HTTPCLIENTFACTORY<a class="headerlink" href="#downloader-httpclientfactory" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">'scrapy.core.downloader.webclient.ScrapyHTTPClientFactory'</span></code></p>
<p>Defines a Twisted <code class="docutils literal notranslate"><span class="pre">protocol.ClientFactory</span></code>  class to use for HTTP/1.0
connections (for <code class="docutils literal notranslate"><span class="pre">HTTP10DownloadHandler</span></code>).</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">HTTP/1.0 is rarely used nowadays so you can safely ignore this setting,
unless you use Twisted&lt;11.1, or if you really want to use HTTP/1.0
and override <a class="reference internal" href="#std:setting-DOWNLOAD_HANDLERS_BASE"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_HANDLERS_BASE</span></code></a> for <code class="docutils literal notranslate"><span class="pre">http(s)</span></code> scheme
accordingly, i.e. to
<code class="docutils literal notranslate"><span class="pre">'scrapy.core.downloader.handlers.http.HTTP10DownloadHandler'</span></code>.</p>
</div>
</div>
<div class="section" id="downloader-clientcontextfactory">
<span id="std:setting-DOWNLOADER_CLIENTCONTEXTFACTORY"></span><h3>DOWNLOADER_CLIENTCONTEXTFACTORY<a class="headerlink" href="#downloader-clientcontextfactory" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">'scrapy.core.downloader.contextfactory.ScrapyClientContextFactory'</span></code></p>
<p>Represents the classpath to the ContextFactory to use.</p>
<p>Here, “ContextFactory” is a Twisted term for SSL/TLS contexts, defining
the TLS/SSL protocol version to use, whether to do certificate verification,
or even enable client-side authentication (and various other things).</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Scrapy default context factory <strong>does NOT perform remote server
certificate verification</strong>. This is usually fine for web scraping.</p>
<p class="last">If you do need remote server certificate verification enabled,
Scrapy also has another context factory class that you can set,
<code class="docutils literal notranslate"><span class="pre">'scrapy.core.downloader.contextfactory.BrowserLikeContextFactory'</span></code>,
which uses the platform’s certificates to validate remote endpoints.
<strong>This is only available if you use Twisted&gt;=14.0.</strong></p>
</div>
<p>If you do use a custom ContextFactory, make sure it accepts a <code class="docutils literal notranslate"><span class="pre">method</span></code>
parameter at init (this is the <code class="docutils literal notranslate"><span class="pre">OpenSSL.SSL</span></code> method mapping
<a class="reference internal" href="#std:setting-DOWNLOADER_CLIENT_TLS_METHOD"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOADER_CLIENT_TLS_METHOD</span></code></a>).</p>
</div>
<div class="section" id="downloader-client-tls-method">
<span id="std:setting-DOWNLOADER_CLIENT_TLS_METHOD"></span><h3>DOWNLOADER_CLIENT_TLS_METHOD<a class="headerlink" href="#downloader-client-tls-method" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">'TLS'</span></code></p>
<p>Use this setting to customize the TLS/SSL method used by the default
HTTP/1.1 downloader.</p>
<p>This setting must be one of these string values:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">'TLS'</span></code>: maps to OpenSSL’s <code class="docutils literal notranslate"><span class="pre">TLS_method()</span></code> (a.k.a <code class="docutils literal notranslate"><span class="pre">SSLv23_method()</span></code>),
which allows protocol negotiation, starting from the highest supported
by the platform; <strong>default, recommended</strong></li>
<li><code class="docutils literal notranslate"><span class="pre">'TLSv1.0'</span></code>: this value forces HTTPS connections to use TLS version 1.0 ;
set this if you want the behavior of Scrapy&lt;1.1</li>
<li><code class="docutils literal notranslate"><span class="pre">'TLSv1.1'</span></code>: forces TLS version 1.1</li>
<li><code class="docutils literal notranslate"><span class="pre">'TLSv1.2'</span></code>: forces TLS version 1.2</li>
<li><code class="docutils literal notranslate"><span class="pre">'SSLv3'</span></code>: forces SSL version 3 (<strong>not recommended</strong>)</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">We recommend that you use PyOpenSSL&gt;=0.13 and Twisted&gt;=0.13
or above (Twisted&gt;=14.0 if you can).</p>
</div>
</div>
<div class="section" id="downloader-middlewares">
<span id="std:setting-DOWNLOADER_MIDDLEWARES"></span><h3>DOWNLOADER_MIDDLEWARES<a class="headerlink" href="#downloader-middlewares" title="Permalink to this headline">¶</a></h3>
<p>Default:: <code class="docutils literal notranslate"><span class="pre">{}</span></code></p>
<p>A dict containing the downloader middlewares enabled in your project, and their
orders. For more info see <a class="reference internal" href="downloader-middleware.html#topics-downloader-middleware-setting"><span class="std std-ref">Activating a downloader middleware</span></a>.</p>
</div>
<div class="section" id="downloader-middlewares-base">
<span id="std:setting-DOWNLOADER_MIDDLEWARES_BASE"></span><h3>DOWNLOADER_MIDDLEWARES_BASE<a class="headerlink" href="#downloader-middlewares-base" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware'</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s1">'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware'</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
    <span class="s1">'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware'</span><span class="p">:</span> <span class="mi">350</span><span class="p">,</span>
    <span class="s1">'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware'</span><span class="p">:</span> <span class="mi">400</span><span class="p">,</span>
    <span class="s1">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span>
    <span class="s1">'scrapy.downloadermiddlewares.retry.RetryMiddleware'</span><span class="p">:</span> <span class="mi">550</span><span class="p">,</span>
    <span class="s1">'scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware'</span><span class="p">:</span> <span class="mi">560</span><span class="p">,</span>
    <span class="s1">'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware'</span><span class="p">:</span> <span class="mi">580</span><span class="p">,</span>
    <span class="s1">'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'</span><span class="p">:</span> <span class="mi">590</span><span class="p">,</span>
    <span class="s1">'scrapy.downloadermiddlewares.redirect.RedirectMiddleware'</span><span class="p">:</span> <span class="mi">600</span><span class="p">,</span>
    <span class="s1">'scrapy.downloadermiddlewares.cookies.CookiesMiddleware'</span><span class="p">:</span> <span class="mi">700</span><span class="p">,</span>
    <span class="s1">'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware'</span><span class="p">:</span> <span class="mi">750</span><span class="p">,</span>
    <span class="s1">'scrapy.downloadermiddlewares.stats.DownloaderStats'</span><span class="p">:</span> <span class="mi">850</span><span class="p">,</span>
    <span class="s1">'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware'</span><span class="p">:</span> <span class="mi">900</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>A dict containing the downloader middlewares enabled by default in Scrapy. Low
orders are closer to the engine, high orders are closer to the downloader. You
should never modify this setting in your project, modify
<a class="reference internal" href="#std:setting-DOWNLOADER_MIDDLEWARES"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOADER_MIDDLEWARES</span></code></a> instead.  For more info see
<a class="reference internal" href="downloader-middleware.html#topics-downloader-middleware-setting"><span class="std std-ref">Activating a downloader middleware</span></a>.</p>
</div>
<div class="section" id="downloader-stats">
<span id="std:setting-DOWNLOADER_STATS"></span><h3>DOWNLOADER_STATS<a class="headerlink" href="#downloader-stats" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>Whether to enable downloader stats collection.</p>
</div>
<div class="section" id="download-delay">
<span id="std:setting-DOWNLOAD_DELAY"></span><h3>DOWNLOAD_DELAY<a class="headerlink" href="#download-delay" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">0</span></code></p>
<p>The amount of time (in secs) that the downloader should wait before downloading
consecutive pages from the same website. This can be used to throttle the
crawling speed to avoid hitting servers too hard. Decimal numbers are
supported.  Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">DOWNLOAD_DELAY</span> <span class="o">=</span> <span class="mf">0.25</span>    <span class="c1"># 250 ms of delay</span>
</pre></div>
</div>
<p>This setting is also affected by the <a class="reference internal" href="#std:setting-RANDOMIZE_DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">RANDOMIZE_DOWNLOAD_DELAY</span></code></a>
setting (which is enabled by default). By default, Scrapy doesn’t wait a fixed
amount of time between requests, but uses a random interval between 0.5 * <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_DELAY</span></code></a> and 1.5 * <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_DELAY</span></code></a>.</p>
<p>When <a class="reference internal" href="#std:setting-CONCURRENT_REQUESTS_PER_IP"><code class="xref std std-setting docutils literal notranslate"><span class="pre">CONCURRENT_REQUESTS_PER_IP</span></code></a> is non-zero, delays are enforced
per ip address instead of per domain.</p>
<p>You can also change this setting per spider by setting <code class="docutils literal notranslate"><span class="pre">download_delay</span></code>
spider attribute.</p>
</div>
<div class="section" id="download-handlers">
<span id="std:setting-DOWNLOAD_HANDLERS"></span><h3>DOWNLOAD_HANDLERS<a class="headerlink" href="#download-handlers" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">{}</span></code></p>
<p>A dict containing the request downloader handlers enabled in your project.
See <a class="reference internal" href="#std:setting-DOWNLOAD_HANDLERS_BASE"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_HANDLERS_BASE</span></code></a> for example format.</p>
</div>
<div class="section" id="download-handlers-base">
<span id="std:setting-DOWNLOAD_HANDLERS_BASE"></span><h3>DOWNLOAD_HANDLERS_BASE<a class="headerlink" href="#download-handlers-base" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">'file'</span><span class="p">:</span> <span class="s1">'scrapy.core.downloader.handlers.file.FileDownloadHandler'</span><span class="p">,</span>
    <span class="s1">'http'</span><span class="p">:</span> <span class="s1">'scrapy.core.downloader.handlers.http.HTTPDownloadHandler'</span><span class="p">,</span>
    <span class="s1">'https'</span><span class="p">:</span> <span class="s1">'scrapy.core.downloader.handlers.http.HTTPDownloadHandler'</span><span class="p">,</span>
    <span class="s1">'s3'</span><span class="p">:</span> <span class="s1">'scrapy.core.downloader.handlers.s3.S3DownloadHandler'</span><span class="p">,</span>
    <span class="s1">'ftp'</span><span class="p">:</span> <span class="s1">'scrapy.core.downloader.handlers.ftp.FTPDownloadHandler'</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>A dict containing the request download handlers enabled by default in Scrapy.
You should never modify this setting in your project, modify
<a class="reference internal" href="#std:setting-DOWNLOAD_HANDLERS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_HANDLERS</span></code></a> instead.</p>
<p>You can disable any of these download handlers by assigning <code class="docutils literal notranslate"><span class="pre">None</span></code> to their
URI scheme in <a class="reference internal" href="#std:setting-DOWNLOAD_HANDLERS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_HANDLERS</span></code></a>. E.g., to disable the built-in FTP
handler (without replacement), place this in your <code class="docutils literal notranslate"><span class="pre">settings.py</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">DOWNLOAD_HANDLERS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'ftp'</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="download-timeout">
<span id="std:setting-DOWNLOAD_TIMEOUT"></span><h3>DOWNLOAD_TIMEOUT<a class="headerlink" href="#download-timeout" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">180</span></code></p>
<p>The amount of time (in secs) that the downloader will wait before timing out.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This timeout can be set per spider using <code class="xref py py-attr docutils literal notranslate"><span class="pre">download_timeout</span></code>
spider attribute and per-request using <a class="reference internal" href="request-response.html#std:reqmeta-download_timeout"><code class="xref std std-reqmeta docutils literal notranslate"><span class="pre">download_timeout</span></code></a>
Request.meta key.</p>
</div>
</div>
<div class="section" id="download-maxsize">
<span id="std:setting-DOWNLOAD_MAXSIZE"></span><h3>DOWNLOAD_MAXSIZE<a class="headerlink" href="#download-maxsize" title="Permalink to this headline">¶</a></h3>
<p>Default: <cite>1073741824</cite> (1024MB)</p>
<p>The maximum response size (in bytes) that downloader will download.</p>
<p>If you want to disable it set to 0.</p>
<div class="admonition note" id="std:reqmeta-download_maxsize">
<p class="first admonition-title">Note</p>
<p>This size can be set per spider using <code class="xref py py-attr docutils literal notranslate"><span class="pre">download_maxsize</span></code>
spider attribute and per-request using <a class="reference internal" href="#std:reqmeta-download_maxsize"><code class="xref std std-reqmeta docutils literal notranslate"><span class="pre">download_maxsize</span></code></a>
Request.meta key.</p>
<p class="last">This feature needs Twisted &gt;= 11.1.</p>
</div>
</div>
<div class="section" id="download-warnsize">
<span id="std:setting-DOWNLOAD_WARNSIZE"></span><h3>DOWNLOAD_WARNSIZE<a class="headerlink" href="#download-warnsize" title="Permalink to this headline">¶</a></h3>
<p>Default: <cite>33554432</cite> (32MB)</p>
<p>The response size (in bytes) that downloader will start to warn.</p>
<p>If you want to disable it set to 0.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>This size can be set per spider using <code class="xref py py-attr docutils literal notranslate"><span class="pre">download_warnsize</span></code>
spider attribute and per-request using <code class="xref std std-reqmeta docutils literal notranslate"><span class="pre">download_warnsize</span></code>
Request.meta key.</p>
<p class="last">This feature needs Twisted &gt;= 11.1.</p>
</div>
</div>
<div class="section" id="download-fail-on-dataloss">
<span id="std:setting-DOWNLOAD_FAIL_ON_DATALOSS"></span><h3>DOWNLOAD_FAIL_ON_DATALOSS<a class="headerlink" href="#download-fail-on-dataloss" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>Whether or not to fail on broken responses, that is, declared
<code class="docutils literal notranslate"><span class="pre">Content-Length</span></code> does not match content sent by the server or chunked
response was not properly finish. If <code class="docutils literal notranslate"><span class="pre">True</span></code>, these responses raise a
<code class="docutils literal notranslate"><span class="pre">ResponseFailed([_DataLoss])</span></code> error. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, these responses
are passed through and the flag <code class="docutils literal notranslate"><span class="pre">dataloss</span></code> is added to the response, i.e.:
<code class="docutils literal notranslate"><span class="pre">'dataloss'</span> <span class="pre">in</span> <span class="pre">response.flags</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p>Optionally, this can be set per-request basis by using the
<a class="reference internal" href="request-response.html#std:reqmeta-download_fail_on_dataloss"><code class="xref std std-reqmeta docutils literal notranslate"><span class="pre">download_fail_on_dataloss</span></code></a> Request.meta key to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">A broken response, or data loss error, may happen under several
circumstances, from server misconfiguration to network errors to data
corruption. It is up to the user to decide if it makes sense to process
broken responses considering they may contain partial or incomplete content.
If <a class="reference internal" href="downloader-middleware.html#std:setting-RETRY_ENABLED"><code class="xref std std-setting docutils literal notranslate"><span class="pre">RETRY_ENABLED</span></code></a> is <code class="docutils literal notranslate"><span class="pre">True</span></code> and this setting is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>,
the <code class="docutils literal notranslate"><span class="pre">ResponseFailed([_DataLoss])</span></code> failure will be retried as usual.</p>
</div>
</div>
<div class="section" id="dupefilter-class">
<span id="std:setting-DUPEFILTER_CLASS"></span><h3>DUPEFILTER_CLASS<a class="headerlink" href="#dupefilter-class" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">'scrapy.dupefilters.RFPDupeFilter'</span></code></p>
<p>The class used to detect and filter duplicate requests.</p>
<p>The default (<code class="docutils literal notranslate"><span class="pre">RFPDupeFilter</span></code>) filters based on request fingerprint using
the <code class="docutils literal notranslate"><span class="pre">scrapy.utils.request.request_fingerprint</span></code> function. In order to change
the way duplicates are checked you could subclass <code class="docutils literal notranslate"><span class="pre">RFPDupeFilter</span></code> and
override its <code class="docutils literal notranslate"><span class="pre">request_fingerprint</span></code> method. This method should accept
scrapy <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal notranslate"><span class="pre">Request</span></code></a> object and return its fingerprint
(a string).</p>
<p>You can disable filtering of duplicate requests by setting
<a class="reference internal" href="#std:setting-DUPEFILTER_CLASS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DUPEFILTER_CLASS</span></code></a> to <code class="docutils literal notranslate"><span class="pre">'scrapy.dupefilters.BaseDupeFilter'</span></code>.
Be very careful about this however, because you can get into crawling loops.
It’s usually a better idea to set the <code class="docutils literal notranslate"><span class="pre">dont_filter</span></code> parameter to
<code class="docutils literal notranslate"><span class="pre">True</span></code> on the specific <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal notranslate"><span class="pre">Request</span></code></a> that should not be
filtered.</p>
</div>
<div class="section" id="dupefilter-debug">
<span id="std:setting-DUPEFILTER_DEBUG"></span><h3>DUPEFILTER_DEBUG<a class="headerlink" href="#dupefilter-debug" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>By default, <code class="docutils literal notranslate"><span class="pre">RFPDupeFilter</span></code> only logs the first duplicate request.
Setting <a class="reference internal" href="#std:setting-DUPEFILTER_DEBUG"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DUPEFILTER_DEBUG</span></code></a> to <code class="docutils literal notranslate"><span class="pre">True</span></code> will make it log all duplicate requests.</p>
</div>
<div class="section" id="editor">
<span id="std:setting-EDITOR"></span><h3>EDITOR<a class="headerlink" href="#editor" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">vi</span></code> (on Unix systems) or the IDLE editor (on Windows)</p>
<p>The editor to use for editing spiders with the <a class="reference internal" href="commands.html#std:command-edit"><code class="xref std std-command docutils literal notranslate"><span class="pre">edit</span></code></a> command.
Additionally, if the <code class="docutils literal notranslate"><span class="pre">EDITOR</span></code> environment variable is set, the <a class="reference internal" href="commands.html#std:command-edit"><code class="xref std std-command docutils literal notranslate"><span class="pre">edit</span></code></a>
command will prefer it over the default setting.</p>
</div>
<div class="section" id="extensions">
<span id="std:setting-EXTENSIONS"></span><h3>EXTENSIONS<a class="headerlink" href="#extensions" title="Permalink to this headline">¶</a></h3>
<p>Default:: <code class="docutils literal notranslate"><span class="pre">{}</span></code></p>
<p>A dict containing the extensions enabled in your project, and their orders.</p>
</div>
<div class="section" id="extensions-base">
<span id="std:setting-EXTENSIONS_BASE"></span><h3>EXTENSIONS_BASE<a class="headerlink" href="#extensions-base" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">'scrapy.extensions.corestats.CoreStats'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.extensions.telnet.TelnetConsole'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.extensions.memusage.MemoryUsage'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.extensions.memdebug.MemoryDebugger'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.extensions.closespider.CloseSpider'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.extensions.feedexport.FeedExporter'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.extensions.logstats.LogStats'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.extensions.spiderstate.SpiderState'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.extensions.throttle.AutoThrottle'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>A dict containing the extensions available by default in Scrapy, and their
orders. This setting contains all stable built-in extensions. Keep in mind that
some of them need to be enabled through a setting.</p>
<p>For more information See the <a class="reference internal" href="extensions.html#topics-extensions"><span class="std std-ref">extensions user guide</span></a>
and the <a class="reference internal" href="extensions.html#topics-extensions-ref"><span class="std std-ref">list of available extensions</span></a>.</p>
</div>
<div class="section" id="feed-tempdir">
<span id="std:setting-FEED_TEMPDIR"></span><h3>FEED_TEMPDIR<a class="headerlink" href="#feed-tempdir" title="Permalink to this headline">¶</a></h3>
<p>The Feed Temp dir allows you to set a custom folder to save crawler
temporary files before uploading with <a class="reference internal" href="feed-exports.html#topics-feed-storage-ftp"><span class="std std-ref">FTP feed storage</span></a> and
<a class="reference internal" href="feed-exports.html#topics-feed-storage-s3"><span class="std std-ref">Amazon S3</span></a>.</p>
</div>
<div class="section" id="ftp-passive-mode">
<span id="std:setting-FTP_PASSIVE_MODE"></span><h3>FTP_PASSIVE_MODE<a class="headerlink" href="#ftp-passive-mode" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>Whether or not to use passive mode when initiating FTP transfers.</p>
</div>
<div class="section" id="ftp-password">
<span id="std:setting-FTP_PASSWORD"></span><h3>FTP_PASSWORD<a class="headerlink" href="#ftp-password" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">"guest"</span></code></p>
<p>The password to use for FTP connections when there is no <code class="docutils literal notranslate"><span class="pre">"ftp_password"</span></code>
in <code class="docutils literal notranslate"><span class="pre">Request</span></code> meta.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Paraphrasing <a class="reference external" href="https://tools.ietf.org/html/rfc1635">RFC 1635</a>, although it is common to use either the password
“guest” or one’s e-mail address for anonymous FTP,
some FTP servers explicitly ask for the user’s e-mail address
and will not allow login with the “guest” password.</p>
</div>
</div>
<div class="section" id="ftp-user">
<span id="std:setting-FTP_USER"></span><h3>FTP_USER<a class="headerlink" href="#ftp-user" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">"anonymous"</span></code></p>
<p>The username to use for FTP connections when there is no <code class="docutils literal notranslate"><span class="pre">"ftp_user"</span></code>
in <code class="docutils literal notranslate"><span class="pre">Request</span></code> meta.</p>
</div>
<div class="section" id="item-pipelines">
<span id="std:setting-ITEM_PIPELINES"></span><h3>ITEM_PIPELINES<a class="headerlink" href="#item-pipelines" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">{}</span></code></p>
<p>A dict containing the item pipelines to use, and their orders. Order values are
arbitrary, but it is customary to define them in the 0-1000 range. Lower orders
process before higher orders.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'mybot.pipelines.validate.ValidateMyItem'</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
    <span class="s1">'mybot.pipelines.validate.StoreMyItem'</span><span class="p">:</span> <span class="mi">800</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="item-pipelines-base">
<span id="std:setting-ITEM_PIPELINES_BASE"></span><h3>ITEM_PIPELINES_BASE<a class="headerlink" href="#item-pipelines-base" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">{}</span></code></p>
<p>A dict containing the pipelines enabled by default in Scrapy. You should never
modify this setting in your project, modify <a class="reference internal" href="#std:setting-ITEM_PIPELINES"><code class="xref std std-setting docutils literal notranslate"><span class="pre">ITEM_PIPELINES</span></code></a> instead.</p>
</div>
<div class="section" id="log-enabled">
<span id="std:setting-LOG_ENABLED"></span><h3>LOG_ENABLED<a class="headerlink" href="#log-enabled" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>Whether to enable logging.</p>
</div>
<div class="section" id="log-encoding">
<span id="std:setting-LOG_ENCODING"></span><h3>LOG_ENCODING<a class="headerlink" href="#log-encoding" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">'utf-8'</span></code></p>
<p>The encoding to use for logging.</p>
</div>
<div class="section" id="log-file">
<span id="std:setting-LOG_FILE"></span><h3>LOG_FILE<a class="headerlink" href="#log-file" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
<p>File name to use for logging output. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, standard error will be used.</p>
</div>
<div class="section" id="log-format">
<span id="std:setting-LOG_FORMAT"></span><h3>LOG_FORMAT<a class="headerlink" href="#log-format" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">'%(asctime)s</span> <span class="pre">[%(name)s]</span> <span class="pre">%(levelname)s:</span> <span class="pre">%(message)s'</span></code></p>
<p>String for formatting log messsages. Refer to the <a class="reference external" href="https://docs.python.org/2/library/logging.html#logrecord-attributes">Python logging documentation</a> for the whole list of available
placeholders.</p>
</div>
<div class="section" id="log-dateformat">
<span id="std:setting-LOG_DATEFORMAT"></span><h3>LOG_DATEFORMAT<a class="headerlink" href="#log-dateformat" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">'%Y-%m-%d</span> <span class="pre">%H:%M:%S'</span></code></p>
<p>String for formatting date/time, expansion of the <code class="docutils literal notranslate"><span class="pre">%(asctime)s</span></code> placeholder
in <a class="reference internal" href="#std:setting-LOG_FORMAT"><code class="xref std std-setting docutils literal notranslate"><span class="pre">LOG_FORMAT</span></code></a>. Refer to the <a class="reference external" href="https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior">Python datetime documentation</a> for the whole list of available
directives.</p>
</div>
<div class="section" id="log-level">
<span id="std:setting-LOG_LEVEL"></span><h3>LOG_LEVEL<a class="headerlink" href="#log-level" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">'DEBUG'</span></code></p>
<p>Minimum level to log. Available levels are: CRITICAL, ERROR, WARNING,
INFO, DEBUG. For more info see <a class="reference internal" href="logging.html#topics-logging"><span class="std std-ref">Logging</span></a>.</p>
</div>
<div class="section" id="log-stdout">
<span id="std:setting-LOG_STDOUT"></span><h3>LOG_STDOUT<a class="headerlink" href="#log-stdout" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, all standard output (and error) of your process will be redirected
to the log. For example if you <code class="docutils literal notranslate"><span class="pre">print('hello')</span></code> it will appear in the Scrapy
log.</p>
</div>
<div class="section" id="log-short-names">
<span id="std:setting-LOG_SHORT_NAMES"></span><h3>LOG_SHORT_NAMES<a class="headerlink" href="#log-short-names" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the logs will just contain the root path. If it is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>
then it displays the component responsible for the log output</p>
</div>
<div class="section" id="memdebug-enabled">
<span id="std:setting-MEMDEBUG_ENABLED"></span><h3>MEMDEBUG_ENABLED<a class="headerlink" href="#memdebug-enabled" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>Whether to enable memory debugging.</p>
</div>
<div class="section" id="memdebug-notify">
<span id="std:setting-MEMDEBUG_NOTIFY"></span><h3>MEMDEBUG_NOTIFY<a class="headerlink" href="#memdebug-notify" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">[]</span></code></p>
<p>When memory debugging is enabled a memory report will be sent to the specified
addresses if this setting is not empty, otherwise the report will be written to
the log.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">MEMDEBUG_NOTIFY</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'user@example.com'</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="memusage-enabled">
<span id="std:setting-MEMUSAGE_ENABLED"></span><h3>MEMUSAGE_ENABLED<a class="headerlink" href="#memusage-enabled" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>Scope: <code class="docutils literal notranslate"><span class="pre">scrapy.extensions.memusage</span></code></p>
<p>Whether to enable the memory usage extension. This extension keeps track of
a peak memory used by the process (it writes it to stats). It can also
optionally shutdown the Scrapy process when it exceeds a memory limit
(see <a class="reference internal" href="#std:setting-MEMUSAGE_LIMIT_MB"><code class="xref std std-setting docutils literal notranslate"><span class="pre">MEMUSAGE_LIMIT_MB</span></code></a>), and notify by email when that happened
(see <a class="reference internal" href="#std:setting-MEMUSAGE_NOTIFY_MAIL"><code class="xref std std-setting docutils literal notranslate"><span class="pre">MEMUSAGE_NOTIFY_MAIL</span></code></a>).</p>
<p>See <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><span class="std std-ref">Memory usage extension</span></a>.</p>
</div>
<div class="section" id="memusage-limit-mb">
<span id="std:setting-MEMUSAGE_LIMIT_MB"></span><h3>MEMUSAGE_LIMIT_MB<a class="headerlink" href="#memusage-limit-mb" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">0</span></code></p>
<p>Scope: <code class="docutils literal notranslate"><span class="pre">scrapy.extensions.memusage</span></code></p>
<p>The maximum amount of memory to allow (in megabytes) before shutting down
Scrapy  (if MEMUSAGE_ENABLED is True). If zero, no check will be performed.</p>
<p>See <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><span class="std std-ref">Memory usage extension</span></a>.</p>
</div>
<div class="section" id="memusage-check-interval-seconds">
<span id="std:setting-MEMUSAGE_CHECK_INTERVAL_SECONDS"></span><h3>MEMUSAGE_CHECK_INTERVAL_SECONDS<a class="headerlink" href="#memusage-check-interval-seconds" title="Permalink to this headline">¶</a></h3>
<div class="versionadded">
<p><span class="versionmodified">New in version 1.1.</span></p>
</div>
<p>Default: <code class="docutils literal notranslate"><span class="pre">60.0</span></code></p>
<p>Scope: <code class="docutils literal notranslate"><span class="pre">scrapy.extensions.memusage</span></code></p>
<p>The <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><span class="std std-ref">Memory usage extension</span></a>
checks the current memory usage, versus the limits set by
<a class="reference internal" href="#std:setting-MEMUSAGE_LIMIT_MB"><code class="xref std std-setting docutils literal notranslate"><span class="pre">MEMUSAGE_LIMIT_MB</span></code></a> and <a class="reference internal" href="#std:setting-MEMUSAGE_WARNING_MB"><code class="xref std std-setting docutils literal notranslate"><span class="pre">MEMUSAGE_WARNING_MB</span></code></a>,
at fixed time intervals.</p>
<p>This sets the length of these intervals, in seconds.</p>
<p>See <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><span class="std std-ref">Memory usage extension</span></a>.</p>
</div>
<div class="section" id="memusage-notify-mail">
<span id="std:setting-MEMUSAGE_NOTIFY_MAIL"></span><h3>MEMUSAGE_NOTIFY_MAIL<a class="headerlink" href="#memusage-notify-mail" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>Scope: <code class="docutils literal notranslate"><span class="pre">scrapy.extensions.memusage</span></code></p>
<p>A list of emails to notify if the memory limit has been reached.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">MEMUSAGE_NOTIFY_MAIL</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'user@example.com'</span><span class="p">]</span>
</pre></div>
</div>
<p>See <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><span class="std std-ref">Memory usage extension</span></a>.</p>
</div>
<div class="section" id="memusage-warning-mb">
<span id="std:setting-MEMUSAGE_WARNING_MB"></span><h3>MEMUSAGE_WARNING_MB<a class="headerlink" href="#memusage-warning-mb" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">0</span></code></p>
<p>Scope: <code class="docutils literal notranslate"><span class="pre">scrapy.extensions.memusage</span></code></p>
<p>The maximum amount of memory to allow (in megabytes) before sending a warning
email notifying about it. If zero, no warning will be produced.</p>
</div>
<div class="section" id="newspider-module">
<span id="std:setting-NEWSPIDER_MODULE"></span><h3>NEWSPIDER_MODULE<a class="headerlink" href="#newspider-module" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">''</span></code></p>
<p>Module where to create new spiders using the <a class="reference internal" href="commands.html#std:command-genspider"><code class="xref std std-command docutils literal notranslate"><span class="pre">genspider</span></code></a> command.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">NEWSPIDER_MODULE</span> <span class="o">=</span> <span class="s1">'mybot.spiders_dev'</span>
</pre></div>
</div>
</div>
<div class="section" id="randomize-download-delay">
<span id="std:setting-RANDOMIZE_DOWNLOAD_DELAY"></span><h3>RANDOMIZE_DOWNLOAD_DELAY<a class="headerlink" href="#randomize-download-delay" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>If enabled, Scrapy will wait a random amount of time (between 0.5 * <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_DELAY</span></code></a> and 1.5 * <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_DELAY</span></code></a>) while fetching requests from the same
website.</p>
<p>This randomization decreases the chance of the crawler being detected (and
subsequently blocked) by sites which analyze requests looking for statistically
significant similarities in the time between their requests.</p>
<p>The randomization policy is the same used by <a class="reference external" href="https://www.gnu.org/software/wget/manual/wget.html">wget</a> <code class="docutils literal notranslate"><span class="pre">--random-wait</span></code> option.</p>
<p>If <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DOWNLOAD_DELAY</span></code></a> is zero (default) this option has no effect.</p>
</div>
<div class="section" id="reactor-threadpool-maxsize">
<span id="std:setting-REACTOR_THREADPOOL_MAXSIZE"></span><h3>REACTOR_THREADPOOL_MAXSIZE<a class="headerlink" href="#reactor-threadpool-maxsize" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">10</span></code></p>
<p>The maximum limit for Twisted Reactor thread pool size. This is common
multi-purpose thread pool used by various Scrapy components. Threaded
DNS Resolver, BlockingFeedStorage, S3FilesStore just to name a few. Increase
this value if you’re experiencing problems with insufficient blocking IO.</p>
</div>
<div class="section" id="redirect-max-times">
<span id="std:setting-REDIRECT_MAX_TIMES"></span><h3>REDIRECT_MAX_TIMES<a class="headerlink" href="#redirect-max-times" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">20</span></code></p>
<p>Defines the maximum times a request can be redirected. After this maximum the
request’s response is returned as is. We used Firefox default value for the
same task.</p>
</div>
<div class="section" id="redirect-priority-adjust">
<span id="std:setting-REDIRECT_PRIORITY_ADJUST"></span><h3>REDIRECT_PRIORITY_ADJUST<a class="headerlink" href="#redirect-priority-adjust" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">+2</span></code></p>
<p>Scope: <code class="docutils literal notranslate"><span class="pre">scrapy.downloadermiddlewares.redirect.RedirectMiddleware</span></code></p>
<p>Adjust redirect request priority relative to original request:</p>
<ul class="simple">
<li><strong>a positive priority adjust (default) means higher priority.</strong></li>
<li>a negative priority adjust means lower priority.</li>
</ul>
</div>
<div class="section" id="retry-priority-adjust">
<span id="std:setting-RETRY_PRIORITY_ADJUST"></span><h3>RETRY_PRIORITY_ADJUST<a class="headerlink" href="#retry-priority-adjust" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">-1</span></code></p>
<p>Scope: <code class="docutils literal notranslate"><span class="pre">scrapy.downloadermiddlewares.retry.RetryMiddleware</span></code></p>
<p>Adjust retry request priority relative to original request:</p>
<ul class="simple">
<li>a positive priority adjust means higher priority.</li>
<li><strong>a negative priority adjust (default) means lower priority.</strong></li>
</ul>
</div>
<div class="section" id="robotstxt-obey">
<span id="std:setting-ROBOTSTXT_OBEY"></span><h3>ROBOTSTXT_OBEY<a class="headerlink" href="#robotstxt-obey" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>Scope: <code class="docutils literal notranslate"><span class="pre">scrapy.downloadermiddlewares.robotstxt</span></code></p>
<p>If enabled, Scrapy will respect robots.txt policies. For more information see
<a class="reference internal" href="downloader-middleware.html#topics-dlmw-robots"><span class="std std-ref">RobotsTxtMiddleware</span></a>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">While the default value is <code class="docutils literal notranslate"><span class="pre">False</span></code> for historical reasons,
this option is enabled by default in settings.py file generated
by <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">startproject</span></code> command.</p>
</div>
</div>
<div class="section" id="scheduler">
<span id="std:setting-SCHEDULER"></span><h3>SCHEDULER<a class="headerlink" href="#scheduler" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">'scrapy.core.scheduler.Scheduler'</span></code></p>
<p>The scheduler to use for crawling.</p>
</div>
<div class="section" id="scheduler-debug">
<span id="std:setting-SCHEDULER_DEBUG"></span><h3>SCHEDULER_DEBUG<a class="headerlink" href="#scheduler-debug" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>Setting to <code class="docutils literal notranslate"><span class="pre">True</span></code> will log debug information about the requests scheduler.
This currently logs (only once) if the requests cannot be serialized to disk.
Stats counter (<code class="docutils literal notranslate"><span class="pre">scheduler/unserializable</span></code>) tracks the number of times this happens.</p>
<p>Example entry in logs:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="mi">1956</span><span class="o">-</span><span class="mo">01</span><span class="o">-</span><span class="mi">31</span> <span class="mo">00</span><span class="p">:</span><span class="mo">00</span><span class="p">:</span><span class="mo">00</span><span class="o">+</span><span class="mi">0800</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">scheduler</span><span class="p">]</span> <span class="n">ERROR</span><span class="p">:</span> <span class="n">Unable</span> <span class="n">to</span> <span class="n">serialize</span> <span class="n">request</span><span class="p">:</span>
<span class="o">&lt;</span><span class="n">GET</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">example</span><span class="o">.</span><span class="n">com</span><span class="o">&gt;</span> <span class="o">-</span> <span class="n">reason</span><span class="p">:</span> <span class="n">cannot</span> <span class="n">serialize</span> <span class="o">&lt;</span><span class="n">Request</span> <span class="n">at</span> <span class="mh">0x9a7c7ec</span><span class="o">&gt;</span>
<span class="p">(</span><span class="nb">type</span> <span class="n">Request</span><span class="p">)</span><span class="o">&gt;</span> <span class="o">-</span> <span class="n">no</span> <span class="n">more</span> <span class="n">unserializable</span> <span class="n">requests</span> <span class="n">will</span> <span class="n">be</span> <span class="n">logged</span>
<span class="p">(</span><span class="n">see</span> <span class="s1">'scheduler/unserializable'</span> <span class="n">stats</span> <span class="n">counter</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="scheduler-disk-queue">
<span id="std:setting-SCHEDULER_DISK_QUEUE"></span><h3>SCHEDULER_DISK_QUEUE<a class="headerlink" href="#scheduler-disk-queue" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">'scrapy.squeues.PickleLifoDiskQueue'</span></code></p>
<p>Type of disk queue that will be used by scheduler. Other available types are
<code class="docutils literal notranslate"><span class="pre">scrapy.squeues.PickleFifoDiskQueue</span></code>, <code class="docutils literal notranslate"><span class="pre">scrapy.squeues.MarshalFifoDiskQueue</span></code>,
<code class="docutils literal notranslate"><span class="pre">scrapy.squeues.MarshalLifoDiskQueue</span></code>.</p>
</div>
<div class="section" id="scheduler-memory-queue">
<span id="std:setting-SCHEDULER_MEMORY_QUEUE"></span><h3>SCHEDULER_MEMORY_QUEUE<a class="headerlink" href="#scheduler-memory-queue" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">'scrapy.squeues.LifoMemoryQueue'</span></code></p>
<p>Type of in-memory queue used by scheduler. Other available type is:
<code class="docutils literal notranslate"><span class="pre">scrapy.squeues.FifoMemoryQueue</span></code>.</p>
</div>
<div class="section" id="scheduler-priority-queue">
<span id="std:setting-SCHEDULER_PRIORITY_QUEUE"></span><h3>SCHEDULER_PRIORITY_QUEUE<a class="headerlink" href="#scheduler-priority-queue" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">'queuelib.PriorityQueue'</span></code></p>
<p>Type of priority queue used by scheduler.</p>
</div>
<div class="section" id="spider-contracts">
<span id="std:setting-SPIDER_CONTRACTS"></span><h3>SPIDER_CONTRACTS<a class="headerlink" href="#spider-contracts" title="Permalink to this headline">¶</a></h3>
<p>Default:: <code class="docutils literal notranslate"><span class="pre">{}</span></code></p>
<p>A dict containing the spider contracts enabled in your project, used for
testing spiders. For more info see <a class="reference internal" href="contracts.html#topics-contracts"><span class="std std-ref">Spiders Contracts</span></a>.</p>
</div>
<div class="section" id="spider-contracts-base">
<span id="std:setting-SPIDER_CONTRACTS_BASE"></span><h3>SPIDER_CONTRACTS_BASE<a class="headerlink" href="#spider-contracts-base" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">'scrapy.contracts.default.UrlContract'</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">'scrapy.contracts.default.ReturnsContract'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s1">'scrapy.contracts.default.ScrapesContract'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>A dict containing the scrapy contracts enabled by default in Scrapy. You should
never modify this setting in your project, modify <a class="reference internal" href="#std:setting-SPIDER_CONTRACTS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">SPIDER_CONTRACTS</span></code></a>
instead. For more info see <a class="reference internal" href="contracts.html#topics-contracts"><span class="std std-ref">Spiders Contracts</span></a>.</p>
<p>You can disable any of these contracts by assigning <code class="docutils literal notranslate"><span class="pre">None</span></code> to their class
path in <a class="reference internal" href="#std:setting-SPIDER_CONTRACTS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">SPIDER_CONTRACTS</span></code></a>. E.g., to disable the built-in
<code class="docutils literal notranslate"><span class="pre">ScrapesContract</span></code>, place this in your <code class="docutils literal notranslate"><span class="pre">settings.py</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">SPIDER_CONTRACTS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'scrapy.contracts.default.ScrapesContract'</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="spider-loader-class">
<span id="std:setting-SPIDER_LOADER_CLASS"></span><h3>SPIDER_LOADER_CLASS<a class="headerlink" href="#spider-loader-class" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">'scrapy.spiderloader.SpiderLoader'</span></code></p>
<p>The class that will be used for loading spiders, which must implement the
<a class="reference internal" href="api.html#topics-api-spiderloader"><span class="std std-ref">SpiderLoader API</span></a>.</p>
</div>
<div class="section" id="spider-loader-warn-only">
<span id="std:setting-SPIDER_LOADER_WARN_ONLY"></span><h3>SPIDER_LOADER_WARN_ONLY<a class="headerlink" href="#spider-loader-warn-only" title="Permalink to this headline">¶</a></h3>
<div class="versionadded">
<p><span class="versionmodified">New in version 1.3.3.</span></p>
</div>
<p>Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
<p>By default, when scrapy tries to import spider classes from <a class="reference internal" href="#std:setting-SPIDER_MODULES"><code class="xref std std-setting docutils literal notranslate"><span class="pre">SPIDER_MODULES</span></code></a>,
it will fail loudly if there is any <code class="docutils literal notranslate"><span class="pre">ImportError</span></code> exception.
But you can choose to silence this exception and turn it into a simple
warning by setting <code class="docutils literal notranslate"><span class="pre">SPIDER_LOADER_WARN_ONLY</span> <span class="pre">=</span> <span class="pre">True</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Some <a class="reference internal" href="commands.html#topics-commands"><span class="std std-ref">scrapy commands</span></a> run with this setting to <code class="docutils literal notranslate"><span class="pre">True</span></code>
already (i.e. they will only issue a warning and will not fail)
since they do not actually need to load spider classes to work:
<a class="reference internal" href="commands.html#std:command-runspider"><code class="xref std std-command docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">runspider</span></code></a>,
<a class="reference internal" href="commands.html#std:command-settings"><code class="xref std std-command docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">settings</span></code></a>,
<a class="reference internal" href="commands.html#std:command-startproject"><code class="xref std std-command docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">startproject</span></code></a>,
<a class="reference internal" href="commands.html#std:command-version"><code class="xref std std-command docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">version</span></code></a>.</p>
</div>
</div>
<div class="section" id="spider-middlewares">
<span id="std:setting-SPIDER_MIDDLEWARES"></span><h3>SPIDER_MIDDLEWARES<a class="headerlink" href="#spider-middlewares" title="Permalink to this headline">¶</a></h3>
<p>Default:: <code class="docutils literal notranslate"><span class="pre">{}</span></code></p>
<p>A dict containing the spider middlewares enabled in your project, and their
orders. For more info see <a class="reference internal" href="spider-middleware.html#topics-spider-middleware-setting"><span class="std std-ref">Activating a spider middleware</span></a>.</p>
</div>
<div class="section" id="spider-middlewares-base">
<span id="std:setting-SPIDER_MIDDLEWARES_BASE"></span><h3>SPIDER_MIDDLEWARES_BASE<a class="headerlink" href="#spider-middlewares-base" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware'</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
    <span class="s1">'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span>
    <span class="s1">'scrapy.spidermiddlewares.referer.RefererMiddleware'</span><span class="p">:</span> <span class="mi">700</span><span class="p">,</span>
    <span class="s1">'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware'</span><span class="p">:</span> <span class="mi">800</span><span class="p">,</span>
    <span class="s1">'scrapy.spidermiddlewares.depth.DepthMiddleware'</span><span class="p">:</span> <span class="mi">900</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>A dict containing the spider middlewares enabled by default in Scrapy, and
their orders. Low orders are closer to the engine, high orders are closer to
the spider. For more info see <a class="reference internal" href="spider-middleware.html#topics-spider-middleware-setting"><span class="std std-ref">Activating a spider middleware</span></a>.</p>
</div>
<div class="section" id="spider-modules">
<span id="std:setting-SPIDER_MODULES"></span><h3>SPIDER_MODULES<a class="headerlink" href="#spider-modules" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">[]</span></code></p>
<p>A list of modules where Scrapy will look for spiders.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">SPIDER_MODULES</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'mybot.spiders_prod'</span><span class="p">,</span> <span class="s1">'mybot.spiders_dev'</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="stats-class">
<span id="std:setting-STATS_CLASS"></span><h3>STATS_CLASS<a class="headerlink" href="#stats-class" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">'scrapy.statscollectors.MemoryStatsCollector'</span></code></p>
<p>The class to use for collecting stats, who must implement the
<a class="reference internal" href="api.html#topics-api-stats"><span class="std std-ref">Stats Collector API</span></a>.</p>
</div>
<div class="section" id="stats-dump">
<span id="std:setting-STATS_DUMP"></span><h3>STATS_DUMP<a class="headerlink" href="#stats-dump" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>Dump the <a class="reference internal" href="stats.html#topics-stats"><span class="std std-ref">Scrapy stats</span></a> (to the Scrapy log) once the spider
finishes.</p>
<p>For more info see: <a class="reference internal" href="stats.html#topics-stats"><span class="std std-ref">Stats Collection</span></a>.</p>
</div>
<div class="section" id="statsmailer-rcpts">
<span id="std:setting-STATSMAILER_RCPTS"></span><h3>STATSMAILER_RCPTS<a class="headerlink" href="#statsmailer-rcpts" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">[]</span></code> (empty list)</p>
<p>Send Scrapy stats after spiders finish scraping. See
<code class="xref py py-class docutils literal notranslate"><span class="pre">StatsMailer</span></code> for more info.</p>
</div>
<div class="section" id="telnetconsole-enabled">
<span id="std:setting-TELNETCONSOLE_ENABLED"></span><h3>TELNETCONSOLE_ENABLED<a class="headerlink" href="#telnetconsole-enabled" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
<p>A boolean which specifies if the <a class="reference internal" href="telnetconsole.html#topics-telnetconsole"><span class="std std-ref">telnet console</span></a>
will be enabled (provided its extension is also enabled).</p>
</div>
<div class="section" id="telnetconsole-port">
<span id="std:setting-TELNETCONSOLE_PORT"></span><h3>TELNETCONSOLE_PORT<a class="headerlink" href="#telnetconsole-port" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">[6023,</span> <span class="pre">6073]</span></code></p>
<p>The port range to use for the telnet console. If set to <code class="docutils literal notranslate"><span class="pre">None</span></code> or <code class="docutils literal notranslate"><span class="pre">0</span></code>, a
dynamically assigned port is used. For more info see
<a class="reference internal" href="telnetconsole.html#topics-telnetconsole"><span class="std std-ref">Telnet Console</span></a>.</p>
</div>
<div class="section" id="templates-dir">
<span id="std:setting-TEMPLATES_DIR"></span><h3>TEMPLATES_DIR<a class="headerlink" href="#templates-dir" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">templates</span></code> dir inside scrapy module</p>
<p>The directory where to look for templates when creating new projects with
<a class="reference internal" href="commands.html#std:command-startproject"><code class="xref std std-command docutils literal notranslate"><span class="pre">startproject</span></code></a> command and new spiders with <a class="reference internal" href="commands.html#std:command-genspider"><code class="xref std std-command docutils literal notranslate"><span class="pre">genspider</span></code></a>
command.</p>
<p>The project name must not conflict with the name of custom files or directories
in the <code class="docutils literal notranslate"><span class="pre">project</span></code> subdirectory.</p>
</div>
<div class="section" id="urllength-limit">
<span id="std:setting-URLLENGTH_LIMIT"></span><h3>URLLENGTH_LIMIT<a class="headerlink" href="#urllength-limit" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">2083</span></code></p>
<p>Scope: <code class="docutils literal notranslate"><span class="pre">spidermiddlewares.urllength</span></code></p>
<p>The maximum URL length to allow for crawled URLs. For more information about
the default value for this setting see: <a class="reference external" href="https://boutell.com/newfaq/misc/urllength.html">https://boutell.com/newfaq/misc/urllength.html</a></p>
</div>
<div class="section" id="user-agent">
<span id="std:setting-USER_AGENT"></span><h3>USER_AGENT<a class="headerlink" href="#user-agent" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">"Scrapy/VERSION</span> <span class="pre">(+https://scrapy.org)"</span></code></p>
<p>The default User-Agent to use when crawling, unless overridden.</p>
</div>
<div class="section" id="settings-documented-elsewhere">
<h3>Settings documented elsewhere:<a class="headerlink" href="#settings-documented-elsewhere" title="Permalink to this headline">¶</a></h3>
<p>The following settings are documented elsewhere, please check each specific
case to see how to enable and use them.</p>
<ul class="simple">
<li><a class="reference internal" href="downloader-middleware.html#std:setting-AJAXCRAWL_ENABLED">AJAXCRAWL_ENABLED</a></li>
<li><a class="reference internal" href="autothrottle.html#std:setting-AUTOTHROTTLE_DEBUG">AUTOTHROTTLE_DEBUG</a></li>
<li><a class="reference internal" href="autothrottle.html#std:setting-AUTOTHROTTLE_ENABLED">AUTOTHROTTLE_ENABLED</a></li>
<li><a class="reference internal" href="autothrottle.html#std:setting-AUTOTHROTTLE_MAX_DELAY">AUTOTHROTTLE_MAX_DELAY</a></li>
<li><a class="reference internal" href="autothrottle.html#std:setting-AUTOTHROTTLE_START_DELAY">AUTOTHROTTLE_START_DELAY</a></li>
<li><a class="reference internal" href="autothrottle.html#std:setting-AUTOTHROTTLE_TARGET_CONCURRENCY">AUTOTHROTTLE_TARGET_CONCURRENCY</a></li>
<li><a class="reference internal" href="extensions.html#std:setting-CLOSESPIDER_ERRORCOUNT">CLOSESPIDER_ERRORCOUNT</a></li>
<li><a class="reference internal" href="extensions.html#std:setting-CLOSESPIDER_ITEMCOUNT">CLOSESPIDER_ITEMCOUNT</a></li>
<li><a class="reference internal" href="extensions.html#std:setting-CLOSESPIDER_PAGECOUNT">CLOSESPIDER_PAGECOUNT</a></li>
<li><a class="reference internal" href="extensions.html#std:setting-CLOSESPIDER_TIMEOUT">CLOSESPIDER_TIMEOUT</a></li>
<li><a class="reference internal" href="commands.html#std:setting-COMMANDS_MODULE">COMMANDS_MODULE</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-COMPRESSION_ENABLED">COMPRESSION_ENABLED</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-COOKIES_DEBUG">COOKIES_DEBUG</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-COOKIES_ENABLED">COOKIES_ENABLED</a></li>
<li><a class="reference internal" href="feed-exports.html#std:setting-FEED_EXPORTERS">FEED_EXPORTERS</a></li>
<li><a class="reference internal" href="feed-exports.html#std:setting-FEED_EXPORTERS_BASE">FEED_EXPORTERS_BASE</a></li>
<li><a class="reference internal" href="feed-exports.html#std:setting-FEED_EXPORT_ENCODING">FEED_EXPORT_ENCODING</a></li>
<li><a class="reference internal" href="feed-exports.html#std:setting-FEED_EXPORT_FIELDS">FEED_EXPORT_FIELDS</a></li>
<li><a class="reference internal" href="feed-exports.html#std:setting-FEED_EXPORT_INDENT">FEED_EXPORT_INDENT</a></li>
<li><a class="reference internal" href="feed-exports.html#std:setting-FEED_FORMAT">FEED_FORMAT</a></li>
<li><a class="reference internal" href="feed-exports.html#std:setting-FEED_STORAGES">FEED_STORAGES</a></li>
<li><a class="reference internal" href="feed-exports.html#std:setting-FEED_STORAGES_BASE">FEED_STORAGES_BASE</a></li>
<li><a class="reference internal" href="feed-exports.html#std:setting-FEED_STORE_EMPTY">FEED_STORE_EMPTY</a></li>
<li><a class="reference internal" href="feed-exports.html#std:setting-FEED_URI">FEED_URI</a></li>
<li><a class="reference internal" href="media-pipeline.html#std:setting-FILES_EXPIRES">FILES_EXPIRES</a></li>
<li><a class="reference internal" href="media-pipeline.html#std:setting-FILES_RESULT_FIELD">FILES_RESULT_FIELD</a></li>
<li><a class="reference internal" href="media-pipeline.html#std:setting-FILES_STORE">FILES_STORE</a></li>
<li><a class="reference internal" href="media-pipeline.html#std:setting-FILES_STORE_GCS_ACL">FILES_STORE_GCS_ACL</a></li>
<li><a class="reference internal" href="media-pipeline.html#std:setting-FILES_STORE_S3_ACL">FILES_STORE_S3_ACL</a></li>
<li><a class="reference internal" href="media-pipeline.html#std:setting-FILES_URLS_FIELD">FILES_URLS_FIELD</a></li>
<li><a class="reference internal" href="media-pipeline.html#std:setting-GCS_PROJECT_ID">GCS_PROJECT_ID</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_ALWAYS_STORE">HTTPCACHE_ALWAYS_STORE</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_DBM_MODULE">HTTPCACHE_DBM_MODULE</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_DIR">HTTPCACHE_DIR</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_ENABLED">HTTPCACHE_ENABLED</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_EXPIRATION_SECS">HTTPCACHE_EXPIRATION_SECS</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_GZIP">HTTPCACHE_GZIP</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_IGNORE_HTTP_CODES">HTTPCACHE_IGNORE_HTTP_CODES</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_IGNORE_MISSING">HTTPCACHE_IGNORE_MISSING</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_IGNORE_RESPONSE_CACHE_CONTROLS">HTTPCACHE_IGNORE_RESPONSE_CACHE_CONTROLS</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_IGNORE_SCHEMES">HTTPCACHE_IGNORE_SCHEMES</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_POLICY">HTTPCACHE_POLICY</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPCACHE_STORAGE">HTTPCACHE_STORAGE</a></li>
<li><a class="reference internal" href="spider-middleware.html#std:setting-HTTPERROR_ALLOWED_CODES">HTTPERROR_ALLOWED_CODES</a></li>
<li><a class="reference internal" href="spider-middleware.html#std:setting-HTTPERROR_ALLOW_ALL">HTTPERROR_ALLOW_ALL</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPPROXY_AUTH_ENCODING">HTTPPROXY_AUTH_ENCODING</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-HTTPPROXY_ENABLED">HTTPPROXY_ENABLED</a></li>
<li><a class="reference internal" href="media-pipeline.html#std:setting-IMAGES_EXPIRES">IMAGES_EXPIRES</a></li>
<li><a class="reference internal" href="media-pipeline.html#std:setting-IMAGES_MIN_HEIGHT">IMAGES_MIN_HEIGHT</a></li>
<li><a class="reference internal" href="media-pipeline.html#std:setting-IMAGES_MIN_WIDTH">IMAGES_MIN_WIDTH</a></li>
<li><a class="reference internal" href="media-pipeline.html#std:setting-IMAGES_RESULT_FIELD">IMAGES_RESULT_FIELD</a></li>
<li><a class="reference internal" href="media-pipeline.html#std:setting-IMAGES_STORE">IMAGES_STORE</a></li>
<li><a class="reference internal" href="media-pipeline.html#std:setting-IMAGES_STORE_GCS_ACL">IMAGES_STORE_GCS_ACL</a></li>
<li><a class="reference internal" href="media-pipeline.html#std:setting-IMAGES_STORE_S3_ACL">IMAGES_STORE_S3_ACL</a></li>
<li><a class="reference internal" href="media-pipeline.html#std:setting-IMAGES_THUMBS">IMAGES_THUMBS</a></li>
<li><a class="reference internal" href="media-pipeline.html#std:setting-IMAGES_URLS_FIELD">IMAGES_URLS_FIELD</a></li>
<li><a class="reference internal" href="email.html#std:setting-MAIL_FROM">MAIL_FROM</a></li>
<li><a class="reference internal" href="email.html#std:setting-MAIL_HOST">MAIL_HOST</a></li>
<li><a class="reference internal" href="email.html#std:setting-MAIL_PASS">MAIL_PASS</a></li>
<li><a class="reference internal" href="email.html#std:setting-MAIL_PORT">MAIL_PORT</a></li>
<li><a class="reference internal" href="email.html#std:setting-MAIL_SSL">MAIL_SSL</a></li>
<li><a class="reference internal" href="email.html#std:setting-MAIL_TLS">MAIL_TLS</a></li>
<li><a class="reference internal" href="email.html#std:setting-MAIL_USER">MAIL_USER</a></li>
<li><a class="reference internal" href="media-pipeline.html#std:setting-MEDIA_ALLOW_REDIRECTS">MEDIA_ALLOW_REDIRECTS</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-METAREFRESH_ENABLED">METAREFRESH_ENABLED</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-METAREFRESH_MAXDELAY">METAREFRESH_MAXDELAY</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-REDIRECT_ENABLED">REDIRECT_ENABLED</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-REDIRECT_MAX_TIMES">REDIRECT_MAX_TIMES</a></li>
<li><a class="reference internal" href="spider-middleware.html#std:setting-REFERER_ENABLED">REFERER_ENABLED</a></li>
<li><a class="reference internal" href="spider-middleware.html#std:setting-REFERRER_POLICY">REFERRER_POLICY</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-RETRY_ENABLED">RETRY_ENABLED</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-RETRY_HTTP_CODES">RETRY_HTTP_CODES</a></li>
<li><a class="reference internal" href="downloader-middleware.html#std:setting-RETRY_TIMES">RETRY_TIMES</a></li>
<li><a class="reference internal" href="telnetconsole.html#std:setting-TELNETCONSOLE_HOST">TELNETCONSOLE_HOST</a></li>
<li><a class="reference internal" href="telnetconsole.html#std:setting-TELNETCONSOLE_PASSWORD">TELNETCONSOLE_PASSWORD</a></li>
<li><a class="reference internal" href="telnetconsole.html#std:setting-TELNETCONSOLE_PORT">TELNETCONSOLE_PORT</a></li>
<li><a class="reference internal" href="telnetconsole.html#std:setting-TELNETCONSOLE_USERNAME">TELNETCONSOLE_USERNAME</a></li>
</ul>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="exceptions.html" class="btn btn-neutral float-right" title="Exceptions" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="link-extractors.html" class="btn btn-neutral" title="Link Extractors" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr /><div><div id="rtd-vdj8s11e" class="ethical-rtd"></div></div>

  <div role="contentinfo">
    <p>
        © Copyright 2008–2018, Scrapy developers
      
        <span class="commit">
          Revision <code>a9254127</code>.
        </span>
      

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: latest
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions"><!-- Inserted RTD Footer -->
<div class="injected">

  

      
      
      
      <dl>
        <dt>Versions</dt>
        
         <strong> 
        <dd><a href="https://docs.scrapy.org/en/latest/topics/settings.html">latest</a></dd>
         </strong> 
        
        
        <dd><a href="https://docs.scrapy.org/en/1.6/topics/settings.html">1.6</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.5/topics/settings.html">1.5</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.4/topics/settings.html">1.4</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.3/topics/settings.html">1.3</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.2/topics/settings.html">1.2</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.1/topics/settings.html">1.1</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.0/topics/settings.html">1.0</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.24/topics/settings.html">0.24</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.22/topics/settings.html">0.22</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.20/topics/settings.html">0.20</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/master/topics/settings.html">master</a></dd>
        
        
      </dl>
      
      

      
      
      <dl>
        <dt>Downloads</dt>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/pdf/latest/">PDF</a></dd>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/htmlzip/latest/">HTML</a></dd>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/epub/latest/">Epub</a></dd>
        
      </dl>
      
      

      
      <dl>
        <!-- These are kept as relative links for internal installs that are http -->
        <dt>On Read the Docs</dt>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/">Project Home</a>
        </dd>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/builds/">Builds</a>
        </dd>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/downloads/">Downloads</a>
        </dd>
      </dl>
      

      

      
      <dl>
        <dt>On GitHub</dt>
        <dd>
          <a href="https://github.com/scrapy/scrapy/blob/origin/1.6/docs/topics/settings.rst">View</a>
        </dd>
        
      </dl>
      
      

      
      <dl>
        <dt>Search</dt>
        <dd>
          <div style="padding: 6px;">
            <form id="flyout-search-form" class="wy-form" target="_blank" action="//readthedocs.org/projects/scrapy/search/" method="get">
              <input type="text" name="q" placeholder="Search docs" />
              </form>
          </div>
        </dd>
      </dl>
      



      <hr />
      
        <small>
          <span>Hosted by <a href="https://readthedocs.org">Read the Docs</a></span>
          <span> · </span>
          <a href="https://docs.readthedocs.io/page/privacy-policy.html">Privacy Policy</a>
        </small>
      

      

</div>
</div>
  </div>



  

    
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'../',
              VERSION:'1.6.0',
              LANGUAGE:'en',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="https://assets.readthedocs.org/static/javascript/readthedocs-doc-embed.js"></script>
    

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script type="text/javascript">
!function(){var analytics=window.analytics=window.analytics||[];if(!analytics.initialize)if(analytics.invoked)window.console&amp;&amp;console.error&amp;&amp;console.error("Segment snippet included twice.");else{analytics.invoked=!0;analytics.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","page","once","off","on"];analytics.factory=function(t){return function(){var e=Array.prototype.slice.call(arguments);e.unshift(t);analytics.push(e);return analytics}};for(var t=0;t&lt;analytics.methods.length;t++){var e=analytics.methods[t];analytics[e]=analytics.factory(e)}analytics.load=function(t){var e=document.createElement("script");e.type="text/javascript";e.async=!0;e.src=("https:"===document.location.protocol?"https://":"http://")+"cdn.segment.com/analytics.js/v1/"+t+"/analytics.min.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n)};analytics.SNIPPET_VERSION="3.1.0";
analytics.load("8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA");
analytics.page();
}}();

analytics.ready(function () {
    ga('require', 'linker');
    ga('linker:autoLink', ['scrapinghub.com', 'crawlera.com']);
});
</script>



<div id="rtd-vddn5ijgi"><div class="ethical-fixedfooter"><div class="ethical-content"><div class="ethical-close"><a href="javascript:$('.ethical-fixedfooter').hide()" aria-label="Close Ad">×</a></div><img src="https://readthedocs.org/sustainability/view/548/P4wVSldF3HZ1/" class="ethical-pixel" /><div><a href="https://readthedocs.org/sustainability/click/548/P4wVSldF3HZ1/" rel="nofollow" target="_blank"><span class="ethical-text"></span></a><a href="https://readthedocs.org/sustainability/click/548/P4wVSldF3HZ1/" rel="nofollow" target="_blank">Hiring Python devs? Read the Docs can help!</a><span class="ethical-callout"><small><em><a href="https://docs.readthedocs.io/en/latest/ethical-advertising.html" rel="nofollow" target="_blank">ads served ethically</a></em></small></span></div></div></div></div></body></html>