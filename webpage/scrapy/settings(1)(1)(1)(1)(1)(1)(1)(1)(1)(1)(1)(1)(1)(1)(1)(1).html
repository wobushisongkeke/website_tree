<!DOCTYPE html><!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]--><!--[if gt IE 8]><!--><html xmlns="http://www.w3.org/1999/xhtml" class=" js flexbox canvas canvastext webgl no-touch geolocation postmessage websqldatabase indexeddb hashchange history draganddrop websockets rgba hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients cssreflections csstransforms csstransforms3d csstransitions fontface generatedcontent video audio localstorage sessionstorage webworkers applicationcache svg inlinesvg smil svgclippaths" lang="en" style=""><!--<![endif]--><head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Settings — Scrapy 0.12.0 documentation</title>
  

  
  

  

  
  
    

  

  
  

  
    <link rel="stylesheet" href="https://media.readthedocs.org/css/sphinx_rtd_theme.css" type="text/css" />
  

  
    <link rel="top" title="Scrapy 0.12.0 documentation" href="../index.html" />
        <link rel="next" title="Signals" href="signals.html" />
        <link rel="prev" title="Requests and Responses" href="request-response.html" /> 

  
  <script type="text/javascript" async="" src="https://ssl.google-analytics.com/ga.js"></script><script src="../_static/js/modernizr.min.js"></script>


<!-- RTD Extra Head -->

<!-- 
Always link to the latest version, as canonical.
http://docs.readthedocs.org/en/latest/canonical.html
-->
<link rel="canonical" href="http://doc.scrapy.org/en/latest/topics/settings.html" />

<link rel="stylesheet" href="https://media.readthedocs.org/css/readthedocs-doc-embed.css" type="text/css" />

<script type="text/javascript" src="../_static/readthedocs-data.js"></script>

<!-- Add page-specific data, which must exist in the page js, not global -->
<script type="text/javascript">
READTHEDOCS_DATA['page'] = 'topics/settings'
</script>

<script type="text/javascript" src="../_static/readthedocs-dynamic-include.js"></script>

<!-- end RTD <extrahead> --></head>

<body class="wy-body-for-nav" role="document" style="">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Scrapy
          

          
          </a>

          
            
            
            
              <div class="version">
                0.12
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/overview.html">Scrapy at a glance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/install.html">Installation guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/tutorial.html">Scrapy Tutorial</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="commands.html">Command line tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="items.html">Items</a></li>
<li class="toctree-l1"><a class="reference internal" href="spiders.html">Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="link-extractors.html">Link Extractors</a></li>
<li class="toctree-l1"><a class="reference internal" href="selectors.html">XPath Selectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="loaders.html">Item Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="shell.html">Scrapy shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="item-pipeline.html">Item Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="feed-exports.html">Feed exports</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="stats.html">Stats Collection</a></li>
<li class="toctree-l1"><a class="reference internal" href="email.html">Sending e-mail</a></li>
<li class="toctree-l1"><a class="reference internal" href="telnetconsole.html">Telnet Console</a></li>
<li class="toctree-l1"><a class="reference internal" href="webservice.html">Web Service</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="firefox.html">Using Firefox for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="firebug.html">Using Firebug for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="leaks.html">Debugging memory leaks</a></li>
<li class="toctree-l1"><a class="reference internal" href="images.html">Downloading Item Images</a></li>
<li class="toctree-l1"><a class="reference internal" href="ubuntu.html">Ubuntu packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="scrapyd.html">Scrapy Service (scrapyd)</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="downloader-middleware.html">Downloader Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="spider-middleware.html">Spider Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="extensions.html">Extensions</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="request-response.html">Requests and Responses</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href=""><span class="toctree-expand"></span>Settings</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#designating-the-settings">Designating the settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="#populating-the-settings"><span class="toctree-expand"></span>Populating the settings</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#global-overrides">1. Global overrides</a></li>
<li class="toctree-l3"><a class="reference internal" href="#project-settings-module">2. Project settings module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#default-settings-per-command">3. Default settings per-command</a></li>
<li class="toctree-l3"><a class="reference internal" href="#default-global-settings">4. Default global settings</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#how-to-access-settings">How to access settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="#rationale-for-setting-names">Rationale for setting names</a></li>
<li class="toctree-l2"><a class="reference internal" href="#built-in-settings-reference"><span class="toctree-expand"></span>Built-in settings reference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#aws-access-key-id">AWS_ACCESS_KEY_ID</a></li>
<li class="toctree-l3"><a class="reference internal" href="#aws-secret-access-key">AWS_SECRET_ACCESS_KEY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bot-name">BOT_NAME</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bot-version">BOT_VERSION</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concurrent-items">CONCURRENT_ITEMS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concurrent-requests-per-spider">CONCURRENT_REQUESTS_PER_SPIDER</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concurrent-spiders">CONCURRENT_SPIDERS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cookies-debug">COOKIES_DEBUG</a></li>
<li class="toctree-l3"><a class="reference internal" href="#default-item-class">DEFAULT_ITEM_CLASS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#default-request-headers">DEFAULT_REQUEST_HEADERS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#default-response-encoding">DEFAULT_RESPONSE_ENCODING</a></li>
<li class="toctree-l3"><a class="reference internal" href="#depth-limit">DEPTH_LIMIT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#depth-stats">DEPTH_STATS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloader-debug">DOWNLOADER_DEBUG</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloader-middlewares">DOWNLOADER_MIDDLEWARES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloader-middlewares-base">DOWNLOADER_MIDDLEWARES_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#downloader-stats">DOWNLOADER_STATS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-delay">DOWNLOAD_DELAY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-handlers">DOWNLOAD_HANDLERS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-handlers-base">DOWNLOAD_HANDLERS_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-timeout">DOWNLOAD_TIMEOUT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dupefilter-class">DUPEFILTER_CLASS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#encoding-aliases">ENCODING_ALIASES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#encoding-aliases-base">ENCODING_ALIASES_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#extensions">EXTENSIONS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#extensions-base">EXTENSIONS_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#item-pipelines">ITEM_PIPELINES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-enabled">LOG_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-encoding">LOG_ENCODING</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-file">LOG_FILE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-level">LOG_LEVEL</a></li>
<li class="toctree-l3"><a class="reference internal" href="#log-stdout">LOG_STDOUT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memdebug-enabled">MEMDEBUG_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memdebug-notify">MEMDEBUG_NOTIFY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memusage-enabled">MEMUSAGE_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memusage-limit-mb">MEMUSAGE_LIMIT_MB</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memusage-notify-mail">MEMUSAGE_NOTIFY_MAIL</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memusage-report">MEMUSAGE_REPORT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memusage-warning-mb">MEMUSAGE_WARNING_MB</a></li>
<li class="toctree-l3"><a class="reference internal" href="#newspider-module">NEWSPIDER_MODULE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#randomize-download-delay">RANDOMIZE_DOWNLOAD_DELAY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#redirect-max-times">REDIRECT_MAX_TIMES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#redirect-max-metarefresh-delay">REDIRECT_MAX_METAREFRESH_DELAY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#redirect-priority-adjust">REDIRECT_PRIORITY_ADJUST</a></li>
<li class="toctree-l3"><a class="reference internal" href="#robotstxt-obey">ROBOTSTXT_OBEY</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scheduler">SCHEDULER</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scheduler-order">SCHEDULER_ORDER</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scheduler-middlewares">SCHEDULER_MIDDLEWARES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scheduler-middlewares-base">SCHEDULER_MIDDLEWARES_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spider-middlewares">SPIDER_MIDDLEWARES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spider-middlewares-base">SPIDER_MIDDLEWARES_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spider-modules">SPIDER_MODULES</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sqlite-db">SQLITE_DB</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stats-class">STATS_CLASS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stats-dump">STATS_DUMP</a></li>
<li class="toctree-l3"><a class="reference internal" href="#stats-enabled">STATS_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="#statsmailer-rcpts">STATSMAILER_RCPTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#telnetconsole-enabled">TELNETCONSOLE_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="#telnetconsole-port">TELNETCONSOLE_PORT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#templates-dir">TEMPLATES_DIR</a></li>
<li class="toctree-l3"><a class="reference internal" href="#urllength-limit">URLLENGTH_LIMIT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#user-agent">USER_AGENT</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="signals.html">Signals</a></li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">Exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="exporters.html">Item Exporters</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api-stability.html">Versioning and API Stability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../experimental/index.html">Experimental features</a></li>
</ul>

            
          
        </div>
      <div id="rtd-spkhsscm" class="ethical-rtd ethical-dark-theme"><div class="ethical-sidebar"><div class="ethical-content"><a href="https://readthedocs.org/sustainability/click/194/yfbXbLGusy9q/" rel="nofollow" target="_blank" class="ethical-image-link"><img src="https://assets.readthedocs.org/sustainability/english-house.png" /></a><div class="ethical-text"><a href="https://readthedocs.org/sustainability/click/194/yfbXbLGusy9q/" rel="nofollow" target="_blank"><b>Reach over 7 million devs</b> each month when you advertise with Read the Docs</a>.</div></div><div class="ethical-callout"><small><em><a href="https://readthedocs.org/sustainability/advertising/">Sponsored</a><span> · </span><a href="https://docs.readthedocs.io/en/latest/ethical-advertising.html">Ads served ethically</a></em></small></div></div></div></div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">Scrapy</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> »</li>
      
    <li>Settings</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="https://github.com/scrapy/scrapy/blob/0.12/docs/topics/settings.rst" class="fa fa-github"> Edit on GitHub</a>
          
        
      </li>
  </ul>
  <hr />
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-scrapy.conf">
<span id="settings"></span><span id="topics-settings"></span><h1>Settings<a class="headerlink" href="#module-scrapy.conf" title="Permalink to this headline">¶</a></h1>
<p>The Scrapy settings allows you to customize the behaviour of all Scrapy
components, including the core, extensions, pipelines and spiders themselves.</p>
<p>The infrastructure of the settings provides a global namespace of key-value mappings
that the code can use to pull configuration values from. The settings can be
populated through different mechanisms, which are described below.</p>
<p>The settings are also the mechanism for selecting the currently active Scrapy
project (in case you have many).</p>
<p>For a list of available built-in settings see: <a class="reference internal" href="#topics-settings-ref"><span>Built-in settings reference</span></a>.</p>
<div class="section" id="designating-the-settings">
<h2>Designating the settings<a class="headerlink" href="#designating-the-settings" title="Permalink to this headline">¶</a></h2>
<p>When you use Scrapy, you have to tell it which settings you’re using. You can
do this by using an environment variable, <code class="docutils literal"><span class="pre">SCRAPY_SETTINGS_MODULE</span></code>.</p>
<p>The value of <code class="docutils literal"><span class="pre">SCRAPY_SETTINGS_MODULE</span></code> should be in Python path syntax, e.g.
<code class="docutils literal"><span class="pre">myproject.settings</span></code>. Note that the settings module should be on the
Python <a class="reference external" href="http://diveintopython.org/getting_to_know_python/everything_is_an_object.html">import search path</a>.</p>
</div>
<div class="section" id="populating-the-settings">
<h2>Populating the settings<a class="headerlink" href="#populating-the-settings" title="Permalink to this headline">¶</a></h2>
<p>Settings can be populated using different mechanisms, each of which having a
different precedence. Here is the list of them in decreasing order of
precedence:</p>
<blockquote>
<div><ol class="arabic simple">
<li>Global overrides (most precedence)</li>
<li>Project settings module</li>
<li>Default settings per-command</li>
<li>Default global settings (less precedence)</li>
</ol>
</div></blockquote>
<p>These mechanisms are described in more detail below.</p>
<div class="section" id="global-overrides">
<h3>1. Global overrides<a class="headerlink" href="#global-overrides" title="Permalink to this headline">¶</a></h3>
<p>Global overrides are the ones that take most precedence, and are usually
populated by command-line options.</p>
<dl class="docutils">
<dt>Example::</dt>
<dd><div class="first last highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scrapy.conf</span> <span class="kn">import</span> <span class="n">settings</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">settings</span><span class="o">.</span><span class="n">overrides</span><span class="p">[</span><span class="s1">'LOG_ENABLED'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
</pre></div>
</div>
</dd>
</dl>
<p>You can also override one (or more) settings from command line using the
<code class="docutils literal"><span class="pre">--set</span></code> command line argument.</p>
<p>Example:</p>
<div class="highlight-sh"><div class="highlight"><pre><span></span>scrapy crawl domain.com --set <span class="nv">LOG_FILE</span><span class="o">=</span>scrapy.log
</pre></div>
</div>
</div>
<div class="section" id="project-settings-module">
<h3>2. Project settings module<a class="headerlink" href="#project-settings-module" title="Permalink to this headline">¶</a></h3>
<p>The project settings module is the standard configuration file for your Scrapy
project.  It’s where most of your custom settings will be populated. For
example:: <code class="docutils literal"><span class="pre">myproject.settings</span></code>.</p>
</div>
<div class="section" id="default-settings-per-command">
<h3>3. Default settings per-command<a class="headerlink" href="#default-settings-per-command" title="Permalink to this headline">¶</a></h3>
<p>Each <a class="reference internal" href="commands.html"><em>Scrapy tool</em></a> command can have its own default
settings, which override the global default settings. Those custom command
settings are specified in the <code class="docutils literal"><span class="pre">default_settings</span></code> attribute of the command
class.</p>
</div>
<div class="section" id="default-global-settings">
<h3>4. Default global settings<a class="headerlink" href="#default-global-settings" title="Permalink to this headline">¶</a></h3>
<p>The global defaults are located in the <code class="docutils literal"><span class="pre">scrapy.settings.default_settings</span></code>
module and documented in the <a class="reference internal" href="#topics-settings-ref"><span>Built-in settings reference</span></a> section.</p>
</div>
</div>
<div class="section" id="how-to-access-settings">
<h2>How to access settings<a class="headerlink" href="#how-to-access-settings" title="Permalink to this headline">¶</a></h2>
<p>Here’s an example of the simplest way to access settings from Python code:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scrapy.conf</span> <span class="kn">import</span> <span class="n">settings</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">settings</span><span class="p">[</span><span class="s1">'LOG_ENABLED'</span><span class="p">]</span>
<span class="go">True</span>
</pre></div>
</div>
<p>In other words, settings can be accesed like a dict, but it’s usually preferred
to extract the setting in the format you need it to avoid type errors. In order
to do that you’ll have to use one of the following methods:</p>
<dl class="class">
<dt id="scrapy.conf.Settings">
<em class="property">class </em><code class="descclassname">scrapy.conf.</code><code class="descname">Settings</code><a class="headerlink" href="#scrapy.conf.Settings" title="Permalink to this definition">¶</a></dt>
<dd><p>There is a (singleton) Settings object automatically instantiated when the
<a class="reference internal" href="#module-scrapy.conf" title="scrapy.conf: Settings manager"><code class="xref py py-mod docutils literal"><span class="pre">scrapy.conf</span></code></a> module is loaded, and it’s usually accessed like this:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scrapy.conf</span> <span class="kn">import</span> <span class="n">settings</span>
</pre></div>
</div>
<blockquote>
<div><dl class="method">
<dt id="scrapy.conf.Settings.get">
<code class="descname">get</code><span class="sig-paren">(</span><em>name</em>, <em>default=None</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.conf.Settings.get" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a setting value without affecting its original type.</p>
<table class="docutils field-list" frame="void" rules="none">
<colgroup><col class="field-name" />
<col class="field-body" />
</colgroup><tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<em>string</em>) – the setting name</li>
<li><strong>default</strong> (<em>any</em>) – the value to return if no setting is found</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.conf.Settings.getbool">
<code class="descname">getbool</code><span class="sig-paren">(</span><em>name</em>, <em>default=False</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.conf.Settings.getbool" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a setting value as a boolean. For example, both <code class="docutils literal"><span class="pre">1</span></code> and <code class="docutils literal"><span class="pre">'1'</span></code>, and
<code class="docutils literal"><span class="pre">True</span></code> return <code class="docutils literal"><span class="pre">True</span></code>, while <code class="docutils literal"><span class="pre">0</span></code>, <code class="docutils literal"><span class="pre">'0'</span></code>, <code class="docutils literal"><span class="pre">False</span></code> and <code class="docutils literal"><span class="pre">None</span></code>
return <code class="docutils literal"><span class="pre">False``</span></code></p>
<p>For example, settings populated through environment variables set to <code class="docutils literal"><span class="pre">'0'</span></code>
will return <code class="docutils literal"><span class="pre">False</span></code> when using this method.</p>
<table class="docutils field-list" frame="void" rules="none">
<colgroup><col class="field-name" />
<col class="field-body" />
</colgroup><tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<em>string</em>) – the setting name</li>
<li><strong>default</strong> (<em>any</em>) – the value to return if no setting is found</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.conf.Settings.getint">
<code class="descname">getint</code><span class="sig-paren">(</span><em>name</em>, <em>default=0</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.conf.Settings.getint" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a setting value as an int</p>
<table class="docutils field-list" frame="void" rules="none">
<colgroup><col class="field-name" />
<col class="field-body" />
</colgroup><tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<em>string</em>) – the setting name</li>
<li><strong>default</strong> (<em>any</em>) – the value to return if no setting is found</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.conf.Settings.getfloat">
<code class="descname">getfloat</code><span class="sig-paren">(</span><em>name</em>, <em>default=0.0</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.conf.Settings.getfloat" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a setting value as a float</p>
<table class="docutils field-list" frame="void" rules="none">
<colgroup><col class="field-name" />
<col class="field-body" />
</colgroup><tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<em>string</em>) – the setting name</li>
<li><strong>default</strong> (<em>any</em>) – the value to return if no setting is found</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.conf.Settings.getlist">
<code class="descname">getlist</code><span class="sig-paren">(</span><em>name</em>, <em>default=None</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.conf.Settings.getlist" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a setting value as a list. If the setting original type is a list it
will be returned verbatim. If it’s a string it will be split by ”,”.</p>
<p>For example, settings populated through environment variables set to
<code class="docutils literal"><span class="pre">'one,two'</span></code> will return a list [‘one’, ‘two’] when using this method.</p>
<table class="docutils field-list" frame="void" rules="none">
<colgroup><col class="field-name" />
<col class="field-body" />
</colgroup><tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<em>string</em>) – the setting name</li>
<li><strong>default</strong> (<em>any</em>) – the value to return if no setting is found</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div></blockquote>
</dd></dl>

</div>
<div class="section" id="rationale-for-setting-names">
<h2>Rationale for setting names<a class="headerlink" href="#rationale-for-setting-names" title="Permalink to this headline">¶</a></h2>
<p>Setting names are usually prefixed with the component that they configure. For
example, proper setting names for a fictional robots.txt extension would be
<code class="docutils literal"><span class="pre">ROBOTSTXT_ENABLED</span></code>, <code class="docutils literal"><span class="pre">ROBOTSTXT_OBEY</span></code>, <code class="docutils literal"><span class="pre">ROBOTSTXT_CACHEDIR</span></code>, etc.</p>
</div>
<div class="section" id="built-in-settings-reference">
<span id="topics-settings-ref"></span><h2>Built-in settings reference<a class="headerlink" href="#built-in-settings-reference" title="Permalink to this headline">¶</a></h2>
<p>Here’s a list of all available Scrapy settings, in alphabetical order, along
with their default values and the scope where they apply.</p>
<p>The scope, where available, shows where the setting is being used, if it’s tied
to any particular component. In that case the module of that component will be
shown, typically an extension, middleware or pipeline. It also means that the
component must be enabled in order for the setting to have any effect.</p>
<div class="section" id="aws-access-key-id">
<span id="std:setting-AWS_ACCESS_KEY_ID"></span><h3>AWS_ACCESS_KEY_ID<a class="headerlink" href="#aws-access-key-id" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">None</span></code></p>
<p>The AWS access key used by code that requires access to <a class="reference external" href="http://aws.amazon.com/">Amazon Web services</a>,
such as the <a class="reference internal" href="feed-exports.html#topics-feed-storage-s3"><span>S3 feed storage backend</span></a>.</p>
</div>
<div class="section" id="aws-secret-access-key">
<span id="std:setting-AWS_SECRET_ACCESS_KEY"></span><h3>AWS_SECRET_ACCESS_KEY<a class="headerlink" href="#aws-secret-access-key" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">None</span></code></p>
<p>The AWS secret key used by code that requires access to <a class="reference external" href="http://aws.amazon.com/">Amazon Web services</a>,
such as the <a class="reference internal" href="feed-exports.html#topics-feed-storage-s3"><span>S3 feed storage backend</span></a>.</p>
</div>
<div class="section" id="bot-name">
<span id="std:setting-BOT_NAME"></span><h3>BOT_NAME<a class="headerlink" href="#bot-name" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">'scrapybot'</span></code></p>
<p>The name of the bot implemented by this Scrapy project (also known as the
project name). This will be used to construct the User-Agent by default, and
also for logging.</p>
<p>It’s automatically populated with your project name when you create your
project with the <a class="reference internal" href="commands.html#std:command-startproject"><code class="xref std std-command docutils literal"><span class="pre">startproject</span></code></a> command.</p>
</div>
<div class="section" id="bot-version">
<span id="std:setting-BOT_VERSION"></span><h3>BOT_VERSION<a class="headerlink" href="#bot-version" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">1.0</span></code></p>
<p>The version of the bot implemented by this Scrapy project. This will be used to
construct the User-Agent by default.</p>
</div>
<div class="section" id="concurrent-items">
<span id="std:setting-CONCURRENT_ITEMS"></span><h3>CONCURRENT_ITEMS<a class="headerlink" href="#concurrent-items" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">100</span></code></p>
<p>Maximum number of concurrent items (per response) to process in parallel in the
Item Processor (also known as the <a class="reference internal" href="item-pipeline.html#topics-item-pipeline"><span>Item Pipeline</span></a>).</p>
</div>
<div class="section" id="concurrent-requests-per-spider">
<span id="std:setting-CONCURRENT_REQUESTS_PER_SPIDER"></span><h3>CONCURRENT_REQUESTS_PER_SPIDER<a class="headerlink" href="#concurrent-requests-per-spider" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">8</span></code></p>
<p>Specifies how many concurrent (ie. simultaneous) requests will be performed per
open spider.</p>
</div>
<div class="section" id="concurrent-spiders">
<span id="std:setting-CONCURRENT_SPIDERS"></span><h3>CONCURRENT_SPIDERS<a class="headerlink" href="#concurrent-spiders" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">8</span></code></p>
<p>Maximum number of spiders to scrape in parallel.</p>
</div>
<div class="section" id="cookies-debug">
<span id="std:setting-COOKIES_DEBUG"></span><h3>COOKIES_DEBUG<a class="headerlink" href="#cookies-debug" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">False</span></code></p>
<p>Enable debugging message of Cookies Downloader Middleware.</p>
</div>
<div class="section" id="default-item-class">
<span id="std:setting-DEFAULT_ITEM_CLASS"></span><h3>DEFAULT_ITEM_CLASS<a class="headerlink" href="#default-item-class" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">'scrapy.item.Item'</span></code></p>
<p>The default class that will be used for instantiating items in the <a class="reference internal" href="shell.html#topics-shell"><span>the
Scrapy shell</span></a>.</p>
</div>
<div class="section" id="default-request-headers">
<span id="std:setting-DEFAULT_REQUEST_HEADERS"></span><h3>DEFAULT_REQUEST_HEADERS<a class="headerlink" href="#default-request-headers" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">'Accept'</span><span class="p">:</span> <span class="s1">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span><span class="p">,</span>
    <span class="s1">'Accept-Language'</span><span class="p">:</span> <span class="s1">'en'</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The default headers used for Scrapy HTTP Requests. They’re populated in the
<a class="reference internal" href="downloader-middleware.html#scrapy.contrib.downloadermiddleware.defaultheaders.DefaultHeadersMiddleware" title="scrapy.contrib.downloadermiddleware.defaultheaders.DefaultHeadersMiddleware"><code class="xref py py-class docutils literal"><span class="pre">DefaultHeadersMiddleware</span></code></a>.</p>
</div>
<div class="section" id="default-response-encoding">
<span id="std:setting-DEFAULT_RESPONSE_ENCODING"></span><h3>DEFAULT_RESPONSE_ENCODING<a class="headerlink" href="#default-response-encoding" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">'ascii'</span></code></p>
<p>The default encoding to use for <a class="reference internal" href="request-response.html#scrapy.http.TextResponse" title="scrapy.http.TextResponse"><code class="xref py py-class docutils literal"><span class="pre">TextResponse</span></code></a> objects (and
subclasses) when no encoding is declared and no encoding could be inferred from
the body.</p>
</div>
<div class="section" id="depth-limit">
<span id="std:setting-DEPTH_LIMIT"></span><h3>DEPTH_LIMIT<a class="headerlink" href="#depth-limit" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">0</span></code></p>
<p>The maximum depth that will be allowed to crawl for any site. If zero, no limit
will be imposed.</p>
</div>
<div class="section" id="depth-stats">
<span id="std:setting-DEPTH_STATS"></span><h3>DEPTH_STATS<a class="headerlink" href="#depth-stats" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">True</span></code></p>
<p>Whether to collect depth stats.</p>
</div>
<div class="section" id="downloader-debug">
<span id="std:setting-DOWNLOADER_DEBUG"></span><h3>DOWNLOADER_DEBUG<a class="headerlink" href="#downloader-debug" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">False</span></code></p>
<p>Whether to enable the Downloader debugging mode.</p>
</div>
<div class="section" id="downloader-middlewares">
<span id="std:setting-DOWNLOADER_MIDDLEWARES"></span><h3>DOWNLOADER_MIDDLEWARES<a class="headerlink" href="#downloader-middlewares" title="Permalink to this headline">¶</a></h3>
<p>Default:: <code class="docutils literal"><span class="pre">{}</span></code></p>
<p>A dict containing the downloader middlewares enabled in your project, and their
orders. For more info see <a class="reference internal" href="downloader-middleware.html#topics-downloader-middleware-setting"><span>Activating a downloader middleware</span></a>.</p>
</div>
<div class="section" id="downloader-middlewares-base">
<span id="std:setting-DOWNLOADER_MIDDLEWARES_BASE"></span><h3>DOWNLOADER_MIDDLEWARES_BASE<a class="headerlink" href="#downloader-middlewares-base" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.robotstxt.RobotsTxtMiddleware'</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.httpauth.HttpAuthMiddleware'</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware'</span><span class="p">:</span> <span class="mi">400</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.retry.RetryMiddleware'</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.defaultheaders.DefaultHeadersMiddleware'</span><span class="p">:</span> <span class="mi">550</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.redirect.RedirectMiddleware'</span><span class="p">:</span> <span class="mi">600</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.cookies.CookiesMiddleware'</span><span class="p">:</span> <span class="mi">700</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware'</span><span class="p">:</span> <span class="mi">750</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.httpcompression.HttpCompressionMiddleware'</span><span class="p">:</span> <span class="mi">800</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.stats.DownloaderStats'</span><span class="p">:</span> <span class="mi">850</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.httpcache.HttpCacheMiddleware'</span><span class="p">:</span> <span class="mi">900</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>A dict containing the downloader middlewares enabled by default in Scrapy. You
should never modify this setting in your project, modify
<a class="reference internal" href="#std:setting-DOWNLOADER_MIDDLEWARES"><code class="xref std std-setting docutils literal"><span class="pre">DOWNLOADER_MIDDLEWARES</span></code></a> instead.  For more info see
<a class="reference internal" href="downloader-middleware.html#topics-downloader-middleware-setting"><span>Activating a downloader middleware</span></a>.</p>
</div>
<div class="section" id="downloader-stats">
<span id="std:setting-DOWNLOADER_STATS"></span><h3>DOWNLOADER_STATS<a class="headerlink" href="#downloader-stats" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">True</span></code></p>
<p>Whether to enable downloader stats collection.</p>
</div>
<div class="section" id="download-delay">
<span id="std:setting-DOWNLOAD_DELAY"></span><h3>DOWNLOAD_DELAY<a class="headerlink" href="#download-delay" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">0</span></code></p>
<p>The amount of time (in secs) that the downloader should wait before downloading
consecutive pages from the same spider. This can be used to throttle the
crawling speed to avoid hitting servers too hard. Decimal numbers are
supported.  Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">DOWNLOAD_DELAY</span> <span class="o">=</span> <span class="mf">0.25</span>    <span class="c1"># 250 ms of delay</span>
</pre></div>
</div>
<p>This setting is also affected by the <a class="reference internal" href="#std:setting-RANDOMIZE_DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal"><span class="pre">RANDOMIZE_DOWNLOAD_DELAY</span></code></a>
setting (which is enabled by default). By default, Scrapy doesn’t wait a fixed
amount of time between requests, but uses a random interval between 0.5 and 1.5
* <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_DELAY</span></code></a>.</p>
<p>You can also change this setting per spider.</p>
</div>
<div class="section" id="download-handlers">
<span id="std:setting-DOWNLOAD_HANDLERS"></span><h3>DOWNLOAD_HANDLERS<a class="headerlink" href="#download-handlers" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">{}</span></code></p>
<p>A dict containing the request downloader handlers enabled in your project.
See <cite>DOWNLOAD_HANDLERS_BASE</cite> for example format.</p>
</div>
<div class="section" id="download-handlers-base">
<span id="std:setting-DOWNLOAD_HANDLERS_BASE"></span><h3>DOWNLOAD_HANDLERS_BASE<a class="headerlink" href="#download-handlers-base" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">'file'</span><span class="p">:</span> <span class="s1">'scrapy.core.downloader.handlers.file.FileDownloadHandler'</span><span class="p">,</span>
    <span class="s1">'http'</span><span class="p">:</span> <span class="s1">'scrapy.core.downloader.handlers.http.HttpDownloadHandler'</span><span class="p">,</span>
    <span class="s1">'https'</span><span class="p">:</span> <span class="s1">'scrapy.core.downloader.handlers.http.HttpDownloadHandler'</span><span class="p">,</span>
    <span class="s1">'s3'</span><span class="p">:</span> <span class="s1">'scrapy.core.downloader.handlers.s3.S3DownloadHandler'</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>A dict containing the request download handlers enabled by default in Scrapy.
You should never modify this setting in your project, modify
<a class="reference internal" href="#std:setting-DOWNLOAD_HANDLERS"><code class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_HANDLERS</span></code></a> instead.</p>
</div>
<div class="section" id="download-timeout">
<span id="std:setting-DOWNLOAD_TIMEOUT"></span><h3>DOWNLOAD_TIMEOUT<a class="headerlink" href="#download-timeout" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">180</span></code></p>
<p>The amount of time (in secs) that the downloader will wait before timing out.</p>
</div>
<div class="section" id="dupefilter-class">
<span id="std:setting-DUPEFILTER_CLASS"></span><h3>DUPEFILTER_CLASS<a class="headerlink" href="#dupefilter-class" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">'scrapy.contrib.dupefilter.RequestFingerprintDupeFilter'</span></code></p>
<p>The class used to detect and filter duplicate requests.</p>
<p>The default (<code class="docutils literal"><span class="pre">RequestFingerprintDupeFilter</span></code>) filters based on request fingerprint
(using <code class="docutils literal"><span class="pre">scrapy.utils.request.request_fingerprint</span></code>) and grouping per domain.</p>
</div>
<div class="section" id="encoding-aliases">
<span id="std:setting-ENCODING_ALIASES"></span><h3>ENCODING_ALIASES<a class="headerlink" href="#encoding-aliases" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">{}</span></code></p>
<p>A mapping of custom encoding aliases for your project, where the keys are the
aliases (and must be lower case) and the values are the encodings they map to.</p>
<p>This setting extends the <a class="reference internal" href="#std:setting-ENCODING_ALIASES_BASE"><code class="xref std std-setting docutils literal"><span class="pre">ENCODING_ALIASES_BASE</span></code></a> setting which
contains some default mappings.</p>
</div>
<div class="section" id="encoding-aliases-base">
<span id="std:setting-ENCODING_ALIASES_BASE"></span><h3>ENCODING_ALIASES_BASE<a class="headerlink" href="#encoding-aliases-base" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="c1"># gb2312 is superseded by gb18030</span>
    <span class="s1">'gb2312'</span><span class="p">:</span> <span class="s1">'gb18030'</span><span class="p">,</span>
    <span class="s1">'chinese'</span><span class="p">:</span> <span class="s1">'gb18030'</span><span class="p">,</span>
    <span class="s1">'csiso58gb231280'</span><span class="p">:</span> <span class="s1">'gb18030'</span><span class="p">,</span>
    <span class="s1">'euc- cn'</span><span class="p">:</span> <span class="s1">'gb18030'</span><span class="p">,</span>
    <span class="s1">'euccn'</span><span class="p">:</span> <span class="s1">'gb18030'</span><span class="p">,</span>
    <span class="s1">'eucgb2312-cn'</span><span class="p">:</span> <span class="s1">'gb18030'</span><span class="p">,</span>
    <span class="s1">'gb2312-1980'</span><span class="p">:</span> <span class="s1">'gb18030'</span><span class="p">,</span>
    <span class="s1">'gb2312-80'</span><span class="p">:</span> <span class="s1">'gb18030'</span><span class="p">,</span>
    <span class="s1">'iso- ir-58'</span><span class="p">:</span> <span class="s1">'gb18030'</span><span class="p">,</span>
    <span class="c1"># gbk is superseded by gb18030</span>
    <span class="s1">'gbk'</span><span class="p">:</span> <span class="s1">'gb18030'</span><span class="p">,</span>
    <span class="s1">'936'</span><span class="p">:</span> <span class="s1">'gb18030'</span><span class="p">,</span>
    <span class="s1">'cp936'</span><span class="p">:</span> <span class="s1">'gb18030'</span><span class="p">,</span>
    <span class="s1">'ms936'</span><span class="p">:</span> <span class="s1">'gb18030'</span><span class="p">,</span>
    <span class="c1"># latin_1 is a subset of cp1252</span>
    <span class="s1">'latin_1'</span><span class="p">:</span> <span class="s1">'cp1252'</span><span class="p">,</span>
    <span class="s1">'iso-8859-1'</span><span class="p">:</span> <span class="s1">'cp1252'</span><span class="p">,</span>
    <span class="s1">'iso8859-1'</span><span class="p">:</span> <span class="s1">'cp1252'</span><span class="p">,</span>
    <span class="s1">'8859'</span><span class="p">:</span> <span class="s1">'cp1252'</span><span class="p">,</span>
    <span class="s1">'cp819'</span><span class="p">:</span> <span class="s1">'cp1252'</span><span class="p">,</span>
    <span class="s1">'latin'</span><span class="p">:</span> <span class="s1">'cp1252'</span><span class="p">,</span>
    <span class="s1">'latin1'</span><span class="p">:</span> <span class="s1">'cp1252'</span><span class="p">,</span>
    <span class="s1">'l1'</span><span class="p">:</span> <span class="s1">'cp1252'</span><span class="p">,</span>
    <span class="c1"># others</span>
    <span class="s1">'zh-cn'</span><span class="p">:</span> <span class="s1">'gb18030'</span><span class="p">,</span>
    <span class="s1">'win-1251'</span><span class="p">:</span> <span class="s1">'cp1251'</span><span class="p">,</span>
    <span class="s1">'macintosh'</span> <span class="p">:</span> <span class="s1">'mac_roman'</span><span class="p">,</span>
    <span class="s1">'x-sjis'</span><span class="p">:</span> <span class="s1">'shift_jis'</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The default encoding aliases defined in Scrapy. Don’t override this setting in
your project, override <a class="reference internal" href="#std:setting-ENCODING_ALIASES"><code class="xref std std-setting docutils literal"><span class="pre">ENCODING_ALIASES</span></code></a> instead.</p>
<p>The reason why <a class="reference external" href="http://en.wikipedia.org/wiki/ISO/IEC_8859-1">ISO-8859-1</a> (and all its aliases) are mapped to <a class="reference external" href="http://en.wikipedia.org/wiki/Windows-1252">CP1252</a> is
due to a well known browser hack. For more information see: <a class="reference external" href="http://en.wikipedia.org/wiki/Character_encodings_in_HTML">Character
encodings in HTML</a>.</p>
</div>
<div class="section" id="extensions">
<span id="std:setting-EXTENSIONS"></span><h3>EXTENSIONS<a class="headerlink" href="#extensions" title="Permalink to this headline">¶</a></h3>
<p>Default:: <code class="docutils literal"><span class="pre">{}</span></code></p>
<p>A dict containing the extensions enabled in your project, and their orders.</p>
</div>
<div class="section" id="extensions-base">
<span id="std:setting-EXTENSIONS_BASE"></span><h3>EXTENSIONS_BASE<a class="headerlink" href="#extensions-base" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">'scrapy.contrib.corestats.CoreStats'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.webservice.WebService'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.telnet.TelnetConsole'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.memusage.MemoryUsage'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.memdebug.MemoryDebugger'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.closedomain.CloseDomain'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The list of available extensions. Keep in mind that some of them need to
be enabled through a setting. By default, this setting contains all stable
built-in extensions.</p>
<p>For more information See the <a class="reference internal" href="extensions.html#topics-extensions"><span>extensions user guide</span></a>
and the <a class="reference internal" href="extensions.html#topics-extensions-ref"><span>list of available extensions</span></a>.</p>
</div>
<div class="section" id="item-pipelines">
<span id="std:setting-ITEM_PIPELINES"></span><h3>ITEM_PIPELINES<a class="headerlink" href="#item-pipelines" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">[]</span></code></p>
<p>The item pipelines to use (a list of classes).</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">'mybot.pipeline.validate.ValidateMyItem'</span><span class="p">,</span>
    <span class="s1">'mybot.pipeline.validate.StoreMyItem'</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="log-enabled">
<span id="std:setting-LOG_ENABLED"></span><h3>LOG_ENABLED<a class="headerlink" href="#log-enabled" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">True</span></code></p>
<p>Whether to enable logging.</p>
</div>
<div class="section" id="log-encoding">
<span id="std:setting-LOG_ENCODING"></span><h3>LOG_ENCODING<a class="headerlink" href="#log-encoding" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">'utf-8'</span></code></p>
<p>The encoding to use for logging.</p>
</div>
<div class="section" id="log-file">
<span id="std:setting-LOG_FILE"></span><h3>LOG_FILE<a class="headerlink" href="#log-file" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">None</span></code></p>
<p>File name to use for logging output. If None, standard error will be used.</p>
</div>
<div class="section" id="log-level">
<span id="std:setting-LOG_LEVEL"></span><h3>LOG_LEVEL<a class="headerlink" href="#log-level" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">'DEBUG'</span></code></p>
<p>Minimum level to log. Available levels are: CRITICAL, ERROR, WARNING,
INFO, DEBUG. For more info see <a class="reference internal" href="logging.html#topics-logging"><span>Logging</span></a>.</p>
</div>
<div class="section" id="log-stdout">
<span id="std:setting-LOG_STDOUT"></span><h3>LOG_STDOUT<a class="headerlink" href="#log-stdout" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">False</span></code></p>
<p>If <code class="docutils literal"><span class="pre">True</span></code>, all standard output (and error) of your process will be redirected
to the log. For example if you <code class="docutils literal"><span class="pre">print</span> <span class="pre">'hello'</span></code> it will appear in the Scrapy
log.</p>
</div>
<div class="section" id="memdebug-enabled">
<span id="std:setting-MEMDEBUG_ENABLED"></span><h3>MEMDEBUG_ENABLED<a class="headerlink" href="#memdebug-enabled" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">False</span></code></p>
<p>Whether to enable memory debugging.</p>
</div>
<div class="section" id="memdebug-notify">
<span id="std:setting-MEMDEBUG_NOTIFY"></span><h3>MEMDEBUG_NOTIFY<a class="headerlink" href="#memdebug-notify" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">[]</span></code></p>
<p>When memory debugging is enabled a memory report will be sent to the specified
addresses if this setting is not empty, otherwise the report will be written to
the log.</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">MEMDEBUG_NOTIFY</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'user@example.com'</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="memusage-enabled">
<span id="std:setting-MEMUSAGE_ENABLED"></span><h3>MEMUSAGE_ENABLED<a class="headerlink" href="#memusage-enabled" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">False</span></code></p>
<p>Scope: <code class="docutils literal"><span class="pre">scrapy.contrib.memusage</span></code></p>
<p>Whether to enable the memory usage extension that will shutdown the Scrapy
process when it exceeds a memory limit, and also notify by email when that
happened.</p>
<p>See <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><span>Memory usage extension</span></a>.</p>
</div>
<div class="section" id="memusage-limit-mb">
<span id="std:setting-MEMUSAGE_LIMIT_MB"></span><h3>MEMUSAGE_LIMIT_MB<a class="headerlink" href="#memusage-limit-mb" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">0</span></code></p>
<p>Scope: <code class="docutils literal"><span class="pre">scrapy.contrib.memusage</span></code></p>
<p>The maximum amount of memory to allow (in megabytes) before shutting down
Scrapy  (if MEMUSAGE_ENABLED is True). If zero, no check will be performed.</p>
<p>See <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><span>Memory usage extension</span></a>.</p>
</div>
<div class="section" id="memusage-notify-mail">
<span id="std:setting-MEMUSAGE_NOTIFY_MAIL"></span><h3>MEMUSAGE_NOTIFY_MAIL<a class="headerlink" href="#memusage-notify-mail" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">False</span></code></p>
<p>Scope: <code class="docutils literal"><span class="pre">scrapy.contrib.memusage</span></code></p>
<p>A list of emails to notify if the memory limit has been reached.</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">MEMUSAGE_NOTIFY_MAIL</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'user@example.com'</span><span class="p">]</span>
</pre></div>
</div>
<p>See <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><span>Memory usage extension</span></a>.</p>
</div>
<div class="section" id="memusage-report">
<span id="std:setting-MEMUSAGE_REPORT"></span><h3>MEMUSAGE_REPORT<a class="headerlink" href="#memusage-report" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">False</span></code></p>
<p>Scope: <code class="docutils literal"><span class="pre">scrapy.contrib.memusage</span></code></p>
<p>Whether to send a memory usage report after each domain has been closed.</p>
<p>See <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><span>Memory usage extension</span></a>.</p>
</div>
<div class="section" id="memusage-warning-mb">
<span id="std:setting-MEMUSAGE_WARNING_MB"></span><h3>MEMUSAGE_WARNING_MB<a class="headerlink" href="#memusage-warning-mb" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">0</span></code></p>
<p>Scope: <code class="docutils literal"><span class="pre">scrapy.contrib.memusage</span></code></p>
<p>The maximum amount of memory to allow (in megabytes) before sending a warning
email notifying about it. If zero, no warning will be produced.</p>
</div>
<div class="section" id="newspider-module">
<span id="std:setting-NEWSPIDER_MODULE"></span><h3>NEWSPIDER_MODULE<a class="headerlink" href="#newspider-module" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">''</span></code></p>
<p>Module where to create new spiders using the <a class="reference internal" href="commands.html#std:command-genspider"><code class="xref std std-command docutils literal"><span class="pre">genspider</span></code></a> command.</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">NEWSPIDER_MODULE</span> <span class="o">=</span> <span class="s1">'mybot.spiders_dev'</span>
</pre></div>
</div>
</div>
<div class="section" id="randomize-download-delay">
<span id="std:setting-RANDOMIZE_DOWNLOAD_DELAY"></span><h3>RANDOMIZE_DOWNLOAD_DELAY<a class="headerlink" href="#randomize-download-delay" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">True</span></code></p>
<p>If enabled, Scrapy will wait a random amount of time (between 0.5 and 1.5
* <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_DELAY</span></code></a>) while fetching requests from the same
spider.</p>
<p>This randomization decreases the chance of the crawler being detected (and
subsequently blocked) by sites which analyze requests looking for statistically
significant similarities in the time between their requests.</p>
<p>The randomization policy is the same used by <a class="reference external" href="http://www.gnu.org/software/wget/manual/wget.html">wget</a> <code class="docutils literal"><span class="pre">--random-wait</span></code> option.</p>
<p>If <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_DELAY</span></code></a> is zero (default) this option has no effect.</p>
</div>
<div class="section" id="redirect-max-times">
<span id="std:setting-REDIRECT_MAX_TIMES"></span><h3>REDIRECT_MAX_TIMES<a class="headerlink" href="#redirect-max-times" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">20</span></code></p>
<p>Defines the maximun times a request can be redirected. After this maximun the
request’s response is returned as is. We used Firefox default value for the
same task.</p>
</div>
<div class="section" id="redirect-max-metarefresh-delay">
<span id="std:setting-REDIRECT_MAX_METAREFRESH_DELAY"></span><h3>REDIRECT_MAX_METAREFRESH_DELAY<a class="headerlink" href="#redirect-max-metarefresh-delay" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">100</span></code></p>
<p>Some sites use meta-refresh for redirecting to a session expired page, so we
restrict automatic redirection to a maximum delay (in seconds)</p>
</div>
<div class="section" id="redirect-priority-adjust">
<span id="std:setting-REDIRECT_PRIORITY_ADJUST"></span><h3>REDIRECT_PRIORITY_ADJUST<a class="headerlink" href="#redirect-priority-adjust" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">+2</span></code></p>
<p>Adjust redirect request priority relative to original request.
A negative priority adjust means more priority.</p>
</div>
<div class="section" id="robotstxt-obey">
<span id="std:setting-ROBOTSTXT_OBEY"></span><h3>ROBOTSTXT_OBEY<a class="headerlink" href="#robotstxt-obey" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">False</span></code></p>
<p>Scope: <code class="docutils literal"><span class="pre">scrapy.contrib.downloadermiddleware.robotstxt</span></code></p>
<p>If enabled, Scrapy will respect robots.txt policies. For more information see
<a class="reference internal" href="downloader-middleware.html#topics-dlmw-robots"><span>RobotsTxtMiddleware</span></a></p>
</div>
<div class="section" id="scheduler">
<span id="std:setting-SCHEDULER"></span><h3>SCHEDULER<a class="headerlink" href="#scheduler" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">'scrapy.core.scheduler.Scheduler'</span></code></p>
<p>The scheduler to use for crawling.</p>
</div>
<div class="section" id="scheduler-order">
<span id="std:setting-SCHEDULER_ORDER"></span><h3>SCHEDULER_ORDER<a class="headerlink" href="#scheduler-order" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">'DFO'</span></code></p>
<p>Scope: <code class="docutils literal"><span class="pre">scrapy.core.scheduler</span></code></p>
<p>The order to use for the crawling scheduler. Available orders are:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">'BFO'</span></code>:  <a class="reference external" href="http://en.wikipedia.org/wiki/Breadth-first_search">Breadth-first order</a> - typically consumes more memory but
reaches most relevant pages earlier.</li>
<li><code class="docutils literal"><span class="pre">'DFO'</span></code>:  <a class="reference external" href="http://en.wikipedia.org/wiki/Depth-first_search">Depth-first order</a> - typically consumes less memory than
but takes longer to reach most relevant pages.</li>
</ul>
</div>
<div class="section" id="scheduler-middlewares">
<span id="std:setting-SCHEDULER_MIDDLEWARES"></span><h3>SCHEDULER_MIDDLEWARES<a class="headerlink" href="#scheduler-middlewares" title="Permalink to this headline">¶</a></h3>
<p>Default:: <code class="docutils literal"><span class="pre">{}</span></code></p>
<p>A dict containing the scheduler middlewares enabled in your project, and their
orders.</p>
</div>
<div class="section" id="scheduler-middlewares-base">
<span id="std:setting-SCHEDULER_MIDDLEWARES_BASE"></span><h3>SCHEDULER_MIDDLEWARES_BASE<a class="headerlink" href="#scheduler-middlewares-base" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">SCHEDULER_MIDDLEWARES_BASE</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'scrapy.contrib.schedulermiddleware.duplicatesfilter.DuplicatesFilterMiddleware'</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>A dict containing the scheduler middlewares enabled by default in Scrapy. You
should never modify this setting in your project, modify
<a class="reference internal" href="#std:setting-SCHEDULER_MIDDLEWARES"><code class="xref std std-setting docutils literal"><span class="pre">SCHEDULER_MIDDLEWARES</span></code></a> instead.</p>
</div>
<div class="section" id="spider-middlewares">
<span id="std:setting-SPIDER_MIDDLEWARES"></span><h3>SPIDER_MIDDLEWARES<a class="headerlink" href="#spider-middlewares" title="Permalink to this headline">¶</a></h3>
<p>Default:: <code class="docutils literal"><span class="pre">{}</span></code></p>
<p>A dict containing the spider middlewares enabled in your project, and their
orders. For more info see <a class="reference internal" href="spider-middleware.html#topics-spider-middleware-setting"><span>Activating a spider middleware</span></a>.</p>
</div>
<div class="section" id="spider-middlewares-base">
<span id="std:setting-SPIDER_MIDDLEWARES_BASE"></span><h3>SPIDER_MIDDLEWARES_BASE<a class="headerlink" href="#spider-middlewares-base" title="Permalink to this headline">¶</a></h3>
<p>Default:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">'scrapy.contrib.spidermiddleware.httperror.HttpErrorMiddleware'</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.itemsampler.ItemSamplerMiddleware'</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.spidermiddleware.offsite.OffsiteMiddleware'</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.spidermiddleware.referer.RefererMiddleware'</span><span class="p">:</span> <span class="mi">700</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.spidermiddleware.urllength.UrlLengthMiddleware'</span><span class="p">:</span> <span class="mi">800</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.spidermiddleware.depth.DepthMiddleware'</span><span class="p">:</span> <span class="mi">900</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>A dict containing the spider middlewares enabled by default in Scrapy. You
should never modify this setting in your project, modify
<a class="reference internal" href="#std:setting-SPIDER_MIDDLEWARES"><code class="xref std std-setting docutils literal"><span class="pre">SPIDER_MIDDLEWARES</span></code></a> instead. For more info see
<a class="reference internal" href="spider-middleware.html#topics-spider-middleware-setting"><span>Activating a spider middleware</span></a>.</p>
</div>
<div class="section" id="spider-modules">
<span id="std:setting-SPIDER_MODULES"></span><h3>SPIDER_MODULES<a class="headerlink" href="#spider-modules" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">[]</span></code></p>
<p>A list of modules where Scrapy will look for spiders.</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">SPIDER_MODULES</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'mybot.spiders_prod'</span><span class="p">,</span> <span class="s1">'mybot.spiders_dev'</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="sqlite-db">
<span id="std:setting-SQLITE_DB"></span><h3>SQLITE_DB<a class="headerlink" href="#sqlite-db" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">'scrapy.db'</span></code></p>
<p>The location of the project SQLite database, used for storing the spider queue
and other persistent data of the project. If a relative path is given, is taken
relative to the project data dir. For more info see:
<a class="reference internal" href="commands.html#topics-project-structure"><span>Default structure of Scrapy projects</span></a>.</p>
</div>
<div class="section" id="stats-class">
<span id="std:setting-STATS_CLASS"></span><h3>STATS_CLASS<a class="headerlink" href="#stats-class" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">'scrapy.statscol.MemoryStatsCollector'</span></code></p>
<p>The class to use for collecting stats (must implement the Stats Collector API,
or subclass the StatsCollector class).</p>
</div>
<div class="section" id="stats-dump">
<span id="std:setting-STATS_DUMP"></span><h3>STATS_DUMP<a class="headerlink" href="#stats-dump" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">False</span></code></p>
<p>Dump (to log) domain-specific stats collected when a domain is closed, and all
global stats when the Scrapy process finishes (ie. when the engine is
shutdown).</p>
</div>
<div class="section" id="stats-enabled">
<span id="std:setting-STATS_ENABLED"></span><h3>STATS_ENABLED<a class="headerlink" href="#stats-enabled" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">True</span></code></p>
<p>Enable stats collection.</p>
</div>
<div class="section" id="statsmailer-rcpts">
<span id="std:setting-STATSMAILER_RCPTS"></span><h3>STATSMAILER_RCPTS<a class="headerlink" href="#statsmailer-rcpts" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">[]</span></code> (empty list)</p>
<p>Send Scrapy stats after domains finish scraping. See
<code class="xref py py-class docutils literal"><span class="pre">StatsMailer</span></code> for more info.</p>
</div>
<div class="section" id="telnetconsole-enabled">
<span id="std:setting-TELNETCONSOLE_ENABLED"></span><h3>TELNETCONSOLE_ENABLED<a class="headerlink" href="#telnetconsole-enabled" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">True</span></code></p>
<p>A boolean which specifies if the <a class="reference internal" href="telnetconsole.html#topics-telnetconsole"><span>telnet console</span></a>
will be enabled (provided its extension is also enabled).</p>
</div>
<div class="section" id="telnetconsole-port">
<span id="std:setting-TELNETCONSOLE_PORT"></span><h3>TELNETCONSOLE_PORT<a class="headerlink" href="#telnetconsole-port" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">[6023,</span> <span class="pre">6073]</span></code></p>
<p>The port range to use for the telnet console. If set to <code class="docutils literal"><span class="pre">None</span></code> or <code class="docutils literal"><span class="pre">0</span></code>, a
dynamically assigned port is used. For more info see
<a class="reference internal" href="telnetconsole.html#topics-telnetconsole"><span>Telnet Console</span></a>.</p>
</div>
<div class="section" id="templates-dir">
<span id="std:setting-TEMPLATES_DIR"></span><h3>TEMPLATES_DIR<a class="headerlink" href="#templates-dir" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">templates</span></code> dir inside scrapy module</p>
<p>The directory where to look for templates when creating new projects with
<a class="reference internal" href="commands.html#std:command-startproject"><code class="xref std std-command docutils literal"><span class="pre">startproject</span></code></a> command.</p>
</div>
<div class="section" id="urllength-limit">
<span id="std:setting-URLLENGTH_LIMIT"></span><h3>URLLENGTH_LIMIT<a class="headerlink" href="#urllength-limit" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">2083</span></code></p>
<p>Scope: <code class="docutils literal"><span class="pre">contrib.spidermiddleware.urllength</span></code></p>
<p>The maximum URL length to allow for crawled URLs. For more information about
the default value for this setting see: <a class="reference external" href="http://www.boutell.com/newfaq/misc/urllength.html">http://www.boutell.com/newfaq/misc/urllength.html</a></p>
</div>
<div class="section" id="user-agent">
<span id="std:setting-USER_AGENT"></span><h3>USER_AGENT<a class="headerlink" href="#user-agent" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal"><span class="pre">"%s/%s"</span> <span class="pre">%</span> <span class="pre">(BOT_NAME,</span> <span class="pre">BOT_VERSION)</span></code></p>
<p>The default User-Agent to use when crawling, unless overridden.</p>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="signals.html" class="btn btn-neutral float-right" title="Signals" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="request-response.html" class="btn btn-neutral" title="Requests and Responses" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr /><div><div id="rtd-uxokzi2q" class="ethical-rtd"></div></div>

  <div role="contentinfo">
    <p>
        © Copyright 2008-2011, Insophia.
      
        <span class="commit">
          Revision <code>fac5e5ea</code>.
        </span>
      

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: 0.12
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Versions</dt>
        
          <dd><a href="/en/latest/">latest</a></dd>
        
          <dd><a href="/en/stable/">stable</a></dd>
        
          <dd><a href="/en/master/">master</a></dd>
        
          <dd><a href="/en/1.1/">1.1</a></dd>
        
          <dd><a href="/en/1.0/">1.0</a></dd>
        
          <dd><a href="/en/0.24/">0.24</a></dd>
        
          <dd><a href="/en/0.22/">0.22</a></dd>
        
          <dd><a href="/en/0.20/">0.20</a></dd>
        
          <dd><a href="/en/0.18/">0.18</a></dd>
        
          <dd><a href="/en/0.16/">0.16</a></dd>
        
          <dd><a href="/en/0.14/">0.14</a></dd>
        
          <dd><a href="/en/0.12/">0.12</a></dd>
        
          <dd><a href="/en/0.10.3/">0.10.3</a></dd>
        
          <dd><a href="/en/0.9/">0.9</a></dd>
        
      </dl>
      <dl>
        <dt>Downloads</dt>
        
          <dd><a href="//readthedocs.org/projects/scrapy/downloads/pdf/0.12/">pdf</a></dd>
        
      </dl>
      <dl>
        <dt>On Read the Docs</dt>
          <dd>
            <a href="//readthedocs.org/projects/scrapy/?fromdocs=scrapy">Project Home</a>
          </dd>
          <dd>
            <a href="//readthedocs.org/builds/scrapy/?fromdocs=scrapy">Builds</a>
          </dd>
      </dl>
      <hr />
      Free document hosting provided by <a href="http://www.readthedocs.org">Read the Docs</a>.

    </div>
  </div>



  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.12.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-2.0.3.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-migrate-1.2.1.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/underscore.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/doctools.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/readthedocs-doc-embed.js"></script>

  

  
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   


<div id="rtd-0gc78vas"></div></body></html>