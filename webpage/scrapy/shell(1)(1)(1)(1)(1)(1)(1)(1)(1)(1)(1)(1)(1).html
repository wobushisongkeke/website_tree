<!DOCTYPE html><!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]--><!--[if gt IE 8]><!--><html xmlns="http://www.w3.org/1999/xhtml" class=" js flexbox canvas canvastext webgl no-touch geolocation postmessage websqldatabase indexeddb hashchange history draganddrop websockets rgba hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients cssreflections csstransforms csstransforms3d csstransitions fontface generatedcontent video audio localstorage sessionstorage webworkers applicationcache svg inlinesvg smil svgclippaths" lang="en" style=""><!--<![endif]--><head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Scrapy shell — Scrapy 0.18.4 documentation</title>
  

  
  

  

  
  
    

  

  
  

  
    <link rel="stylesheet" href="https://media.readthedocs.org/css/sphinx_rtd_theme.css" type="text/css" />
  

  
    <link rel="top" title="Scrapy 0.18.4 documentation" href="../index.html" />
        <link rel="next" title="Item Pipeline" href="item-pipeline.html" />
        <link rel="prev" title="Item Loaders" href="loaders.html" /> 

  
  <script type="text/javascript" async="" src="https://ssl.google-analytics.com/ga.js"></script><script src="../_static/js/modernizr.min.js"></script>


<!-- RTD Extra Head -->

<!-- 
Always link to the latest version, as canonical.
http://docs.readthedocs.org/en/latest/canonical.html
-->
<link rel="canonical" href="http://doc.scrapy.org/en/latest/topics/shell.html" />

<link rel="stylesheet" href="https://media.readthedocs.org/css/readthedocs-doc-embed.css" type="text/css" />

<script type="text/javascript" src="../_static/readthedocs-data.js"></script>

<!-- Add page-specific data, which must exist in the page js, not global -->
<script type="text/javascript">
READTHEDOCS_DATA['page'] = 'topics/shell'
</script>

<script type="text/javascript" src="../_static/readthedocs-dynamic-include.js"></script>

<!-- end RTD <extrahead> --></head>

<body class="wy-body-for-nav" role="document" style="">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Scrapy
          

          
          </a>

          
            
            
            
              <div class="version">
                0.18
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/overview.html">Scrapy at a glance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/install.html">Installation guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/tutorial.html">Scrapy Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/examples.html">Examples</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="commands.html">Command line tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="items.html">Items</a></li>
<li class="toctree-l1"><a class="reference internal" href="spiders.html">Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="link-extractors.html">Link Extractors</a></li>
<li class="toctree-l1"><a class="reference internal" href="selectors.html">Selectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="loaders.html">Item Loaders</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href=""><span class="toctree-expand"></span>Scrapy shell</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#launch-the-shell">Launch the shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-the-shell"><span class="toctree-expand"></span>Using the shell</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#available-shortcuts">Available Shortcuts</a></li>
<li class="toctree-l3"><a class="reference internal" href="#available-scrapy-objects">Available Scrapy objects</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#example-of-shell-session">Example of shell session</a></li>
<li class="toctree-l2"><a class="reference internal" href="#invoking-the-shell-from-spiders-to-inspect-responses">Invoking the shell from spiders to inspect responses</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="item-pipeline.html">Item Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="feed-exports.html">Feed exports</a></li>
<li class="toctree-l1"><a class="reference internal" href="link-extractors.html">Link Extractors</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="stats.html">Stats Collection</a></li>
<li class="toctree-l1"><a class="reference internal" href="email.html">Sending e-mail</a></li>
<li class="toctree-l1"><a class="reference internal" href="telnetconsole.html">Telnet Console</a></li>
<li class="toctree-l1"><a class="reference internal" href="webservice.html">Web Service</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="debug.html">Debugging Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="contracts.html">Spiders Contracts</a></li>
<li class="toctree-l1"><a class="reference internal" href="practices.html">Common Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="broad-crawls.html">Broad Crawls</a></li>
<li class="toctree-l1"><a class="reference internal" href="firefox.html">Using Firefox for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="firebug.html">Using Firebug for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="leaks.html">Debugging memory leaks</a></li>
<li class="toctree-l1"><a class="reference internal" href="images.html">Downloading Item Images</a></li>
<li class="toctree-l1"><a class="reference internal" href="ubuntu.html">Ubuntu packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="scrapyd.html">Scrapyd</a></li>
<li class="toctree-l1"><a class="reference internal" href="autothrottle.html">AutoThrottle extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="jobs.html">Jobs: pausing and resuming crawls</a></li>
<li class="toctree-l1"><a class="reference internal" href="djangoitem.html">DjangoItem</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="downloader-middleware.html">Downloader Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="spider-middleware.html">Spider Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="extensions.html">Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">Core API</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="request-response.html">Requests and Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="signals.html">Signals</a></li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">Exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="exporters.html">Item Exporters</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html">Versioning and API Stability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../experimental/index.html">Experimental features</a></li>
</ul>

            
          
        </div>
      <div id="rtd-vfok5ih6" class="ethical-rtd ethical-dark-theme"></div></div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">Scrapy</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> »</li>
      
    <li>Scrapy shell</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="https://github.com/scrapy/scrapy/blob/0.18/docs/topics/shell.rst" class="fa fa-github"> Edit on GitHub</a>
          
        
      </li>
  </ul>
  <hr />
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="scrapy-shell">
<span id="topics-shell"></span><h1>Scrapy shell<a class="headerlink" href="#scrapy-shell" title="Permalink to this headline">¶</a></h1>
<p>The Scrapy shell is an interactive shell where you can try and debug your
scraping code very quickly, without having to run the spider. It’s meant to be
used for testing data extraction code, but you can actually use it for testing
any kind of code as it is also a regular Python shell.</p>
<p>The shell is used for testing XPath expressions and see how they work and what
data they extract from the web pages you’re trying to scrape. It allows you to
interactively test your XPaths while you’re writing your spider, without having
to run the spider to test every change.</p>
<p>Once you get familiarized with the Scrapy shell, you’ll see that it’s an
invaluable tool for developing and debugging your spiders.</p>
<p>If you have <a class="reference external" href="http://ipython.scipy.org/">IPython</a> installed, the Scrapy shell will use it (instead of the
standard Python console). The <a class="reference external" href="http://ipython.scipy.org/">IPython</a> console is much more powerful and
provides smart auto-completion and colorized output, among other things.</p>
<p>We highly recommend you install <a class="reference external" href="http://ipython.scipy.org/">IPython</a>, specially if you’re working on
Unix systems (where <a class="reference external" href="http://ipython.scipy.org/">IPython</a> excels). See the <a class="reference external" href="http://ipython.scipy.org/doc/rel-0.9.1/html/install/index.html">IPython installation guide</a>
for more info.</p>
<div class="section" id="launch-the-shell">
<h2>Launch the shell<a class="headerlink" href="#launch-the-shell" title="Permalink to this headline">¶</a></h2>
<p>To launch the Scrapy shell you can use the <a class="reference internal" href="commands.html#std:command-shell"><code class="xref std std-command docutils literal"><span class="pre">shell</span></code></a> command like
this:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>scrapy shell &lt;url&gt;
</pre></div>
</div>
<p>Where the <code class="docutils literal"><span class="pre">&lt;url&gt;</span></code> is the URL you want to scrape.</p>
</div>
<div class="section" id="using-the-shell">
<h2>Using the shell<a class="headerlink" href="#using-the-shell" title="Permalink to this headline">¶</a></h2>
<p>The Scrapy shell is just a regular Python console (or <cite>IPython</cite> console if you
have it available) which provides some additional shortcut functions for
convenience.</p>
<div class="section" id="available-shortcuts">
<h3>Available Shortcuts<a class="headerlink" href="#available-shortcuts" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal"><span class="pre">shelp()</span></code> - print a help with the list of available objects and shortcuts</li>
<li><code class="docutils literal"><span class="pre">fetch(request_or_url)</span></code> - fetch a new response from the given request or
URL and update all related objects accordingly.</li>
<li><code class="docutils literal"><span class="pre">view(response)</span></code> - open the given response in your local web browser, for
inspection. This will add a <a class="reference external" href="http://www.w3schools.com/TAGS/tag_base.asp">&lt;base&gt; tag</a> to the response body in order
for external links (such as images and style sheets) to display properly.
Note, however,that this will create a temporary file in your computer,
which won’t be removed automatically.</li>
</ul>
</div></blockquote>
</div>
<div class="section" id="available-scrapy-objects">
<h3>Available Scrapy objects<a class="headerlink" href="#available-scrapy-objects" title="Permalink to this headline">¶</a></h3>
<p>The Scrapy shell automatically creates some convenient objects from the
downloaded page, like the <a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><code class="xref py py-class docutils literal"><span class="pre">Response</span></code></a> object and the
<a class="reference internal" href="selectors.html#scrapy.selector.XPathSelector" title="scrapy.selector.XPathSelector"><code class="xref py py-class docutils literal"><span class="pre">XPathSelector</span></code></a> objects (for both HTML and XML
content).</p>
<p>Those objects are:</p>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal"><span class="pre">spider</span></code> - the Spider which is known to handle the URL, or a
<a class="reference internal" href="spiders.html#scrapy.spider.BaseSpider" title="scrapy.spider.BaseSpider"><code class="xref py py-class docutils literal"><span class="pre">BaseSpider</span></code></a> object if there is no spider found for
the current URL</li>
<li><code class="docutils literal"><span class="pre">request</span></code> - a <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal"><span class="pre">Request</span></code></a> object of the last fetched
page. You can modify this request using <a class="reference internal" href="request-response.html#scrapy.http.Request.replace" title="scrapy.http.Request.replace"><code class="xref py py-meth docutils literal"><span class="pre">replace()</span></code></a> or
fetch a new request (without leaving the shell) using the <code class="docutils literal"><span class="pre">fetch</span></code>
shortcut.</li>
<li><code class="docutils literal"><span class="pre">response</span></code> - a <a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><code class="xref py py-class docutils literal"><span class="pre">Response</span></code></a> object containing the last
fetched page</li>
<li><code class="docutils literal"><span class="pre">hxs</span></code> - a <a class="reference internal" href="selectors.html#scrapy.selector.HtmlXPathSelector" title="scrapy.selector.HtmlXPathSelector"><code class="xref py py-class docutils literal"><span class="pre">HtmlXPathSelector</span></code></a> object constructed
with the last response fetched</li>
<li><code class="docutils literal"><span class="pre">xxs</span></code> - a <a class="reference internal" href="selectors.html#scrapy.selector.XmlXPathSelector" title="scrapy.selector.XmlXPathSelector"><code class="xref py py-class docutils literal"><span class="pre">XmlXPathSelector</span></code></a> object constructed
with the last response fetched</li>
<li><code class="docutils literal"><span class="pre">settings</span></code> - the current <a class="reference internal" href="settings.html#topics-settings"><span>Scrapy settings</span></a></li>
</ul>
</div></blockquote>
</div>
</div>
<div class="section" id="example-of-shell-session">
<h2>Example of shell session<a class="headerlink" href="#example-of-shell-session" title="Permalink to this headline">¶</a></h2>
<p>Here’s an example of a typical shell session where we start by scraping the
<a class="reference external" href="http://scrapy.org">http://scrapy.org</a> page, and then proceed to scrape the <a class="reference external" href="http://slashdot.org">http://slashdot.org</a>
page. Finally, we modify the (Slashdot) request method to POST and re-fetch it
getting a HTTP 405 (method not allowed) error. We end the session by typing
Ctrl-D (in Unix systems) or Ctrl-Z in Windows.</p>
<p>Keep in mind that the data extracted here may not be the same when you try it,
as those pages are not static and could have changed by the time you test this.
The only purpose of this example is to get you familiarized with how the Scrapy
shell works.</p>
<p>First, we launch the shell:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>scrapy shell http://scrapy.org --nolog
</pre></div>
</div>
<p>Then, the shell fetches the URL (using the Scrapy downloader) and prints the
list of available objects and useful shortcuts (you’ll notice that these lines
all start with the <code class="docutils literal"><span class="pre">[s]</span></code> prefix):</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>[s] Available objects
[s]   hxs       &lt;HtmlXPathSelector (http://scrapy.org) xpath=None&gt;
[s]   item      Item()
[s]   request   &lt;http://scrapy.org&gt;
[s]   response  &lt;http://scrapy.org&gt;
[s]   settings  &lt;Settings 'mybot.settings'&gt;
[s]   spider    &lt;scrapy.spider.models.BaseSpider object at 0x2bed9d0&gt;
[s]   xxs       &lt;XmlXPathSelector (http://scrapy.org) xpath=None&gt;
[s] Useful shortcuts:
[s]   shelp()           Prints this help.
[s]   fetch(req_or_url) Fetch a new request or URL and update objects
[s]   view(response)    View response in a browser

&gt;&gt;&gt;
</pre></div>
</div>
<p>After that, we can star playing with the objects:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">"//h2/text()"</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">u'Welcome to Scrapy'</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">fetch</span><span class="p">(</span><span class="s2">"http://slashdot.org"</span><span class="p">)</span>
<span class="go">[s] Available Scrapy objects:</span>
<span class="go">[s]   hxs        &lt;HtmlXPathSelector (http://slashdot.org) xpath=None&gt;</span>
<span class="go">[s]   item       JobItem()</span>
<span class="go">[s]   request    &lt;GET http://slashdot.org&gt;</span>
<span class="go">[s]   response   &lt;200 http://slashdot.org&gt;</span>
<span class="go">[s]   settings   &lt;Settings 'jobsbot.settings'&gt;</span>
<span class="go">[s]   spider     &lt;BaseSpider 'default' at 0x3c44a10&gt;</span>
<span class="go">[s]   xxs        &lt;XmlXPathSelector (http://slashdot.org) xpath=None&gt;</span>
<span class="go">[s] Useful shortcuts:</span>
<span class="go">[s]   shelp()           Shell help (print this help)</span>
<span class="go">[s]   fetch(req_or_url) Fetch request (or URL) and update local objects</span>
<span class="go">[s]   view(response)    View response in a browser</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">"//h2/text()"</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
<span class="go">[u'News for nerds, stuff that matters']</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">request</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">"POST"</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">fetch</span><span class="p">(</span><span class="n">request</span><span class="p">)</span>
<span class="go">2009-04-03 00:57:39-0300 [default] ERROR: Downloading &lt;http://slashdot.org&gt; from &lt;None&gt;: 405 Method Not Allowed</span>

<span class="go">&gt;&gt;&gt;</span>
</pre></div>
</div>
</div>
<div class="section" id="invoking-the-shell-from-spiders-to-inspect-responses">
<span id="topics-shell-inspect-response"></span><h2>Invoking the shell from spiders to inspect responses<a class="headerlink" href="#invoking-the-shell-from-spiders-to-inspect-responses" title="Permalink to this headline">¶</a></h2>
<p>Sometimes you want to inspect the responses that are being processed in a
certain point of your spider, if only to check that response you expect is
getting there.</p>
<p>This can be achieved by using the <code class="docutils literal"><span class="pre">scrapy.shell.inspect_response</span></code> function.</p>
<p>Here’s an example of how you would call it from your spider:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">BaseSpider</span><span class="p">):</span>
    <span class="o">...</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span> <span class="o">==</span> <span class="s1">'http://www.example.com/products.php'</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">scrapy.shell</span> <span class="kn">import</span> <span class="n">inspect_response</span>
            <span class="n">inspect_response</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>

        <span class="c1"># ... your parsing code ..</span>
</pre></div>
</div>
<p>When you run the spider, you will get something similar to this:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>2009-08-27 19:15:25-0300 [example.com] DEBUG: Crawled &lt;http://www.example.com/&gt; (referer: &lt;None&gt;)
2009-08-27 19:15:26-0300 [example.com] DEBUG: Crawled &lt;http://www.example.com/products.php&gt; (referer: &lt;http://www.example.com/&gt;)
[s] Available objects
[s]   hxs       &lt;HtmlXPathSelector (http://www.example.com/products.php) xpath=None&gt;
...

&gt;&gt;&gt; response.url
'http://www.example.com/products.php'
</pre></div>
</div>
<p>Then, you can check if the extraction code is working:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hxs</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s1">'//h1'</span><span class="p">)</span>
<span class="go">[]</span>
</pre></div>
</div>
<p>Nope, it doesn’t. So you can open the response in your web browser and see if
it’s the response you were expecting:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">view</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
</pre></div>
</div>
<p>Finally you hit Ctrl-D (or Ctrl-Z in Windows) to exit the shell and resume the
crawling:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="o">^</span><span class="n">D</span>
<span class="go">2009-08-27 19:15:25-0300 [example.com] DEBUG: Crawled &lt;http://www.example.com/product.php?id=1&gt; (referer: &lt;None&gt;)</span>
<span class="go">2009-08-27 19:15:25-0300 [example.com] DEBUG: Crawled &lt;http://www.example.com/product.php?id=2&gt; (referer: &lt;None&gt;)</span>
<span class="go"># ...</span>
</pre></div>
</div>
<p>Note that you can’t use the <code class="docutils literal"><span class="pre">fetch</span></code> shortcut here since the Scrapy engine is
blocked by the shell. However, after you leave the shell, the spider will
continue crawling where it stopped, as shown above.</p>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="item-pipeline.html" class="btn btn-neutral float-right" title="Item Pipeline" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="loaders.html" class="btn btn-neutral" title="Item Loaders" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr /><div><div id="rtd-nm72lom5" class="ethical-rtd"></div></div>

  <div role="contentinfo">
    <p>
        © Copyright 2008-2013, Scrapy developers.
      
        <span class="commit">
          Revision <code>dc43890b</code>.
        </span>
      

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: 0.18
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Versions</dt>
        
          <dd><a href="/en/latest/">latest</a></dd>
        
          <dd><a href="/en/stable/">stable</a></dd>
        
          <dd><a href="/en/master/">master</a></dd>
        
          <dd><a href="/en/1.1/">1.1</a></dd>
        
          <dd><a href="/en/1.0/">1.0</a></dd>
        
          <dd><a href="/en/0.24/">0.24</a></dd>
        
          <dd><a href="/en/0.22/">0.22</a></dd>
        
          <dd><a href="/en/0.20/">0.20</a></dd>
        
          <dd><a href="/en/0.18/">0.18</a></dd>
        
      </dl>
      <dl>
        <dt>Downloads</dt>
        
          <dd><a href="//readthedocs.org/projects/scrapy/downloads/pdf/0.18/">pdf</a></dd>
        
          <dd><a href="//readthedocs.org/projects/scrapy/downloads/htmlzip/0.18/">htmlzip</a></dd>
        
          <dd><a href="//readthedocs.org/projects/scrapy/downloads/epub/0.18/">epub</a></dd>
        
      </dl>
      <dl>
        <dt>On Read the Docs</dt>
          <dd>
            <a href="//readthedocs.org/projects/scrapy/?fromdocs=scrapy">Project Home</a>
          </dd>
          <dd>
            <a href="//readthedocs.org/builds/scrapy/?fromdocs=scrapy">Builds</a>
          </dd>
      </dl>
      <hr />
      Free document hosting provided by <a href="http://www.readthedocs.org">Read the Docs</a>.

    </div>
  </div>



  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.18.4',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-2.0.3.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-migrate-1.2.1.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/underscore.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/doctools.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/readthedocs-doc-embed.js"></script>

  

  
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   


<div id="rtd-bi9pxgln"><div class="ethical-fixedfooter"><div class="ethical-content"><div class="ethical-close"><a href="javascript:$('.ethical-fixedfooter').hide()" aria-label="Close Ad">×</a></div><img src="https://readthedocs.org/sustainability/view/641/wVG8yDnp93a7/" class="ethical-pixel" /><div><a href="https://readthedocs.org/sustainability/click/641/wVG8yDnp93a7/" rel="nofollow" target="_blank"><span class="ethical-text"></span></a><a href="https://readthedocs.org/sustainability/click/641/wVG8yDnp93a7/" rel="nofollow" target="_blank">Private repos and priority support. Try Read the Docs for Business Today!</a><span class="ethical-callout"><small><em><a href="https://docs.readthedocs.io/en/latest/ethical-advertising.html" rel="nofollow" target="_blank">ads served ethically</a></em></small></span></div></div></div></div></body></html>