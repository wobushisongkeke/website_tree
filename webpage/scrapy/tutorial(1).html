<!DOCTYPE html><!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]--><!--[if gt IE 8]><!--><html xmlns="http://www.w3.org/1999/xhtml" class=" js flexbox canvas canvastext webgl no-touch geolocation postmessage websqldatabase indexeddb hashchange history draganddrop websockets rgba hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients cssreflections csstransforms csstransforms3d csstransitions fontface generatedcontent video audio localstorage sessionstorage webworkers applicationcache svg inlinesvg smil svgclippaths" lang="en" style=""><!--<![endif]--><head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Scrapy Tutorial — Scrapy 1.6.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Examples" href="examples.html" />
    <link rel="prev" title="Installation guide" href="install.html" /> 

  
  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script type="text/javascript" async="" src="https://www.google-analytics.com/plugins/ua/linkid.js"></script><script type="text/javascript" async="" src="https://cdn.segment.com/analytics.js/v1/8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA/analytics.min.js"></script><script async="" src="https://www.google-analytics.com/analytics.js"></script><script src="../_static/js/modernizr.min.js"></script>


<!-- RTD Extra Head -->

<!-- 
Always link to the latest version, as canonical.
http://docs.readthedocs.org/en/latest/canonical.html
-->
<link rel="canonical" href="https://docs.scrapy.org/en/latest/intro/tutorial.html" />

<link rel="stylesheet" href="https://assets.readthedocs.org/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="text/javascript" src="../_static/readthedocs-data.js"></script>

<!-- Add page-specific data, which must exist in the page js, not global -->
<script type="text/javascript">
READTHEDOCS_DATA['page'] = 'intro/tutorial'
READTHEDOCS_DATA['source_suffix'] = '.rst'
</script>

<script type="text/javascript" src="https://assets.readthedocs.org/static/javascript/readthedocs-analytics.js"></script>

<!-- end RTD <extrahead> -->
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Scrapy
          

          
          </a>

          
            
            
            
              <div class="version">
                1.6
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">First steps</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Scrapy at a glance</a></li>
<li class="toctree-l1"><a class="reference internal" href="install.html">Installation guide</a></li>
<li class="toctree-l1 current"><a class="reference internal current" href="#"><span class="toctree-expand"></span>Scrapy Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#creating-a-project">Creating a project</a></li>
<li class="toctree-l2"><a class="reference internal" href="#our-first-spider"><span class="toctree-expand"></span>Our first Spider</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#how-to-run-our-spider"><span class="toctree-expand"></span>How to run our spider</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#what-just-happened-under-the-hood">What just happened under the hood?</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#a-shortcut-to-the-start-requests-method">A shortcut to the start_requests method</a></li>
<li class="toctree-l3"><a class="reference internal" href="#extracting-data"><span class="toctree-expand"></span>Extracting data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#xpath-a-brief-intro">XPath: a brief intro</a></li>
<li class="toctree-l4"><a class="reference internal" href="#extracting-quotes-and-authors">Extracting quotes and authors</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#extracting-data-in-our-spider">Extracting data in our spider</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#storing-the-scraped-data">Storing the scraped data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#following-links"><span class="toctree-expand"></span>Following links</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#a-shortcut-for-creating-requests">A shortcut for creating Requests</a></li>
<li class="toctree-l3"><a class="reference internal" href="#more-examples-and-patterns">More examples and patterns</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#using-spider-arguments">Using spider arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="#next-steps">Next steps</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/commands.html">Command line tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/spiders.html">Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/selectors.html">Selectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/items.html">Items</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/loaders.html">Item Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/shell.html">Scrapy shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/item-pipeline.html">Item Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/feed-exports.html">Feed exports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/request-response.html">Requests and Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/link-extractors.html">Link Extractors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/settings.html">Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/exceptions.html">Exceptions</a></li>
</ul>
<p class="caption"><span class="caption-text">Built-in services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/stats.html">Stats Collection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/email.html">Sending e-mail</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/telnetconsole.html">Telnet Console</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/webservice.html">Web Service</a></li>
</ul>
<p class="caption"><span class="caption-text">Solving specific problems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/debug.html">Debugging Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/contracts.html">Spiders Contracts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/practices.html">Common Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/broad-crawls.html">Broad Crawls</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/developer-tools.html">Using your browser’s Developer Tools for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/leaks.html">Debugging memory leaks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/media-pipeline.html">Downloading and processing files and images</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/deploy.html">Deploying Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/autothrottle.html">AutoThrottle extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/jobs.html">Jobs: pausing and resuming crawls</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending Scrapy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/architecture.html">Architecture overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/downloader-middleware.html">Downloader Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/spider-middleware.html">Spider Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/extensions.html">Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/api.html">Core API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/signals.html">Signals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/exporters.html">Item Exporters</a></li>
</ul>
<p class="caption"><span class="caption-text">All the rest</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html">Versioning and API Stability</a></li>
</ul>

            
          
        </div>
      <div id="rtd-amhki5l" class="ethical-rtd ethical-dark-theme"></div></div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Scrapy</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> »</li>
        
      <li>Scrapy Tutorial</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/scrapy/scrapy/blob/1.6/docs/intro/tutorial.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr />
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="scrapy-tutorial">
<span id="intro-tutorial"></span><h1>Scrapy Tutorial<a class="headerlink" href="#scrapy-tutorial" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, we’ll assume that Scrapy is already installed on your system.
If that’s not the case, see <a class="reference internal" href="install.html#intro-install"><span class="std std-ref">Installation guide</span></a>.</p>
<p>We are going to scrape <a class="reference external" href="http://quotes.toscrape.com/">quotes.toscrape.com</a>, a website
that lists quotes from famous authors.</p>
<p>This tutorial will walk you through these tasks:</p>
<ol class="arabic simple">
<li>Creating a new Scrapy project</li>
<li>Writing a <a class="reference internal" href="../topics/spiders.html#topics-spiders"><span class="std std-ref">spider</span></a> to crawl a site and extract data</li>
<li>Exporting the scraped data using the command line</li>
<li>Changing spider to recursively follow links</li>
<li>Using spider arguments</li>
</ol>
<p>Scrapy is written in <a class="reference external" href="https://www.python.org/">Python</a>. If you’re new to the language you might want to
start by getting an idea of what the language is like, to get the most out of
Scrapy.</p>
<p>If you’re already familiar with other languages, and want to learn Python quickly, the <a class="reference external" href="https://docs.python.org/3/tutorial">Python Tutorial</a> is a good resource.</p>
<p>If you’re new to programming and want to start with Python, the following books
may be useful to you:</p>
<ul class="simple">
<li><a class="reference external" href="https://automatetheboringstuff.com/">Automate the Boring Stuff With Python</a></li>
<li><a class="reference external" href="http://openbookproject.net/thinkcs/python/english3e/">How To Think Like a Computer Scientist</a></li>
<li><a class="reference external" href="https://learnpythonthehardway.org/python3/">Learn Python 3 The Hard Way</a></li>
</ul>
<p>You can also take a look at <a class="reference external" href="https://wiki.python.org/moin/BeginnersGuide/NonProgrammers">this list of Python resources for non-programmers</a>,
as well as the <a class="reference external" href="https://www.reddit.com/r/learnpython/wiki/index#wiki_new_to_python.3F">suggested resources in the learnpython-subreddit</a>.</p>
<div class="section" id="creating-a-project">
<h2>Creating a project<a class="headerlink" href="#creating-a-project" title="Permalink to this headline">¶</a></h2>
<p>Before you start scraping, you will have to set up a new Scrapy project. Enter a
directory where you’d like to store your code and run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">startproject</span> <span class="n">tutorial</span>
</pre></div>
</div>
<p>This will create a <code class="docutils literal notranslate"><span class="pre">tutorial</span></code> directory with the following contents:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tutorial</span><span class="o">/</span>
    <span class="n">scrapy</span><span class="o">.</span><span class="n">cfg</span>            <span class="c1"># deploy configuration file</span>

    <span class="n">tutorial</span><span class="o">/</span>             <span class="c1"># project's Python module, you'll import your code from here</span>
        <span class="fm">__init__</span><span class="o">.</span><span class="n">py</span>

        <span class="n">items</span><span class="o">.</span><span class="n">py</span>          <span class="c1"># project items definition file</span>

        <span class="n">middlewares</span><span class="o">.</span><span class="n">py</span>    <span class="c1"># project middlewares file</span>

        <span class="n">pipelines</span><span class="o">.</span><span class="n">py</span>      <span class="c1"># project pipelines file</span>

        <span class="n">settings</span><span class="o">.</span><span class="n">py</span>       <span class="c1"># project settings file</span>

        <span class="n">spiders</span><span class="o">/</span>          <span class="c1"># a directory where you'll later put your spiders</span>
            <span class="fm">__init__</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
</div>
<div class="section" id="our-first-spider">
<h2>Our first Spider<a class="headerlink" href="#our-first-spider" title="Permalink to this headline">¶</a></h2>
<p>Spiders are classes that you define and that Scrapy uses to scrape information
from a website (or a group of websites). They must subclass
<code class="xref py py-class docutils literal notranslate"><span class="pre">scrapy.Spider</span></code> and define the initial requests to make, optionally how
to follow links in the pages, and how to parse the downloaded page content to
extract data.</p>
<p>This is the code for our first Spider. Save it in a file named
<code class="docutils literal notranslate"><span class="pre">quotes_spider.py</span></code> under the <code class="docutils literal notranslate"><span class="pre">tutorial/spiders</span></code> directory in your project:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">"quotes"</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">urls</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s1">'http://quotes.toscrape.com/page/1/'</span><span class="p">,</span>
            <span class="s1">'http://quotes.toscrape.com/page/2/'</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"/"</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="s1">'quotes-</span><span class="si">%s</span><span class="s1">.html'</span> <span class="o">%</span> <span class="n">page</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">body</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">'Saved file </span><span class="si">%s</span><span class="s1">'</span> <span class="o">%</span> <span class="n">filename</span><span class="p">)</span>
</pre></div>
</div>
<p>As you can see, our Spider subclasses <a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider" title="scrapy.spiders.Spider"><code class="xref py py-class docutils literal notranslate"><span class="pre">scrapy.Spider</span></code></a>
and defines some attributes and methods:</p>
<ul>
<li><p class="first"><a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider.name" title="scrapy.spiders.Spider.name"><code class="xref py py-attr docutils literal notranslate"><span class="pre">name</span></code></a>: identifies the Spider. It must be
unique within a project, that is, you can’t set the same name for different
Spiders.</p>
</li>
<li><p class="first"><a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider.start_requests" title="scrapy.spiders.Spider.start_requests"><code class="xref py py-meth docutils literal notranslate"><span class="pre">start_requests()</span></code></a>: must return an iterable of
Requests (you can return a list of requests or write a generator function)
which the Spider will begin to crawl from. Subsequent requests will be
generated successively from these initial requests.</p>
</li>
<li><p class="first"><a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider.parse" title="scrapy.spiders.Spider.parse"><code class="xref py py-meth docutils literal notranslate"><span class="pre">parse()</span></code></a>: a method that will be called to handle
the response downloaded for each of the requests made. The response parameter
is an instance of <a class="reference internal" href="../topics/request-response.html#scrapy.http.TextResponse" title="scrapy.http.TextResponse"><code class="xref py py-class docutils literal notranslate"><span class="pre">TextResponse</span></code></a> that holds
the page content and has further helpful methods to handle it.</p>
<p>The <a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider.parse" title="scrapy.spiders.Spider.parse"><code class="xref py py-meth docutils literal notranslate"><span class="pre">parse()</span></code></a> method usually parses the response, extracting
the scraped data as dicts and also finding new URLs to
follow and creating new requests (<a class="reference internal" href="../topics/request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal notranslate"><span class="pre">Request</span></code></a>) from them.</p>
</li>
</ul>
<div class="section" id="how-to-run-our-spider">
<h3>How to run our spider<a class="headerlink" href="#how-to-run-our-spider" title="Permalink to this headline">¶</a></h3>
<p>To put our spider to work, go to the project’s top level directory and run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">crawl</span> <span class="n">quotes</span>
</pre></div>
</div>
<p>This command runs the spider with name <code class="docutils literal notranslate"><span class="pre">quotes</span></code> that we’ve just added, that
will send some requests for the <code class="docutils literal notranslate"><span class="pre">quotes.toscrape.com</span></code> domain. You will get an output
similar to this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">...</span> <span class="p">(</span><span class="n">omitted</span> <span class="k">for</span> <span class="n">brevity</span><span class="p">)</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">16</span> <span class="mi">21</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">05</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">engine</span><span class="p">]</span> <span class="n">INFO</span><span class="p">:</span> <span class="n">Spider</span> <span class="n">opened</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">16</span> <span class="mi">21</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">05</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">extensions</span><span class="o">.</span><span class="n">logstats</span><span class="p">]</span> <span class="n">INFO</span><span class="p">:</span> <span class="n">Crawled</span> <span class="mi">0</span> <span class="n">pages</span> <span class="p">(</span><span class="n">at</span> <span class="mi">0</span> <span class="n">pages</span><span class="o">/</span><span class="nb">min</span><span class="p">),</span> <span class="n">scraped</span> <span class="mi">0</span> <span class="n">items</span> <span class="p">(</span><span class="n">at</span> <span class="mi">0</span> <span class="n">items</span><span class="o">/</span><span class="nb">min</span><span class="p">)</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">16</span> <span class="mi">21</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">05</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">extensions</span><span class="o">.</span><span class="n">telnet</span><span class="p">]</span> <span class="n">DEBUG</span><span class="p">:</span> <span class="n">Telnet</span> <span class="n">console</span> <span class="n">listening</span> <span class="n">on</span> <span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span><span class="p">:</span><span class="mi">6023</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">16</span> <span class="mi">21</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">05</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">engine</span><span class="p">]</span> <span class="n">DEBUG</span><span class="p">:</span> <span class="n">Crawled</span> <span class="p">(</span><span class="mi">404</span><span class="p">)</span> <span class="o">&lt;</span><span class="n">GET</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">quotes</span><span class="o">.</span><span class="n">toscrape</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">robots</span><span class="o">.</span><span class="n">txt</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">referer</span><span class="p">:</span> <span class="kc">None</span><span class="p">)</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">16</span> <span class="mi">21</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">05</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">engine</span><span class="p">]</span> <span class="n">DEBUG</span><span class="p">:</span> <span class="n">Crawled</span> <span class="p">(</span><span class="mi">200</span><span class="p">)</span> <span class="o">&lt;</span><span class="n">GET</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">quotes</span><span class="o">.</span><span class="n">toscrape</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">page</span><span class="o">/</span><span class="mi">1</span><span class="o">/&gt;</span> <span class="p">(</span><span class="n">referer</span><span class="p">:</span> <span class="kc">None</span><span class="p">)</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">16</span> <span class="mi">21</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">05</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">engine</span><span class="p">]</span> <span class="n">DEBUG</span><span class="p">:</span> <span class="n">Crawled</span> <span class="p">(</span><span class="mi">200</span><span class="p">)</span> <span class="o">&lt;</span><span class="n">GET</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">quotes</span><span class="o">.</span><span class="n">toscrape</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">page</span><span class="o">/</span><span class="mi">2</span><span class="o">/&gt;</span> <span class="p">(</span><span class="n">referer</span><span class="p">:</span> <span class="kc">None</span><span class="p">)</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">16</span> <span class="mi">21</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">05</span> <span class="p">[</span><span class="n">quotes</span><span class="p">]</span> <span class="n">DEBUG</span><span class="p">:</span> <span class="n">Saved</span> <span class="n">file</span> <span class="n">quotes</span><span class="o">-</span><span class="mf">1.</span><span class="n">html</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">16</span> <span class="mi">21</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">05</span> <span class="p">[</span><span class="n">quotes</span><span class="p">]</span> <span class="n">DEBUG</span><span class="p">:</span> <span class="n">Saved</span> <span class="n">file</span> <span class="n">quotes</span><span class="o">-</span><span class="mf">2.</span><span class="n">html</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">16</span> <span class="mi">21</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">05</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">engine</span><span class="p">]</span> <span class="n">INFO</span><span class="p">:</span> <span class="n">Closing</span> <span class="n">spider</span> <span class="p">(</span><span class="n">finished</span><span class="p">)</span>
<span class="o">...</span>
</pre></div>
</div>
<p>Now, check the files in the current directory. You should notice that two new
files have been created: <em>quotes-1.html</em> and <em>quotes-2.html</em>, with the content
for the respective URLs, as our <code class="docutils literal notranslate"><span class="pre">parse</span></code> method instructs.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If you are wondering why we haven’t parsed the HTML yet, hold
on, we will cover that soon.</p>
</div>
<div class="section" id="what-just-happened-under-the-hood">
<h4>What just happened under the hood?<a class="headerlink" href="#what-just-happened-under-the-hood" title="Permalink to this headline">¶</a></h4>
<p>Scrapy schedules the <a class="reference internal" href="../topics/request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal notranslate"><span class="pre">scrapy.Request</span></code></a> objects
returned by the <code class="docutils literal notranslate"><span class="pre">start_requests</span></code> method of the Spider. Upon receiving a
response for each one, it instantiates <a class="reference internal" href="../topics/request-response.html#scrapy.http.Response" title="scrapy.http.Response"><code class="xref py py-class docutils literal notranslate"><span class="pre">Response</span></code></a> objects
and calls the callback method associated with the request (in this case, the
<code class="docutils literal notranslate"><span class="pre">parse</span></code> method) passing the response as argument.</p>
</div>
</div>
<div class="section" id="a-shortcut-to-the-start-requests-method">
<h3>A shortcut to the start_requests method<a class="headerlink" href="#a-shortcut-to-the-start-requests-method" title="Permalink to this headline">¶</a></h3>
<p>Instead of implementing a <a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider.start_requests" title="scrapy.spiders.Spider.start_requests"><code class="xref py py-meth docutils literal notranslate"><span class="pre">start_requests()</span></code></a> method
that generates <a class="reference internal" href="../topics/request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal notranslate"><span class="pre">scrapy.Request</span></code></a> objects from URLs,
you can just define a <a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider.start_urls" title="scrapy.spiders.Spider.start_urls"><code class="xref py py-attr docutils literal notranslate"><span class="pre">start_urls</span></code></a> class attribute
with a list of URLs. This list will then be used by the default implementation
of <a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider.start_requests" title="scrapy.spiders.Spider.start_requests"><code class="xref py py-meth docutils literal notranslate"><span class="pre">start_requests()</span></code></a> to create the initial requests
for your spider:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">"quotes"</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">'http://quotes.toscrape.com/page/1/'</span><span class="p">,</span>
        <span class="s1">'http://quotes.toscrape.com/page/2/'</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"/"</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="s1">'quotes-</span><span class="si">%s</span><span class="s1">.html'</span> <span class="o">%</span> <span class="n">page</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">body</span><span class="p">)</span>
</pre></div>
</div>
<p>The <a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider.parse" title="scrapy.spiders.Spider.parse"><code class="xref py py-meth docutils literal notranslate"><span class="pre">parse()</span></code></a> method will be called to handle each
of the requests for those URLs, even though we haven’t explicitly told Scrapy
to do so. This happens because <a class="reference internal" href="../topics/spiders.html#scrapy.spiders.Spider.parse" title="scrapy.spiders.Spider.parse"><code class="xref py py-meth docutils literal notranslate"><span class="pre">parse()</span></code></a> is Scrapy’s
default callback method, which is called for requests without an explicitly
assigned callback.</p>
</div>
<div class="section" id="extracting-data">
<h3>Extracting data<a class="headerlink" href="#extracting-data" title="Permalink to this headline">¶</a></h3>
<p>The best way to learn how to extract data with Scrapy is trying selectors
using the shell <a class="reference internal" href="../topics/shell.html#topics-shell"><span class="std std-ref">Scrapy shell</span></a>. Run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">shell</span> <span class="s1">'http://quotes.toscrape.com/page/1/'</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Remember to always enclose urls in quotes when running Scrapy shell from
command-line, otherwise urls containing arguments (ie. <code class="docutils literal notranslate"><span class="pre">&amp;</span></code> character)
will not work.</p>
<p>On Windows, use double quotes instead:</p>
<div class="last highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">shell</span> <span class="s2">"http://quotes.toscrape.com/page/1/"</span>
</pre></div>
</div>
</div>
<p>You will see something like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span> <span class="o">...</span> <span class="n">Scrapy</span> <span class="n">log</span> <span class="n">here</span> <span class="o">...</span> <span class="p">]</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">19</span> <span class="mi">12</span><span class="p">:</span><span class="mi">09</span><span class="p">:</span><span class="mi">27</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">engine</span><span class="p">]</span> <span class="n">DEBUG</span><span class="p">:</span> <span class="n">Crawled</span> <span class="p">(</span><span class="mi">200</span><span class="p">)</span> <span class="o">&lt;</span><span class="n">GET</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">quotes</span><span class="o">.</span><span class="n">toscrape</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">page</span><span class="o">/</span><span class="mi">1</span><span class="o">/&gt;</span> <span class="p">(</span><span class="n">referer</span><span class="p">:</span> <span class="kc">None</span><span class="p">)</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="n">Available</span> <span class="n">Scrapy</span> <span class="n">objects</span><span class="p">:</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">scrapy</span>     <span class="n">scrapy</span> <span class="n">module</span> <span class="p">(</span><span class="n">contains</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">,</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Selector</span><span class="p">,</span> <span class="n">etc</span><span class="p">)</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">crawler</span>    <span class="o">&lt;</span><span class="n">scrapy</span><span class="o">.</span><span class="n">crawler</span><span class="o">.</span><span class="n">Crawler</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x7fa91d888c90</span><span class="o">&gt;</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">item</span>       <span class="p">{}</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">request</span>    <span class="o">&lt;</span><span class="n">GET</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">quotes</span><span class="o">.</span><span class="n">toscrape</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">page</span><span class="o">/</span><span class="mi">1</span><span class="o">/&gt;</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">response</span>   <span class="o">&lt;</span><span class="mi">200</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">quotes</span><span class="o">.</span><span class="n">toscrape</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">page</span><span class="o">/</span><span class="mi">1</span><span class="o">/&gt;</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">settings</span>   <span class="o">&lt;</span><span class="n">scrapy</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">Settings</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x7fa91d888c10</span><span class="o">&gt;</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">spider</span>     <span class="o">&lt;</span><span class="n">DefaultSpider</span> <span class="s1">'default'</span> <span class="n">at</span> <span class="mh">0x7fa91c8af990</span><span class="o">&gt;</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="n">Useful</span> <span class="n">shortcuts</span><span class="p">:</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">shelp</span><span class="p">()</span>           <span class="n">Shell</span> <span class="n">help</span> <span class="p">(</span><span class="nb">print</span> <span class="n">this</span> <span class="n">help</span><span class="p">)</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">fetch</span><span class="p">(</span><span class="n">req_or_url</span><span class="p">)</span> <span class="n">Fetch</span> <span class="n">request</span> <span class="p">(</span><span class="ow">or</span> <span class="n">URL</span><span class="p">)</span> <span class="ow">and</span> <span class="n">update</span> <span class="n">local</span> <span class="n">objects</span>
<span class="p">[</span><span class="n">s</span><span class="p">]</span>   <span class="n">view</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>    <span class="n">View</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">a</span> <span class="n">browser</span>
<span class="o">&gt;&gt;&gt;</span>
</pre></div>
</div>
<p>Using the shell, you can try selecting elements using <a class="reference external" href="https://www.w3.org/TR/selectors">CSS</a> with the response
object:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'title'</span><span class="p">)</span>
<span class="go">[&lt;Selector xpath='descendant-or-self::title' data='&lt;title&gt;Quotes to Scrape&lt;/title&gt;'&gt;]</span>
</pre></div>
</div>
<p>The result of running <code class="docutils literal notranslate"><span class="pre">response.css('title')</span></code> is a list-like object called
<a class="reference internal" href="../topics/selectors.html#scrapy.selector.SelectorList" title="scrapy.selector.SelectorList"><code class="xref py py-class docutils literal notranslate"><span class="pre">SelectorList</span></code></a>, which represents a list of
<a class="reference internal" href="../topics/selectors.html#scrapy.selector.Selector" title="scrapy.selector.Selector"><code class="xref py py-class docutils literal notranslate"><span class="pre">Selector</span></code></a> objects that wrap around XML/HTML elements
and allow you to run further queries to fine-grain the selection or extract the
data.</p>
<p>To extract the text from the title above, you can do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'title::text'</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">()</span>
<span class="go">['Quotes to Scrape']</span>
</pre></div>
</div>
<p>There are two things to note here: one is that we’ve added <code class="docutils literal notranslate"><span class="pre">::text</span></code> to the
CSS query, to mean we want to select only the text elements directly inside
<code class="docutils literal notranslate"><span class="pre">&lt;title&gt;</span></code> element.  If we don’t specify <code class="docutils literal notranslate"><span class="pre">::text</span></code>, we’d get the full title
element, including its tags:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'title'</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">()</span>
<span class="go">['&lt;title&gt;Quotes to Scrape&lt;/title&gt;']</span>
</pre></div>
</div>
<p>The other thing is that the result of calling <code class="docutils literal notranslate"><span class="pre">.getall()</span></code> is a list: it is
possible that a selector returns more than one result, so we extract them all.
When you know you just want the first result, as in this case, you can do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'title::text'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="go">'Quotes to Scrape'</span>
</pre></div>
</div>
<p>As an alternative, you could’ve written:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'title::text'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="go">'Quotes to Scrape'</span>
</pre></div>
</div>
<p>However, using <code class="docutils literal notranslate"><span class="pre">.get()</span></code> directly on a <a class="reference internal" href="../topics/selectors.html#scrapy.selector.SelectorList" title="scrapy.selector.SelectorList"><code class="xref py py-class docutils literal notranslate"><span class="pre">SelectorList</span></code></a>
instance avoids an <code class="docutils literal notranslate"><span class="pre">IndexError</span></code> and returns <code class="docutils literal notranslate"><span class="pre">None</span></code> when it doesn’t
find any element matching the selection.</p>
<p>There’s a lesson here: for most scraping code, you want it to be resilient to
errors due to things not being found on a page, so that even if some parts fail
to be scraped, you can at least get <strong>some</strong> data.</p>
<p>Besides the <a class="reference internal" href="../topics/selectors.html#scrapy.selector.SelectorList.getall" title="scrapy.selector.SelectorList.getall"><code class="xref py py-meth docutils literal notranslate"><span class="pre">getall()</span></code></a> and
<a class="reference internal" href="../topics/selectors.html#scrapy.selector.SelectorList.get" title="scrapy.selector.SelectorList.get"><code class="xref py py-meth docutils literal notranslate"><span class="pre">get()</span></code></a> methods, you can also use
the <a class="reference internal" href="../topics/selectors.html#scrapy.selector.SelectorList.re" title="scrapy.selector.SelectorList.re"><code class="xref py py-meth docutils literal notranslate"><span class="pre">re()</span></code></a> method to extract using <a class="reference external" href="https://docs.python.org/3/library/re.html">regular
expressions</a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'title::text'</span><span class="p">)</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="sa">r</span><span class="s1">'Quotes.*'</span><span class="p">)</span>
<span class="go">['Quotes to Scrape']</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'title::text'</span><span class="p">)</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="sa">r</span><span class="s1">'Q\w+'</span><span class="p">)</span>
<span class="go">['Quotes']</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'title::text'</span><span class="p">)</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="sa">r</span><span class="s1">'(\w+) to (\w+)'</span><span class="p">)</span>
<span class="go">['Quotes', 'Scrape']</span>
</pre></div>
</div>
<p>In order to find the proper CSS selectors to use, you might find useful opening
the response page from the shell in your web browser using <code class="docutils literal notranslate"><span class="pre">view(response)</span></code>.
You can use your browser developer tools to inspect the HTML and come up
with a selector (see section about <a class="reference internal" href="../topics/developer-tools.html#topics-developer-tools"><span class="std std-ref">Using your browser’s Developer Tools for scraping</span></a>).</p>
<p><a class="reference external" href="http://selectorgadget.com/">Selector Gadget</a> is also a nice tool to quickly find CSS selector for
visually selected elements, which works in many browsers.</p>
<div class="section" id="xpath-a-brief-intro">
<h4>XPath: a brief intro<a class="headerlink" href="#xpath-a-brief-intro" title="Permalink to this headline">¶</a></h4>
<p>Besides <a class="reference external" href="https://www.w3.org/TR/selectors">CSS</a>, Scrapy selectors also support using <a class="reference external" href="https://www.w3.org/TR/xpath">XPath</a> expressions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">'//title'</span><span class="p">)</span>
<span class="go">[&lt;Selector xpath='//title' data='&lt;title&gt;Quotes to Scrape&lt;/title&gt;'&gt;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">'//title/text()'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="go">'Quotes to Scrape'</span>
</pre></div>
</div>
<p>XPath expressions are very powerful, and are the foundation of Scrapy
Selectors. In fact, CSS selectors are converted to XPath under-the-hood. You
can see that if you read closely the text representation of the selector
objects in the shell.</p>
<p>While perhaps not as popular as CSS selectors, XPath expressions offer more
power because besides navigating the structure, it can also look at the
content. Using XPath, you’re able to select things like: <em>select the link
that contains the text “Next Page”</em>. This makes XPath very fitting to the task
of scraping, and we encourage you to learn XPath even if you already know how to
construct CSS selectors, it will make scraping much easier.</p>
<p>We won’t cover much of XPath here, but you can read more about <a class="reference internal" href="../topics/selectors.html#topics-selectors"><span class="std std-ref">using XPath
with Scrapy Selectors here</span></a>. To learn more about XPath, we
recommend <a class="reference external" href="http://zvon.org/comp/r/tut-XPath_1.html">this tutorial to learn XPath through examples</a>, and <a class="reference external" href="http://plasmasturm.org/log/xpath101/">this tutorial to learn “how
to think in XPath”</a>.</p>
</div>
<div class="section" id="extracting-quotes-and-authors">
<h4>Extracting quotes and authors<a class="headerlink" href="#extracting-quotes-and-authors" title="Permalink to this headline">¶</a></h4>
<p>Now that you know a bit about selection and extraction, let’s complete our
spider by writing the code to extract the quotes from the web page.</p>
<p>Each quote in <a class="reference external" href="http://quotes.toscrape.com">http://quotes.toscrape.com</a> is represented by HTML elements that look
like this:</p>
<div class="highlight-html notranslate"><div class="highlight"><pre><span></span><span class="p">&lt;</span><span class="nt">div</span> <span class="na">class</span><span class="o">=</span><span class="s">"quote"</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">span</span> <span class="na">class</span><span class="o">=</span><span class="s">"text"</span><span class="p">&gt;</span>“The world as we have created it is a process of our
    thinking. It cannot be changed without changing our thinking.”<span class="p">&lt;/</span><span class="nt">span</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">span</span><span class="p">&gt;</span>
        by <span class="p">&lt;</span><span class="nt">small</span> <span class="na">class</span><span class="o">=</span><span class="s">"author"</span><span class="p">&gt;</span>Albert Einstein<span class="p">&lt;/</span><span class="nt">small</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">a</span> <span class="na">href</span><span class="o">=</span><span class="s">"/author/Albert-Einstein"</span><span class="p">&gt;</span>(about)<span class="p">&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">span</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">div</span> <span class="na">class</span><span class="o">=</span><span class="s">"tags"</span><span class="p">&gt;</span>
        Tags:
        <span class="p">&lt;</span><span class="nt">a</span> <span class="na">class</span><span class="o">=</span><span class="s">"tag"</span> <span class="na">href</span><span class="o">=</span><span class="s">"/tag/change/page/1/"</span><span class="p">&gt;</span>change<span class="p">&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">a</span> <span class="na">class</span><span class="o">=</span><span class="s">"tag"</span> <span class="na">href</span><span class="o">=</span><span class="s">"/tag/deep-thoughts/page/1/"</span><span class="p">&gt;</span>deep-thoughts<span class="p">&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">a</span> <span class="na">class</span><span class="o">=</span><span class="s">"tag"</span> <span class="na">href</span><span class="o">=</span><span class="s">"/tag/thinking/page/1/"</span><span class="p">&gt;</span>thinking<span class="p">&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">a</span> <span class="na">class</span><span class="o">=</span><span class="s">"tag"</span> <span class="na">href</span><span class="o">=</span><span class="s">"/tag/world/page/1/"</span><span class="p">&gt;</span>world<span class="p">&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
</pre></div>
</div>
<p>Let’s open up scrapy shell and play a bit to find out how to extract the data
we want:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scrapy shell 'http://quotes.toscrape.com'
</pre></div>
</div>
<p>We get a list of selectors for the quote HTML elements with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">"div.quote"</span><span class="p">)</span>
</pre></div>
</div>
<p>Each of the selectors returned by the query above allows us to run further
queries over their sub-elements. Let’s assign the first selector to a
variable, so that we can run our CSS selectors directly on a particular quote:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">quote</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">"div.quote"</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>Now, let’s extract <code class="docutils literal notranslate"><span class="pre">title</span></code>, <code class="docutils literal notranslate"><span class="pre">author</span></code> and the <code class="docutils literal notranslate"><span class="pre">tags</span></code> from that quote
using the <code class="docutils literal notranslate"><span class="pre">quote</span></code> object we just created:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">title</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">"span.text::text"</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">title</span>
<span class="go">'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">author</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">"small.author::text"</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">author</span>
<span class="go">'Albert Einstein'</span>
</pre></div>
</div>
<p>Given that the tags are a list of strings, we can use the <code class="docutils literal notranslate"><span class="pre">.getall()</span></code> method
to get all of them:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tags</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">"div.tags a.tag::text"</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tags</span>
<span class="go">['change', 'deep-thoughts', 'thinking', 'world']</span>
</pre></div>
</div>
<p>Having figured out how to extract each bit, we can now iterate over all the
quotes elements and put them together into a Python dictionary:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">"div.quote"</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">text</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">"span.text::text"</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="gp">... </span>    <span class="n">author</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">"small.author::text"</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="gp">... </span>    <span class="n">tags</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">"div.tags a.tag::text"</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">()</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">author</span><span class="o">=</span><span class="n">author</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="n">tags</span><span class="p">))</span>
<span class="go">{'tags': ['change', 'deep-thoughts', 'thinking', 'world'], 'author': 'Albert Einstein', 'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'}</span>
<span class="go">{'tags': ['abilities', 'choices'], 'author': 'J.K. Rowling', 'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”'}</span>
<span class="go">    ... a few more of these, omitted for brevity</span>
<span class="go">&gt;&gt;&gt;</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="extracting-data-in-our-spider">
<h3>Extracting data in our spider<a class="headerlink" href="#extracting-data-in-our-spider" title="Permalink to this headline">¶</a></h3>
<p>Let’s get back to our spider. Until now, it doesn’t extract any data in
particular, just saves the whole HTML page to a local file. Let’s integrate the
extraction logic above into our spider.</p>
<p>A Scrapy spider typically generates many dictionaries containing the data
extracted from the page. To do that, we use the <code class="docutils literal notranslate"><span class="pre">yield</span></code> Python keyword
in the callback, as you can see below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">"quotes"</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">'http://quotes.toscrape.com/page/1/'</span><span class="p">,</span>
        <span class="s1">'http://quotes.toscrape.com/page/2/'</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'div.quote'</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">'text'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'span.text::text'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">'author'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'small.author::text'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">'tags'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'div.tags a.tag::text'</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">(),</span>
            <span class="p">}</span>
</pre></div>
</div>
<p>If you run this spider, it will output the extracted data with the log:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">2016</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">19</span> <span class="mi">18</span><span class="p">:</span><span class="mi">57</span><span class="p">:</span><span class="mi">19</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">scraper</span><span class="p">]</span> <span class="n">DEBUG</span><span class="p">:</span> <span class="n">Scraped</span> <span class="kn">from</span> <span class="o">&lt;</span><span class="mi">200</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">quotes</span><span class="o">.</span><span class="n">toscrape</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">page</span><span class="o">/</span><span class="mi">1</span><span class="o">/&gt;</span>
<span class="p">{</span><span class="s1">'tags'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'life'</span><span class="p">,</span> <span class="s1">'love'</span><span class="p">],</span> <span class="s1">'author'</span><span class="p">:</span> <span class="s1">'André Gide'</span><span class="p">,</span> <span class="s1">'text'</span><span class="p">:</span> <span class="s1">'“It is better to be hated for what you are than to be loved for what you are not.”'</span><span class="p">}</span>
<span class="mi">2016</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mi">19</span> <span class="mi">18</span><span class="p">:</span><span class="mi">57</span><span class="p">:</span><span class="mi">19</span> <span class="p">[</span><span class="n">scrapy</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">scraper</span><span class="p">]</span> <span class="n">DEBUG</span><span class="p">:</span> <span class="n">Scraped</span> <span class="kn">from</span> <span class="o">&lt;</span><span class="mi">200</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">quotes</span><span class="o">.</span><span class="n">toscrape</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">page</span><span class="o">/</span><span class="mi">1</span><span class="o">/&gt;</span>
<span class="p">{</span><span class="s1">'tags'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'edison'</span><span class="p">,</span> <span class="s1">'failure'</span><span class="p">,</span> <span class="s1">'inspirational'</span><span class="p">,</span> <span class="s1">'paraphrased'</span><span class="p">],</span> <span class="s1">'author'</span><span class="p">:</span> <span class="s1">'Thomas A. Edison'</span><span class="p">,</span> <span class="s1">'text'</span><span class="p">:</span> <span class="s2">"“I have not failed. I've just found 10,000 ways that won't work.”"</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="storing-the-scraped-data">
<span id="storing-data"></span><h2>Storing the scraped data<a class="headerlink" href="#storing-the-scraped-data" title="Permalink to this headline">¶</a></h2>
<p>The simplest way to store the scraped data is by using <a class="reference internal" href="../topics/feed-exports.html#topics-feed-exports"><span class="std std-ref">Feed exports</span></a>, with the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">crawl</span> <span class="n">quotes</span> <span class="o">-</span><span class="n">o</span> <span class="n">quotes</span><span class="o">.</span><span class="n">json</span>
</pre></div>
</div>
<p>That will generate an <code class="docutils literal notranslate"><span class="pre">quotes.json</span></code> file containing all scraped items,
serialized in <a class="reference external" href="https://en.wikipedia.org/wiki/JSON">JSON</a>.</p>
<p>For historic reasons, Scrapy appends to a given file instead of overwriting
its contents. If you run this command twice without removing the file
before the second time, you’ll end up with a broken JSON file.</p>
<p>You can also use other formats, like <a class="reference external" href="http://jsonlines.org">JSON Lines</a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">crawl</span> <span class="n">quotes</span> <span class="o">-</span><span class="n">o</span> <span class="n">quotes</span><span class="o">.</span><span class="n">jl</span>
</pre></div>
</div>
<p>The <a class="reference external" href="http://jsonlines.org">JSON Lines</a> format is useful because it’s stream-like, you can easily
append new records to it. It doesn’t have the same problem of JSON when you run
twice. Also, as each record is a separate line, you can process big files
without having to fit everything in memory, there are tools like <a class="reference external" href="https://stedolan.github.io/jq">JQ</a> to help
doing that at the command-line.</p>
<p>In small projects (like the one in this tutorial), that should be enough.
However, if you want to perform more complex things with the scraped items, you
can write an <a class="reference internal" href="../topics/item-pipeline.html#topics-item-pipeline"><span class="std std-ref">Item Pipeline</span></a>. A placeholder file
for Item Pipelines has been set up for you when the project is created, in
<code class="docutils literal notranslate"><span class="pre">tutorial/pipelines.py</span></code>. Though you don’t need to implement any item
pipelines if you just want to store the scraped items.</p>
</div>
<div class="section" id="following-links">
<h2>Following links<a class="headerlink" href="#following-links" title="Permalink to this headline">¶</a></h2>
<p>Let’s say, instead of just scraping the stuff from the first two pages
from <a class="reference external" href="http://quotes.toscrape.com">http://quotes.toscrape.com</a>, you want quotes from all the pages in the website.</p>
<p>Now that you know how to extract data from pages, let’s see how to follow links
from them.</p>
<p>First thing is to extract the link to the page we want to follow.  Examining
our page, we can see there is a link to the next page with the following
markup:</p>
<div class="highlight-html notranslate"><div class="highlight"><pre><span></span><span class="p">&lt;</span><span class="nt">ul</span> <span class="na">class</span><span class="o">=</span><span class="s">"pager"</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">li</span> <span class="na">class</span><span class="o">=</span><span class="s">"next"</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">a</span> <span class="na">href</span><span class="o">=</span><span class="s">"/page/2/"</span><span class="p">&gt;</span>Next <span class="p">&lt;</span><span class="nt">span</span> <span class="na">aria-hidden</span><span class="o">=</span><span class="s">"true"</span><span class="p">&gt;</span><span class="ni">&amp;rarr;</span><span class="p">&lt;/</span><span class="nt">span</span><span class="p">&gt;&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">li</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">ul</span><span class="p">&gt;</span>
</pre></div>
</div>
<p>We can try extracting it in the shell:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'li.next a'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="go">'&lt;a href="/page/2/"&gt;Next &lt;span aria-hidden="true"&gt;→&lt;/span&gt;&lt;/a&gt;'</span>
</pre></div>
</div>
<p>This gets the anchor element, but we want the attribute <code class="docutils literal notranslate"><span class="pre">href</span></code>. For that,
Scrapy supports a CSS extension that let’s you select the attribute contents,
like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'li.next a::attr(href)'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="go">'/page/2/'</span>
</pre></div>
</div>
<p>There is also an <code class="docutils literal notranslate"><span class="pre">attrib</span></code> property available
(see <a class="reference internal" href="../topics/selectors.html#selecting-attributes"><span class="std std-ref">Selecting element attributes</span></a> for more):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'li.next a'</span><span class="p">)</span><span class="o">.</span><span class="n">attrib</span><span class="p">[</span><span class="s1">'href'</span><span class="p">]</span>
<span class="go">'/page/2'</span>
</pre></div>
</div>
<p>Let’s see now our spider modified to recursively follow the link to the next
page, extracting data from it:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">"quotes"</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">'http://quotes.toscrape.com/page/1/'</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'div.quote'</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">'text'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'span.text::text'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">'author'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'small.author::text'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">'tags'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'div.tags a.tag::text'</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">(),</span>
            <span class="p">}</span>

        <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'li.next a::attr(href)'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">next_page</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">next_page</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">next_page</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</pre></div>
</div>
<p>Now, after extracting the data, the <code class="docutils literal notranslate"><span class="pre">parse()</span></code> method looks for the link to
the next page, builds a full absolute URL using the
<a class="reference internal" href="../topics/request-response.html#scrapy.http.Response.urljoin" title="scrapy.http.Response.urljoin"><code class="xref py py-meth docutils literal notranslate"><span class="pre">urljoin()</span></code></a> method (since the links can be
relative) and yields a new request to the next page, registering itself as
callback to handle the data extraction for the next page and to keep the
crawling going through all the pages.</p>
<p>What you see here is Scrapy’s mechanism of following links: when you yield
a Request in a callback method, Scrapy will schedule that request to be sent
and register a callback method to be executed when that request finishes.</p>
<p>Using this, you can build complex crawlers that follow links according to rules
you define, and extract different kinds of data depending on the page it’s
visiting.</p>
<p>In our example, it creates a sort of loop, following all the links to the next page
until it doesn’t find one – handy for crawling blogs, forums and other sites with
pagination.</p>
<div class="section" id="a-shortcut-for-creating-requests">
<span id="response-follow-example"></span><h3>A shortcut for creating Requests<a class="headerlink" href="#a-shortcut-for-creating-requests" title="Permalink to this headline">¶</a></h3>
<p>As a shortcut for creating Request objects you can use
<a class="reference internal" href="../topics/request-response.html#scrapy.http.TextResponse.follow" title="scrapy.http.TextResponse.follow"><code class="xref py py-meth docutils literal notranslate"><span class="pre">response.follow</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">"quotes"</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">'http://quotes.toscrape.com/page/1/'</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'div.quote'</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">'text'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'span.text::text'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">'author'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'span small::text'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">'tags'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'div.tags a.tag::text'</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">(),</span>
            <span class="p">}</span>

        <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'li.next a::attr(href)'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">next_page</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">next_page</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</pre></div>
</div>
<p>Unlike scrapy.Request, <code class="docutils literal notranslate"><span class="pre">response.follow</span></code> supports relative URLs directly - no
need to call urljoin. Note that <code class="docutils literal notranslate"><span class="pre">response.follow</span></code> just returns a Request
instance; you still have to yield this Request.</p>
<p>You can also pass a selector to <code class="docutils literal notranslate"><span class="pre">response.follow</span></code> instead of a string;
this selector should extract necessary attributes:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">href</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'li.next a::attr(href)'</span><span class="p">):</span>
    <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">href</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</pre></div>
</div>
<p>For <code class="docutils literal notranslate"><span class="pre">&lt;a&gt;</span></code> elements there is a shortcut: <code class="docutils literal notranslate"><span class="pre">response.follow</span></code> uses their href
attribute automatically. So the code can be shortened further:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'li.next a'</span><span class="p">):</span>
    <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><code class="docutils literal notranslate"><span class="pre">response.follow(response.css('li.next</span> <span class="pre">a'))</span></code> is not valid because
<code class="docutils literal notranslate"><span class="pre">response.css</span></code> returns a list-like object with selectors for all results,
not a single selector. A <code class="docutils literal notranslate"><span class="pre">for</span></code> loop like in the example above, or
<code class="docutils literal notranslate"><span class="pre">response.follow(response.css('li.next</span> <span class="pre">a')[0])</span></code> is fine.</p>
</div>
</div>
<div class="section" id="more-examples-and-patterns">
<h3>More examples and patterns<a class="headerlink" href="#more-examples-and-patterns" title="Permalink to this headline">¶</a></h3>
<p>Here is another spider that illustrates callbacks and following links,
this time for scraping author information:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">AuthorSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">'author'</span>

    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'http://quotes.toscrape.com/'</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="c1"># follow links to author pages</span>
        <span class="k">for</span> <span class="n">href</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'.author + a::attr(href)'</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">href</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse_author</span><span class="p">)</span>

        <span class="c1"># follow pagination links</span>
        <span class="k">for</span> <span class="n">href</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'li.next a::attr(href)'</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">href</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse_author</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">extract_with_css</span><span class="p">(</span><span class="n">query</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="n">query</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

        <span class="k">yield</span> <span class="p">{</span>
            <span class="s1">'name'</span><span class="p">:</span> <span class="n">extract_with_css</span><span class="p">(</span><span class="s1">'h3.author-title::text'</span><span class="p">),</span>
            <span class="s1">'birthdate'</span><span class="p">:</span> <span class="n">extract_with_css</span><span class="p">(</span><span class="s1">'.author-born-date::text'</span><span class="p">),</span>
            <span class="s1">'bio'</span><span class="p">:</span> <span class="n">extract_with_css</span><span class="p">(</span><span class="s1">'.author-description::text'</span><span class="p">),</span>
        <span class="p">}</span>
</pre></div>
</div>
<p>This spider will start from the main page, it will follow all the links to the
authors pages calling the <code class="docutils literal notranslate"><span class="pre">parse_author</span></code> callback for each of them, and also
the pagination links with the <code class="docutils literal notranslate"><span class="pre">parse</span></code> callback as we saw before.</p>
<p>Here we’re passing callbacks to <code class="docutils literal notranslate"><span class="pre">response.follow</span></code> as positional arguments
to make the code shorter; it also works for <code class="docutils literal notranslate"><span class="pre">scrapy.Request</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">parse_author</span></code> callback defines a helper function to extract and cleanup the
data from a CSS query and yields the Python dict with the author data.</p>
<p>Another interesting thing this spider demonstrates is that, even if there are
many quotes from the same author, we don’t need to worry about visiting the
same author page multiple times. By default, Scrapy filters out duplicated
requests to URLs already visited, avoiding the problem of hitting servers too
much because of a programming mistake. This can be configured by the setting
<a class="reference internal" href="../topics/settings.html#std:setting-DUPEFILTER_CLASS"><code class="xref std std-setting docutils literal notranslate"><span class="pre">DUPEFILTER_CLASS</span></code></a>.</p>
<p>Hopefully by now you have a good understanding of how to use the mechanism
of following links and callbacks with Scrapy.</p>
<p>As yet another example spider that leverages the mechanism of following links,
check out the <a class="reference internal" href="../topics/spiders.html#scrapy.spiders.CrawlSpider" title="scrapy.spiders.CrawlSpider"><code class="xref py py-class docutils literal notranslate"><span class="pre">CrawlSpider</span></code></a> class for a generic
spider that implements a small rules engine that you can use to write your
crawlers on top of it.</p>
<p>Also, a common pattern is to build an item with data from more than one page,
using a <a class="reference internal" href="../topics/request-response.html#topics-request-response-ref-request-callback-arguments"><span class="std std-ref">trick to pass additional data to the callbacks</span></a>.</p>
</div>
</div>
<div class="section" id="using-spider-arguments">
<h2>Using spider arguments<a class="headerlink" href="#using-spider-arguments" title="Permalink to this headline">¶</a></h2>
<p>You can provide command line arguments to your spiders by using the <code class="docutils literal notranslate"><span class="pre">-a</span></code>
option when running them:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">crawl</span> <span class="n">quotes</span> <span class="o">-</span><span class="n">o</span> <span class="n">quotes</span><span class="o">-</span><span class="n">humor</span><span class="o">.</span><span class="n">json</span> <span class="o">-</span><span class="n">a</span> <span class="n">tag</span><span class="o">=</span><span class="n">humor</span>
</pre></div>
</div>
<p>These arguments are passed to the Spider’s <code class="docutils literal notranslate"><span class="pre">__init__</span></code> method and become
spider attributes by default.</p>
<p>In this example, the value provided for the <code class="docutils literal notranslate"><span class="pre">tag</span></code> argument will be available
via <code class="docutils literal notranslate"><span class="pre">self.tag</span></code>. You can use this to make your spider fetch only quotes
with a specific tag, building the URL based on the argument:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">"quotes"</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">url</span> <span class="o">=</span> <span class="s1">'http://quotes.toscrape.com/'</span>
        <span class="n">tag</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">'tag'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">tag</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">url</span> <span class="o">=</span> <span class="n">url</span> <span class="o">+</span> <span class="s1">'tag/'</span> <span class="o">+</span> <span class="n">tag</span>
        <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'div.quote'</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">'text'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'span.text::text'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">'author'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'small.author::text'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
            <span class="p">}</span>

        <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'li.next a::attr(href)'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">next_page</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">next_page</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</pre></div>
</div>
<p>If you pass the <code class="docutils literal notranslate"><span class="pre">tag=humor</span></code> argument to this spider, you’ll notice that it
will only visit URLs from the <code class="docutils literal notranslate"><span class="pre">humor</span></code> tag, such as
<code class="docutils literal notranslate"><span class="pre">http://quotes.toscrape.com/tag/humor</span></code>.</p>
<p>You can <a class="reference internal" href="../topics/spiders.html#spiderargs"><span class="std std-ref">learn more about handling spider arguments here</span></a>.</p>
</div>
<div class="section" id="next-steps">
<h2>Next steps<a class="headerlink" href="#next-steps" title="Permalink to this headline">¶</a></h2>
<p>This tutorial covered only the basics of Scrapy, but there’s a lot of other
features not mentioned here. Check the <a class="reference internal" href="overview.html#topics-whatelse"><span class="std std-ref">What else?</span></a> section in
<a class="reference internal" href="overview.html#intro-overview"><span class="std std-ref">Scrapy at a glance</span></a> chapter for a quick overview of the most important ones.</p>
<p>You can continue from the section <a class="reference internal" href="../index.html#section-basics"><span class="std std-ref">Basic concepts</span></a> to know more about the
command-line tool, spiders, selectors and other things the tutorial hasn’t covered like
modeling the scraped data. If you prefer to play with an example project, check
the <a class="reference internal" href="examples.html#intro-examples"><span class="std std-ref">Examples</span></a> section.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="examples.html" class="btn btn-neutral float-right" title="Examples" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="install.html" class="btn btn-neutral" title="Installation guide" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr /><div><div id="rtd-4wxrash2" class="ethical-rtd"></div></div>

  <div role="contentinfo">
    <p>
        © Copyright 2008–2018, Scrapy developers
      
        <span class="commit">
          Revision <code>a9254127</code>.
        </span>
      

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: 1.6
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions"><!-- Inserted RTD Footer -->
<div class="injected">

  

      
      
      
      <dl>
        <dt>Versions</dt>
        
        
        <dd><a href="https://docs.scrapy.org/en/latest/intro/tutorial.html">latest</a></dd>
        
        
         <strong> 
        <dd><a href="https://docs.scrapy.org/en/1.6/intro/tutorial.html">1.6</a></dd>
         </strong> 
        
        
        <dd><a href="https://docs.scrapy.org/en/1.5/intro/tutorial.html">1.5</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.4/intro/tutorial.html">1.4</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.3/intro/tutorial.html">1.3</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.2/intro/tutorial.html">1.2</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.1/intro/tutorial.html">1.1</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.0/intro/tutorial.html">1.0</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.24/intro/tutorial.html">0.24</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.22/intro/tutorial.html">0.22</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.20/intro/tutorial.html">0.20</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/master/intro/tutorial.html">master</a></dd>
        
        
      </dl>
      
      

      
      
      <dl>
        <dt>Downloads</dt>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/pdf/1.6/">PDF</a></dd>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/htmlzip/1.6/">HTML</a></dd>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/epub/1.6/">Epub</a></dd>
        
      </dl>
      
      

      
      <dl>
        <!-- These are kept as relative links for internal installs that are http -->
        <dt>On Read the Docs</dt>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/">Project Home</a>
        </dd>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/builds/">Builds</a>
        </dd>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/downloads/">Downloads</a>
        </dd>
      </dl>
      

      

      
      <dl>
        <dt>On GitHub</dt>
        <dd>
          <a href="https://github.com/scrapy/scrapy/blob/1.6/docs/intro/tutorial.rst">View</a>
        </dd>
        
        <dd>
          <a href="https://github.com/scrapy/scrapy/edit/1.6/docs/intro/tutorial.rst">Edit</a>
        </dd>
        
      </dl>
      
      

      
      <dl>
        <dt>Search</dt>
        <dd>
          <div style="padding: 6px;">
            <form id="flyout-search-form" class="wy-form" target="_blank" action="//readthedocs.org/projects/scrapy/search/" method="get">
              <input type="text" name="q" placeholder="Search docs" />
              </form>
          </div>
        </dd>
      </dl>
      



      <hr />
      
        <small>
          <span>Hosted by <a href="https://readthedocs.org">Read the Docs</a></span>
          <span> · </span>
          <a href="https://docs.readthedocs.io/page/privacy-policy.html">Privacy Policy</a>
        </small>
      

      

</div>
</div>
  </div>



  

    
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'../',
              VERSION:'1.6.0',
              LANGUAGE:'en',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="https://assets.readthedocs.org/static/javascript/readthedocs-doc-embed.js"></script>
    

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script type="text/javascript">
!function(){var analytics=window.analytics=window.analytics||[];if(!analytics.initialize)if(analytics.invoked)window.console&amp;&amp;console.error&amp;&amp;console.error("Segment snippet included twice.");else{analytics.invoked=!0;analytics.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","page","once","off","on"];analytics.factory=function(t){return function(){var e=Array.prototype.slice.call(arguments);e.unshift(t);analytics.push(e);return analytics}};for(var t=0;t&lt;analytics.methods.length;t++){var e=analytics.methods[t];analytics[e]=analytics.factory(e)}analytics.load=function(t){var e=document.createElement("script");e.type="text/javascript";e.async=!0;e.src=("https:"===document.location.protocol?"https://":"http://")+"cdn.segment.com/analytics.js/v1/"+t+"/analytics.min.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n)};analytics.SNIPPET_VERSION="3.1.0";
analytics.load("8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA");
analytics.page();
}}();

analytics.ready(function () {
    ga('require', 'linker');
    ga('linker:autoLink', ['scrapinghub.com', 'crawlera.com']);
});
</script>



<div id="rtd-rd5wkvvo"><div class="ethical-fixedfooter"><div class="ethical-content"><div class="ethical-close"><a href="javascript:$('.ethical-fixedfooter').hide()" aria-label="Close Ad">×</a></div><img src="https://readthedocs.org/sustainability/view/548/Os13DoMNDiOo/" class="ethical-pixel" /><div><a href="https://readthedocs.org/sustainability/click/548/Os13DoMNDiOo/" rel="nofollow" target="_blank"><span class="ethical-text"></span></a><a href="https://readthedocs.org/sustainability/click/548/Os13DoMNDiOo/" rel="nofollow" target="_blank">Hiring Python devs? Read the Docs can help!</a><span class="ethical-callout"><small><em><a href="https://docs.readthedocs.io/en/latest/ethical-advertising.html" rel="nofollow" target="_blank">ads served ethically</a></em></small></span></div></div></div></div></body></html>