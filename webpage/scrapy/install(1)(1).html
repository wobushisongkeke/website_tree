<!DOCTYPE html><!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]--><!--[if gt IE 8]><!--><html xmlns="http://www.w3.org/1999/xhtml" class=" js flexbox canvas canvastext webgl no-touch geolocation postmessage websqldatabase indexeddb hashchange history draganddrop websockets rgba hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients cssreflections csstransforms csstransforms3d csstransitions fontface generatedcontent video audio localstorage sessionstorage webworkers applicationcache svg inlinesvg smil svgclippaths" lang="en" style=""><!--<![endif]--><head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Installation guide — Scrapy 1.5.2 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Scrapy Tutorial" href="tutorial.html" />
    <link rel="prev" title="Scrapy at a glance" href="overview.html" /> 

  
  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script type="text/javascript" async="" src="https://www.google-analytics.com/plugins/ua/linkid.js"></script><script type="text/javascript" async="" src="https://cdn.segment.com/analytics.js/v1/8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA/analytics.min.js"></script><script async="" src="https://www.google-analytics.com/analytics.js"></script><script src="../_static/js/modernizr.min.js"></script>


<!-- RTD Extra Head -->

<!-- 
Always link to the latest version, as canonical.
http://docs.readthedocs.org/en/latest/canonical.html
-->
<link rel="canonical" href="http://doc.scrapy.org/en/latest/intro/install.html" />

<link rel="stylesheet" href="https://assets.readthedocs.org/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="text/javascript" src="../_static/readthedocs-data.js"></script>

<!-- Add page-specific data, which must exist in the page js, not global -->
<script type="text/javascript">
READTHEDOCS_DATA['page'] = 'intro/install'
READTHEDOCS_DATA['source_suffix'] = '.rst'
</script>

<script type="text/javascript" src="https://assets.readthedocs.org/static/javascript/readthedocs-analytics.js"></script>

<!-- end RTD <extrahead> -->
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Scrapy
          

          
          </a>

          
            
            
            
              <div class="version">
                1.5
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">First steps</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Scrapy at a glance</a></li>
<li class="toctree-l1 current"><a class="reference internal current" href="#"><span class="toctree-expand"></span>Installation guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#installing-scrapy"><span class="toctree-expand"></span>Installing Scrapy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#things-that-are-good-to-know">Things that are good to know</a></li>
<li class="toctree-l3"><a class="reference internal" href="#using-a-virtual-environment-recommended">Using a virtual environment (recommended)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#platform-specific-installation-notes"><span class="toctree-expand"></span>Platform specific installation notes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#windows">Windows</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ubuntu-14-04-or-above">Ubuntu 14.04 or above</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mac-os-x">Mac OS X</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pypy">PyPy</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorial.html">Scrapy Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/commands.html">Command line tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/spiders.html">Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/selectors.html">Selectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/items.html">Items</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/loaders.html">Item Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/shell.html">Scrapy shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/item-pipeline.html">Item Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/feed-exports.html">Feed exports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/request-response.html">Requests and Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/link-extractors.html">Link Extractors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/settings.html">Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/exceptions.html">Exceptions</a></li>
</ul>
<p class="caption"><span class="caption-text">Built-in services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/stats.html">Stats Collection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/email.html">Sending e-mail</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/telnetconsole.html">Telnet Console</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/webservice.html">Web Service</a></li>
</ul>
<p class="caption"><span class="caption-text">Solving specific problems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/debug.html">Debugging Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/contracts.html">Spiders Contracts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/practices.html">Common Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/broad-crawls.html">Broad Crawls</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/firefox.html">Using Firefox for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/firebug.html">Using Firebug for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/leaks.html">Debugging memory leaks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/media-pipeline.html">Downloading and processing files and images</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/deploy.html">Deploying Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/autothrottle.html">AutoThrottle extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/jobs.html">Jobs: pausing and resuming crawls</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending Scrapy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/architecture.html">Architecture overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/downloader-middleware.html">Downloader Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/spider-middleware.html">Spider Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/extensions.html">Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/api.html">Core API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/signals.html">Signals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/exporters.html">Item Exporters</a></li>
</ul>
<p class="caption"><span class="caption-text">All the rest</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html">Versioning and API Stability</a></li>
</ul>

            
          
        </div>
      <div id="rtd-1q8siqn2" class="ethical-rtd ethical-dark-theme"></div></div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Scrapy</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> »</li>
        
      <li>Installation guide</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/scrapy/scrapy/blob/1.5/docs/intro/install.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr />
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article"><div class="admonition warning"> <p class="first admonition-title">Note</p> <p class="last"> You are not reading the most recent version of this documentation. <a href="/en/1.6/intro/install.html">1.6</a> is the latest version available.</p></div>
           <div itemprop="articleBody">
            
  <div class="section" id="installation-guide">
<span id="intro-install"></span><h1>Installation guide<a class="headerlink" href="#installation-guide" title="Permalink to this headline">¶</a></h1>
<div class="section" id="installing-scrapy">
<h2>Installing Scrapy<a class="headerlink" href="#installing-scrapy" title="Permalink to this headline">¶</a></h2>
<p>Scrapy runs on Python 2.7 and Python 3.4 or above
under CPython (default Python implementation) and PyPy (starting with PyPy 5.9).</p>
<p>If you’re using <a class="reference external" href="https://docs.anaconda.com/anaconda/">Anaconda</a> or <a class="reference external" href="https://conda.io/docs/user-guide/install/index.html">Miniconda</a>, you can install the package from
the <a class="reference external" href="https://conda-forge.org/">conda-forge</a> channel, which has up-to-date packages for Linux, Windows
and OS X.</p>
<p>To install Scrapy using <code class="docutils literal notranslate"><span class="pre">conda</span></code>, run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">install</span> <span class="o">-</span><span class="n">c</span> <span class="n">conda</span><span class="o">-</span><span class="n">forge</span> <span class="n">scrapy</span>
</pre></div>
</div>
<p>Alternatively, if you’re already familiar with installation of Python packages,
you can install Scrapy and its dependencies from PyPI with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">Scrapy</span>
</pre></div>
</div>
<p>Note that sometimes this may require solving compilation issues for some Scrapy
dependencies depending on your operating system, so be sure to check the
<a class="reference internal" href="#intro-install-platform-notes"><span class="std std-ref">Platform specific installation notes</span></a>.</p>
<p>We strongly recommend that you install Scrapy in <a class="reference internal" href="#intro-using-virtualenv"><span class="std std-ref">a dedicated virtualenv</span></a>,
to avoid conflicting with your system packages.</p>
<p>For more detailed and platform specifics instructions, read on.</p>
<div class="section" id="things-that-are-good-to-know">
<h3>Things that are good to know<a class="headerlink" href="#things-that-are-good-to-know" title="Permalink to this headline">¶</a></h3>
<p>Scrapy is written in pure Python and depends on a few key Python packages (among others):</p>
<ul class="simple">
<li><a class="reference external" href="http://lxml.de/">lxml</a>, an efficient XML and HTML parser</li>
<li><a class="reference external" href="https://pypi.python.org/pypi/parsel">parsel</a>, an HTML/XML data extraction library written on top of lxml,</li>
<li><a class="reference external" href="https://pypi.python.org/pypi/w3lib">w3lib</a>, a multi-purpose helper for dealing with URLs and web page encodings</li>
<li><a class="reference external" href="https://twistedmatrix.com/">twisted</a>, an asynchronous networking framework</li>
<li><a class="reference external" href="https://cryptography.io/">cryptography</a> and <a class="reference external" href="https://pypi.python.org/pypi/pyOpenSSL">pyOpenSSL</a>, to deal with various network-level security needs</li>
</ul>
<p>The minimal versions which Scrapy is tested against are:</p>
<ul class="simple">
<li>Twisted 14.0</li>
<li>lxml 3.4</li>
<li>pyOpenSSL 0.14</li>
</ul>
<p>Scrapy may work with older versions of these packages
but it is not guaranteed it will continue working
because it’s not being tested against them.</p>
<p>Some of these packages themselves depends on non-Python packages
that might require additional installation steps depending on your platform.
Please check <a class="reference internal" href="#intro-install-platform-notes"><span class="std std-ref">platform-specific guides below</span></a>.</p>
<p>In case of any trouble related to these dependencies,
please refer to their respective installation instructions:</p>
<ul class="simple">
<li><a class="reference external" href="http://lxml.de/installation.html">lxml installation</a></li>
<li><a class="reference external" href="https://cryptography.io/en/latest/installation/">cryptography installation</a></li>
</ul>
</div>
<div class="section" id="using-a-virtual-environment-recommended">
<span id="intro-using-virtualenv"></span><h3>Using a virtual environment (recommended)<a class="headerlink" href="#using-a-virtual-environment-recommended" title="Permalink to this headline">¶</a></h3>
<p>TL;DR: We recommend installing Scrapy inside a virtual environment
on all platforms.</p>
<p>Python packages can be installed either globally (a.k.a system wide),
or in user-space. We do not recommend installing scrapy system wide.</p>
<p>Instead, we recommend that you install scrapy within a so-called
“virtual environment” (<a class="reference external" href="https://virtualenv.pypa.io">virtualenv</a>).
Virtualenvs allow you to not conflict with already-installed Python
system packages (which could break some of your system tools and scripts),
and still install packages normally with <code class="docutils literal notranslate"><span class="pre">pip</span></code> (without <code class="docutils literal notranslate"><span class="pre">sudo</span></code> and the likes).</p>
<p>To get started with virtual environments, see <a class="reference external" href="https://virtualenv.pypa.io/en/stable/installation/">virtualenv installation instructions</a>.
To install it globally (having it globally installed actually helps here),
it should be a matter of running:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ [sudo] pip install virtualenv
</pre></div>
</div>
<p>Check this <a class="reference external" href="https://virtualenv.pypa.io/en/stable/userguide/">user guide</a> on how to create your virtualenv.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If you use Linux or OS X, <a class="reference external" href="https://virtualenvwrapper.readthedocs.io/en/latest/install.html">virtualenvwrapper</a> is a handy tool to create virtualenvs.</p>
</div>
<p>Once you have created a virtualenv, you can install scrapy inside it with <code class="docutils literal notranslate"><span class="pre">pip</span></code>,
just like any other Python package.
(See <a class="reference internal" href="#intro-install-platform-notes"><span class="std std-ref">platform-specific guides</span></a>
below for non-Python dependencies that you may need to install beforehand).</p>
<p>Python virtualenvs can be created to use Python 2 by default, or Python 3 by default.</p>
<ul class="simple">
<li>If you want to install scrapy with Python 3, install scrapy within a Python 3 virtualenv.</li>
<li>And if you want to install scrapy with Python 2, install scrapy within a Python 2 virtualenv.</li>
</ul>
</div>
</div>
<div class="section" id="platform-specific-installation-notes">
<span id="intro-install-platform-notes"></span><h2>Platform specific installation notes<a class="headerlink" href="#platform-specific-installation-notes" title="Permalink to this headline">¶</a></h2>
<div class="section" id="windows">
<span id="intro-install-windows"></span><h3>Windows<a class="headerlink" href="#windows" title="Permalink to this headline">¶</a></h3>
<p>Though it’s possible to install Scrapy on Windows using pip, we recommend you
to install <a class="reference external" href="https://docs.anaconda.com/anaconda/">Anaconda</a> or <a class="reference external" href="https://conda.io/docs/user-guide/install/index.html">Miniconda</a> and use the package from the
<a class="reference external" href="https://conda-forge.org/">conda-forge</a> channel, which will avoid most installation issues.</p>
<p>Once you’ve installed <a class="reference external" href="https://docs.anaconda.com/anaconda/">Anaconda</a> or <a class="reference external" href="https://conda.io/docs/user-guide/install/index.html">Miniconda</a>, install Scrapy with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">install</span> <span class="o">-</span><span class="n">c</span> <span class="n">conda</span><span class="o">-</span><span class="n">forge</span> <span class="n">scrapy</span>
</pre></div>
</div>
</div>
<div class="section" id="ubuntu-14-04-or-above">
<span id="intro-install-ubuntu"></span><h3>Ubuntu 14.04 or above<a class="headerlink" href="#ubuntu-14-04-or-above" title="Permalink to this headline">¶</a></h3>
<p>Scrapy is currently tested with recent-enough versions of lxml,
twisted and pyOpenSSL, and is compatible with recent Ubuntu distributions.
But it should support older versions of Ubuntu too, like Ubuntu 14.04,
albeit with potential issues with TLS connections.</p>
<p><strong>Don’t</strong> use the <code class="docutils literal notranslate"><span class="pre">python-scrapy</span></code> package provided by Ubuntu, they are
typically too old and slow to catch up with latest Scrapy.</p>
<p>To install scrapy on Ubuntu (or Ubuntu-based) systems, you need to install
these dependencies:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="n">python</span><span class="o">-</span><span class="n">dev</span> <span class="n">python</span><span class="o">-</span><span class="n">pip</span> <span class="n">libxml2</span><span class="o">-</span><span class="n">dev</span> <span class="n">libxslt1</span><span class="o">-</span><span class="n">dev</span> <span class="n">zlib1g</span><span class="o">-</span><span class="n">dev</span> <span class="n">libffi</span><span class="o">-</span><span class="n">dev</span> <span class="n">libssl</span><span class="o">-</span><span class="n">dev</span>
</pre></div>
</div>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">python-dev</span></code>, <code class="docutils literal notranslate"><span class="pre">zlib1g-dev</span></code>, <code class="docutils literal notranslate"><span class="pre">libxml2-dev</span></code> and <code class="docutils literal notranslate"><span class="pre">libxslt1-dev</span></code>
are required for <code class="docutils literal notranslate"><span class="pre">lxml</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">libssl-dev</span></code> and <code class="docutils literal notranslate"><span class="pre">libffi-dev</span></code> are required for <code class="docutils literal notranslate"><span class="pre">cryptography</span></code></li>
</ul>
<p>If you want to install scrapy on Python 3, you’ll also need Python 3 development headers:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="n">python3</span> <span class="n">python3</span><span class="o">-</span><span class="n">dev</span>
</pre></div>
</div>
<p>Inside a <a class="reference internal" href="#intro-using-virtualenv"><span class="std std-ref">virtualenv</span></a>,
you can install Scrapy with <code class="docutils literal notranslate"><span class="pre">pip</span></code> after that:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">scrapy</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The same non-Python dependencies can be used to install Scrapy in Debian
Jessie (8.0) and above.</p>
</div>
</div>
<div class="section" id="mac-os-x">
<span id="intro-install-macos"></span><h3>Mac OS X<a class="headerlink" href="#mac-os-x" title="Permalink to this headline">¶</a></h3>
<p>Building Scrapy’s dependencies requires the presence of a C compiler and
development headers. On OS X this is typically provided by Apple’s Xcode
development tools. To install the Xcode command line tools open a terminal
window and run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">xcode</span><span class="o">-</span><span class="n">select</span> <span class="o">--</span><span class="n">install</span>
</pre></div>
</div>
<p>There’s a <a class="reference external" href="https://github.com/pypa/pip/issues/2468">known issue</a> that
prevents <code class="docutils literal notranslate"><span class="pre">pip</span></code> from updating system packages. This has to be addressed to
successfully install Scrapy and its dependencies. Here are some proposed
solutions:</p>
<ul>
<li><p class="first"><em>(Recommended)</em> <strong>Don’t</strong> use system python, install a new, updated version
that doesn’t conflict with the rest of your system. Here’s how to do it using
the <a class="reference external" href="https://brew.sh/">homebrew</a> package manager:</p>
<ul>
<li><p class="first">Install <a class="reference external" href="https://brew.sh/">homebrew</a> following the instructions in <a class="reference external" href="https://brew.sh/">https://brew.sh/</a></p>
</li>
<li><p class="first">Update your <code class="docutils literal notranslate"><span class="pre">PATH</span></code> variable to state that homebrew packages should be
used before system packages (Change <code class="docutils literal notranslate"><span class="pre">.bashrc</span></code> to <code class="docutils literal notranslate"><span class="pre">.zshrc</span></code> accordantly
if you’re using <a class="reference external" href="https://www.zsh.org/">zsh</a> as default shell):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">echo</span> <span class="s2">"export PATH=/usr/local/bin:/usr/local/sbin:$PATH"</span> <span class="o">&gt;&gt;</span> <span class="o">~/.</span><span class="n">bashrc</span>
</pre></div>
</div>
</li>
<li><p class="first">Reload <code class="docutils literal notranslate"><span class="pre">.bashrc</span></code> to ensure the changes have taken place:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">source</span> <span class="o">~/.</span><span class="n">bashrc</span>
</pre></div>
</div>
</li>
<li><p class="first">Install python:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">brew</span> <span class="n">install</span> <span class="n">python</span>
</pre></div>
</div>
</li>
<li><p class="first">Latest versions of python have <code class="docutils literal notranslate"><span class="pre">pip</span></code> bundled with them so you won’t need
to install it separately. If this is not the case, upgrade python:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">brew</span> <span class="n">update</span><span class="p">;</span> <span class="n">brew</span> <span class="n">upgrade</span> <span class="n">python</span>
</pre></div>
</div>
</li>
</ul>
</li>
<li><p class="first"><em>(Optional)</em> Install Scrapy inside an isolated python environment.</p>
<p>This method is a workaround for the above OS X issue, but it’s an overall
good practice for managing dependencies and can complement the first method.</p>
<p><a class="reference external" href="https://virtualenv.pypa.io">virtualenv</a> is a tool you can use to create virtual environments in python.
We recommended reading a tutorial like
<a class="reference external" href="http://docs.python-guide.org/en/latest/dev/virtualenvs/">http://docs.python-guide.org/en/latest/dev/virtualenvs/</a> to get started.</p>
</li>
</ul>
<p>After any of these workarounds you should be able to install Scrapy:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">Scrapy</span>
</pre></div>
</div>
</div>
<div class="section" id="pypy">
<h3>PyPy<a class="headerlink" href="#pypy" title="Permalink to this headline">¶</a></h3>
<p>We recommend using the latest PyPy version. The version tested is 5.9.0.
For PyPy3, only Linux installation was tested.</p>
<p>Most scrapy dependencides now have binary wheels for CPython, but not for PyPy.
This means that these dependecies will be built during installation.
On OS X, you are likely to face an issue with building Cryptography dependency,
solution to this problem is described
<a class="reference external" href="https://github.com/pyca/cryptography/issues/2692#issuecomment-272773481">here</a>,
that is to <code class="docutils literal notranslate"><span class="pre">brew</span> <span class="pre">install</span> <span class="pre">openssl</span></code> and then export the flags that this command
recommends (only needed when installing scrapy). Installing on Linux has no special
issues besides installing build dependencies.
Installing scrapy with PyPy on Windows is not tested.</p>
<p>You can check that scrapy is installed correctly by running <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">bench</span></code>.
If this command gives errors such as
<code class="docutils literal notranslate"><span class="pre">TypeError:</span> <span class="pre">...</span> <span class="pre">got</span> <span class="pre">2</span> <span class="pre">unexpected</span> <span class="pre">keyword</span> <span class="pre">arguments</span></code>, this means
that setuptools was unable to pick up one PyPy-specific dependency.
To fix this issue, run <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">'PyPyDispatcher&gt;=2.1.0'</span></code>.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="tutorial.html" class="btn btn-neutral float-right" title="Scrapy Tutorial" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="overview.html" class="btn btn-neutral" title="Scrapy at a glance" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr /><div><div id="rtd-p9znaimh" class="ethical-rtd"></div></div>

  <div role="contentinfo">
    <p>
        © Copyright 2008-2016, Scrapy developers
      
        <span class="commit">
          Revision <code>2ff27774</code>.
        </span>
      

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: 1.5
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions"><!-- Inserted RTD Footer -->
<div class="injected">

  

      
      
      
      <dl>
        <dt>Versions</dt>
        
        
        <dd><a href="https://docs.scrapy.org/en/latest/intro/install.html">latest</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.6/intro/install.html">1.6</a></dd>
        
        
         <strong> 
        <dd><a href="https://docs.scrapy.org/en/1.5/intro/install.html">1.5</a></dd>
         </strong> 
        
        
        <dd><a href="https://docs.scrapy.org/en/1.4/intro/install.html">1.4</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.3/intro/install.html">1.3</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.2/intro/install.html">1.2</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.1/intro/install.html">1.1</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.0/intro/install.html">1.0</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.24/intro/install.html">0.24</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.22/intro/install.html">0.22</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.20/intro/install.html">0.20</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/master/intro/install.html">master</a></dd>
        
        
      </dl>
      
      

      
      
      <dl>
        <dt>Downloads</dt>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/pdf/1.5/">PDF</a></dd>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/htmlzip/1.5/">HTML</a></dd>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/epub/1.5/">Epub</a></dd>
        
      </dl>
      
      

      
      <dl>
        <!-- These are kept as relative links for internal installs that are http -->
        <dt>On Read the Docs</dt>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/">Project Home</a>
        </dd>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/builds/">Builds</a>
        </dd>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/downloads/">Downloads</a>
        </dd>
      </dl>
      

      

      
      <dl>
        <dt>On GitHub</dt>
        <dd>
          <a href="https://github.com/scrapy/scrapy/blob/1.5/docs/intro/install.rst">View</a>
        </dd>
        
        <dd>
          <a href="https://github.com/scrapy/scrapy/edit/1.5/docs/intro/install.rst">Edit</a>
        </dd>
        
      </dl>
      
      

      
      <dl>
        <dt>Search</dt>
        <dd>
          <div style="padding: 6px;">
            <form id="flyout-search-form" class="wy-form" target="_blank" action="//readthedocs.org/projects/scrapy/search/" method="get">
              <input type="text" name="q" placeholder="Search docs" />
              </form>
          </div>
        </dd>
      </dl>
      



      <hr />
      
        <small>
          <span>Hosted by <a href="https://readthedocs.org">Read the Docs</a></span>
          <span> · </span>
          <a href="https://docs.readthedocs.io/page/privacy-policy.html">Privacy Policy</a>
        </small>
      

      

</div>
</div>
  </div>



  

    
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'../',
              VERSION:'1.5.2',
              LANGUAGE:'en',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="https://assets.readthedocs.org/static/javascript/readthedocs-doc-embed.js"></script>
    

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script type="text/javascript">
!function(){var analytics=window.analytics=window.analytics||[];if(!analytics.initialize)if(analytics.invoked)window.console&amp;&amp;console.error&amp;&amp;console.error("Segment snippet included twice.");else{analytics.invoked=!0;analytics.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","page","once","off","on"];analytics.factory=function(t){return function(){var e=Array.prototype.slice.call(arguments);e.unshift(t);analytics.push(e);return analytics}};for(var t=0;t&lt;analytics.methods.length;t++){var e=analytics.methods[t];analytics[e]=analytics.factory(e)}analytics.load=function(t){var e=document.createElement("script");e.type="text/javascript";e.async=!0;e.src=("https:"===document.location.protocol?"https://":"http://")+"cdn.segment.com/analytics.js/v1/"+t+"/analytics.min.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n)};analytics.SNIPPET_VERSION="3.1.0";
analytics.load("8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA");
analytics.page();
}}();

analytics.ready(function () {
    ga('require', 'linker');
    ga('linker:autoLink', ['scrapinghub.com', 'crawlera.com']);
});
</script>



<div id="rtd-e35paeqlk"><div class="ethical-fixedfooter"><div class="ethical-content"><div class="ethical-close"><a href="javascript:$('.ethical-fixedfooter').hide()" aria-label="Close Ad">×</a></div><img src="https://readthedocs.org/sustainability/view/641/CoKJbdueLRVn/" class="ethical-pixel" /><div><a href="https://readthedocs.org/sustainability/click/641/CoKJbdueLRVn/" rel="nofollow" target="_blank"><span class="ethical-text"></span></a><a href="https://readthedocs.org/sustainability/click/641/CoKJbdueLRVn/" rel="nofollow" target="_blank">Private repos and priority support. Try Read the Docs for Business Today!</a><span class="ethical-callout"><small><em><a href="https://docs.readthedocs.io/en/latest/ethical-advertising.html" rel="nofollow" target="_blank">ads served ethically</a></em></small></span></div></div></div></div></body></html>