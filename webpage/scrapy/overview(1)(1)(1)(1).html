<!DOCTYPE html><!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]--><!--[if gt IE 8]><!--><html xmlns="http://www.w3.org/1999/xhtml" class=" js flexbox canvas canvastext webgl no-touch geolocation postmessage websqldatabase indexeddb hashchange history draganddrop websockets rgba hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients cssreflections csstransforms csstransforms3d csstransitions fontface generatedcontent video audio localstorage sessionstorage webworkers applicationcache svg inlinesvg smil svgclippaths" lang="en" style=""><!--<![endif]--><head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Scrapy at a glance — Scrapy 1.3.3 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  

  
    <link rel="stylesheet" href="https://media.readthedocs.org/css/sphinx_rtd_theme.css" type="text/css" />
  

  
        <link rel="index" title="Index" href="../genindex.html" />
        <link rel="search" title="Search" href="../search.html" />
    <link rel="top" title="Scrapy 1.3.3 documentation" href="../index.html" />
        <link rel="next" title="Installation guide" href="install.html" />
        <link rel="prev" title="Scrapy 1.3 documentation" href="../index.html" /> 

  
  <script type="text/javascript" async="" src="https://www.google-analytics.com/plugins/ua/linkid.js"></script><script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script type="text/javascript" async="" src="https://cdn.segment.com/analytics.js/v1/8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA/analytics.min.js"></script><script type="text/javascript" async="" src="https://ssl.google-analytics.com/ga.js"></script><script src="../_static/js/modernizr.min.js"></script>


<!-- RTD Extra Head -->

<!-- 
Always link to the latest version, as canonical.
http://docs.readthedocs.org/en/latest/canonical.html
-->
<link rel="canonical" href="http://doc.scrapy.org/en/latest/intro/overview.html" />

<link rel="stylesheet" href="https://media.readthedocs.org/css/readthedocs-doc-embed.css" type="text/css" />

<script type="text/javascript" src="../_static/readthedocs-data.js"></script>

<!-- Add page-specific data, which must exist in the page js, not global -->
<script type="text/javascript">
READTHEDOCS_DATA['page'] = 'intro/overview' 		
READTHEDOCS_DATA['source_suffix'] = '.rst'
</script>

<script type="text/javascript" src="../_static/readthedocs-dynamic-include.js"></script>

<!-- end RTD <extrahead> --></head>

<body class="wy-body-for-nav" role="document" style="">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Scrapy
          

          
          </a>

          
            
            
            
              <div class="version">
                1.3
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">First steps</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal current" href="#"><span class="toctree-expand"></span>Scrapy at a glance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#walk-through-of-an-example-spider"><span class="toctree-expand"></span>Walk-through of an example spider</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#what-just-happened">What just happened?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#what-else">What else?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-s-next">What’s next?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="install.html">Installation guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial.html">Scrapy Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/commands.html">Command line tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/spiders.html">Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/selectors.html">Selectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/items.html">Items</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/loaders.html">Item Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/shell.html">Scrapy shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/item-pipeline.html">Item Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/feed-exports.html">Feed exports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/request-response.html">Requests and Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/link-extractors.html">Link Extractors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/settings.html">Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/exceptions.html">Exceptions</a></li>
</ul>
<p class="caption"><span class="caption-text">Built-in services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/stats.html">Stats Collection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/email.html">Sending e-mail</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/telnetconsole.html">Telnet Console</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/webservice.html">Web Service</a></li>
</ul>
<p class="caption"><span class="caption-text">Solving specific problems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/debug.html">Debugging Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/contracts.html">Spiders Contracts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/practices.html">Common Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/broad-crawls.html">Broad Crawls</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/firefox.html">Using Firefox for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/firebug.html">Using Firebug for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/leaks.html">Debugging memory leaks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/media-pipeline.html">Downloading and processing files and images</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/deploy.html">Deploying Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/autothrottle.html">AutoThrottle extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/jobs.html">Jobs: pausing and resuming crawls</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending Scrapy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../topics/architecture.html">Architecture overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/downloader-middleware.html">Downloader Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/spider-middleware.html">Spider Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/extensions.html">Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/api.html">Core API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/signals.html">Signals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topics/exporters.html">Item Exporters</a></li>
</ul>
<p class="caption"><span class="caption-text">All the rest</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html">Versioning and API Stability</a></li>
</ul>

            
          
        </div>
      <div id="rtd-kxri0bub" class="ethical-rtd ethical-dark-theme"><div class="ethical-sidebar"><div class="ethical-content"><a href="https://readthedocs.org/sustainability/click/305/EVbKYq5Wq7av/" rel="nofollow" target="_blank" class="ethical-image-link"><img src="https://assets.readthedocs.org/sustainability/readthedocs-logo-fs8.png" /></a><div class="ethical-text"><a href="https://readthedocs.org/sustainability/click/305/EVbKYq5Wq7av/" rel="nofollow" target="_blank">Private repos and priority support<br />Try Read the Docs for Business Today!</a></div></div><div class="ethical-callout"><small><em><a href="https://readthedocs.org/sustainability/advertising/">Sponsored</a><span> · </span><a href="https://docs.readthedocs.io/en/latest/ethical-advertising.html">Ads served ethically</a></em></small></div></div></div></div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Scrapy</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> »</li>
        
      <li>Scrapy at a glance</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/scrapy/scrapy/blob/1.3/docs/intro/overview.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr />
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article"><div class="admonition warning"> <p class="first admonition-title">Note</p> <p class="last"> You are not reading the most recent version of this documentation. <a href="/en/1.6/intro/overview.html">1.6</a> is the latest version available.</p></div>
           <div itemprop="articleBody">
            
  <div class="section" id="scrapy-at-a-glance">
<span id="intro-overview"></span><h1>Scrapy at a glance<a class="headerlink" href="#scrapy-at-a-glance" title="Permalink to this headline">¶</a></h1>
<p>Scrapy is an application framework for crawling web sites and extracting
structured data which can be used for a wide range of useful applications, like
data mining, information processing or historical archival.</p>
<p>Even though Scrapy was originally designed for <a class="reference external" href="https://en.wikipedia.org/wiki/Web_scraping">web scraping</a>, it can also be
used to extract data using APIs (such as <a class="reference external" href="https://affiliate-program.amazon.com/gp/advertising/api/detail/main.html">Amazon Associates Web Services</a>) or
as a general purpose web crawler.</p>
<div class="section" id="walk-through-of-an-example-spider">
<h2>Walk-through of an example spider<a class="headerlink" href="#walk-through-of-an-example-spider" title="Permalink to this headline">¶</a></h2>
<p>In order to show you what Scrapy brings to the table, we’ll walk you through an
example of a Scrapy Spider using the simplest way to run a spider.</p>
<p>Here’s the code for a spider that scrapes famous quotes from website
<a class="reference external" href="http://quotes.toscrape.com">http://quotes.toscrape.com</a>, following the pagination:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">"quotes"</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">'http://quotes.toscrape.com/tag/humor/'</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'div.quote'</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">'text'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'span.text::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
                <span class="s1">'author'</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">'span/small/text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">(),</span>
            <span class="p">}</span>

        <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">'li.next a::attr("href")'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">next_page</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">next_page</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">next_page</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</pre></div>
</div>
<p>Put this in a text file, name it to something like <code class="docutils literal"><span class="pre">quotes_spider.py</span></code>
and run the spider using the <a class="reference internal" href="../topics/commands.html#std:command-runspider"><code class="xref std std-command docutils literal"><span class="pre">runspider</span></code></a> command:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">runspider</span> <span class="n">quotes_spider</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">o</span> <span class="n">quotes</span><span class="o">.</span><span class="n">json</span>
</pre></div>
</div>
<p>When this finishes you will have in the <code class="docutils literal"><span class="pre">quotes.json</span></code> file a list of the
quotes in JSON format, containing text and author, looking like this (reformatted
here for better readability):</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[{</span>
    <span class="s2">"author"</span><span class="p">:</span> <span class="s2">"Jane Austen"</span><span class="p">,</span>
    <span class="s2">"text"</span><span class="p">:</span> <span class="s2">"</span><span class="se">\u201c</span><span class="s2">The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.</span><span class="se">\u201d</span><span class="s2">"</span>
<span class="p">},</span>
<span class="p">{</span>
    <span class="s2">"author"</span><span class="p">:</span> <span class="s2">"Groucho Marx"</span><span class="p">,</span>
    <span class="s2">"text"</span><span class="p">:</span> <span class="s2">"</span><span class="se">\u201c</span><span class="s2">Outside of a dog, a book is man's best friend. Inside of a dog it's too dark to read.</span><span class="se">\u201d</span><span class="s2">"</span>
<span class="p">},</span>
<span class="p">{</span>
    <span class="s2">"author"</span><span class="p">:</span> <span class="s2">"Steve Martin"</span><span class="p">,</span>
    <span class="s2">"text"</span><span class="p">:</span> <span class="s2">"</span><span class="se">\u201c</span><span class="s2">A day without sunshine is like, you know, night.</span><span class="se">\u201d</span><span class="s2">"</span>
<span class="p">},</span>
<span class="o">...</span><span class="p">]</span>
</pre></div>
</div>
<div class="section" id="what-just-happened">
<h3>What just happened?<a class="headerlink" href="#what-just-happened" title="Permalink to this headline">¶</a></h3>
<p>When you ran the command <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">runspider</span> <span class="pre">quotes_spider.py</span></code>, Scrapy looked for a
Spider definition inside it and ran it through its crawler engine.</p>
<p>The crawl started by making requests to the URLs defined in the <code class="docutils literal"><span class="pre">start_urls</span></code>
attribute (in this case, only the URL for quotes in <em>humor</em> category)
and called the default callback method <code class="docutils literal"><span class="pre">parse</span></code>, passing the response object as
an argument. In the <code class="docutils literal"><span class="pre">parse</span></code> callback, we loop through the quote elements
using a CSS Selector, yield a Python dict with the extracted quote text and author,
look for a link to the next page and schedule another request using the same
<code class="docutils literal"><span class="pre">parse</span></code> method as callback.</p>
<p>Here you notice one of the main advantages about Scrapy: requests are
<a class="reference internal" href="../topics/architecture.html#topics-architecture"><span class="std std-ref">scheduled and processed asynchronously</span></a>.  This
means that Scrapy doesn’t need to wait for a request to be finished and
processed, it can send another request or do other things in the meantime. This
also means that other requests can keep going even if some request fails or an
error happens while handling it.</p>
<p>While this enables you to do very fast crawls (sending multiple concurrent
requests at the same time, in a fault-tolerant way) Scrapy also gives you
control over the politeness of the crawl through <a class="reference internal" href="../topics/settings.html#topics-settings-ref"><span class="std std-ref">a few settings</span></a>. You can do things like setting a download delay between
each request, limiting amount of concurrent requests per domain or per IP, and
even <a class="reference internal" href="../topics/autothrottle.html#topics-autothrottle"><span class="std std-ref">using an auto-throttling extension</span></a> that tries
to figure out these automatically.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This is using <a class="reference internal" href="../topics/feed-exports.html#topics-feed-exports"><span class="std std-ref">feed exports</span></a> to generate the
JSON file, you can easily change the export format (XML or CSV, for example) or the
storage backend (FTP or <a class="reference external" href="https://aws.amazon.com/s3/">Amazon S3</a>, for example).  You can also write an
<a class="reference internal" href="../topics/item-pipeline.html#topics-item-pipeline"><span class="std std-ref">item pipeline</span></a> to store the items in a database.</p>
</div>
</div>
</div>
<div class="section" id="what-else">
<span id="topics-whatelse"></span><h2>What else?<a class="headerlink" href="#what-else" title="Permalink to this headline">¶</a></h2>
<p>You’ve seen how to extract and store items from a website using Scrapy, but
this is just the surface. Scrapy provides a lot of powerful features for making
scraping easy and efficient, such as:</p>
<ul class="simple">
<li>Built-in support for <a class="reference internal" href="../topics/selectors.html#topics-selectors"><span class="std std-ref">selecting and extracting</span></a> data
from HTML/XML sources using extended CSS selectors and XPath expressions,
with helper methods to extract using regular expressions.</li>
<li>An <a class="reference internal" href="../topics/shell.html#topics-shell"><span class="std std-ref">interactive shell console</span></a> (IPython aware) for trying
out the CSS and XPath expressions to scrape data, very useful when writing or
debugging your spiders.</li>
<li>Built-in support for <a class="reference internal" href="../topics/feed-exports.html#topics-feed-exports"><span class="std std-ref">generating feed exports</span></a> in
multiple formats (JSON, CSV, XML) and storing them in multiple backends (FTP,
S3, local filesystem)</li>
<li>Robust encoding support and auto-detection, for dealing with foreign,
non-standard and broken encoding declarations.</li>
<li><a class="reference internal" href="../index.html#extending-scrapy"><span class="std std-ref">Strong extensibility support</span></a>, allowing you to plug
in your own functionality using <a class="reference internal" href="../topics/signals.html#topics-signals"><span class="std std-ref">signals</span></a> and a
well-defined API (middlewares, <a class="reference internal" href="../topics/extensions.html#topics-extensions"><span class="std std-ref">extensions</span></a>, and
<a class="reference internal" href="../topics/item-pipeline.html#topics-item-pipeline"><span class="std std-ref">pipelines</span></a>).</li>
<li>Wide range of built-in extensions and middlewares for handling:<ul>
<li>cookies and session handling</li>
<li>HTTP features like compression, authentication, caching</li>
<li>user-agent spoofing</li>
<li>robots.txt</li>
<li>crawl depth restriction</li>
<li>and more</li>
</ul>
</li>
<li>A <a class="reference internal" href="../topics/telnetconsole.html#topics-telnetconsole"><span class="std std-ref">Telnet console</span></a> for hooking into a Python
console running inside your Scrapy process, to introspect and debug your
crawler</li>
<li>Plus other goodies like reusable spiders to crawl sites from <a class="reference external" href="http://www.sitemaps.org">Sitemaps</a> and
XML/CSV feeds, a media pipeline for <a class="reference internal" href="../topics/media-pipeline.html#topics-media-pipeline"><span class="std std-ref">automatically downloading images</span></a> (or any other media) associated with the scraped
items, a caching DNS resolver, and much more!</li>
</ul>
</div>
<div class="section" id="what-s-next">
<h2>What’s next?<a class="headerlink" href="#what-s-next" title="Permalink to this headline">¶</a></h2>
<p>The next steps for you are to <a class="reference internal" href="install.html#intro-install"><span class="std std-ref">install Scrapy</span></a>,
<a class="reference internal" href="tutorial.html#intro-tutorial"><span class="std std-ref">follow through the tutorial</span></a> to learn how to create
a full-blown Scrapy project and <a class="reference external" href="http://scrapy.org/community/">join the community</a>. Thanks for your
interest!</p>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="install.html" class="btn btn-neutral float-right" title="Installation guide" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../index.html" class="btn btn-neutral" title="Scrapy 1.3 documentation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr /><div><div id="rtd-29x9elk4" class="ethical-rtd"></div></div>

  <div role="contentinfo">
    <p>
        © Copyright 2008-2016, Scrapy developers.
      
        <span class="commit">
          Revision <code>3c25d372</code>.
        </span>
      

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: 1.3
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions"><!-- Inserted RTD Footer -->
<div class="injected">

  

      
      
      
      <dl>
        <dt>Versions</dt>
        
        
        <dd><a href="https://docs.scrapy.org/en/latest/intro/overview.html">latest</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.6/intro/overview.html">1.6</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.5/intro/overview.html">1.5</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.4/intro/overview.html">1.4</a></dd>
        
        
         <strong> 
        <dd><a href="https://docs.scrapy.org/en/1.3/intro/overview.html">1.3</a></dd>
         </strong> 
        
        
        <dd><a href="https://docs.scrapy.org/en/1.2/intro/overview.html">1.2</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.1/intro/overview.html">1.1</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.0/intro/overview.html">1.0</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.24/intro/overview.html">0.24</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.22/intro/overview.html">0.22</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.20/intro/overview.html">0.20</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/master/intro/overview.html">master</a></dd>
        
        
      </dl>
      
      

      
      
      <dl>
        <dt>Downloads</dt>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/pdf/1.3/">PDF</a></dd>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/htmlzip/1.3/">HTML</a></dd>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/epub/1.3/">Epub</a></dd>
        
      </dl>
      
      

      
      <dl>
        <!-- These are kept as relative links for internal installs that are http -->
        <dt>On Read the Docs</dt>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/">Project Home</a>
        </dd>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/builds/">Builds</a>
        </dd>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/downloads/">Downloads</a>
        </dd>
      </dl>
      

      

      
      <dl>
        <dt>On GitHub</dt>
        <dd>
          <a href="https://github.com/scrapy/scrapy/blob/1.3/docs/intro/overview.rst">View</a>
        </dd>
        
        <dd>
          <a href="https://github.com/scrapy/scrapy/edit/1.3/docs/intro/overview.rst">Edit</a>
        </dd>
        
      </dl>
      
      

      
      <dl>
        <dt>Search</dt>
        <dd>
          <div style="padding: 6px;">
            <form id="flyout-search-form" class="wy-form" target="_blank" action="//readthedocs.org/projects/scrapy/search/" method="get">
              <input type="text" name="q" placeholder="Search docs" />
              </form>
          </div>
        </dd>
      </dl>
      



      <hr />
      
        <small>
          <span>Hosted by <a href="https://readthedocs.org">Read the Docs</a></span>
          <span> · </span>
          <a href="https://docs.readthedocs.io/page/privacy-policy.html">Privacy Policy</a>
        </small>
      

      

</div>
</div>
  </div>



  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'1.3.3',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-2.0.3.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-migrate-1.2.1.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/underscore.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/doctools.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/readthedocs-doc-embed.js"></script>

  

  
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
 
<script type="text/javascript">
!function(){var analytics=window.analytics=window.analytics||[];if(!analytics.initialize)if(analytics.invoked)window.console&amp;&amp;console.error&amp;&amp;console.error("Segment snippet included twice.");else{analytics.invoked=!0;analytics.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","page","once","off","on"];analytics.factory=function(t){return function(){var e=Array.prototype.slice.call(arguments);e.unshift(t);analytics.push(e);return analytics}};for(var t=0;t&lt;analytics.methods.length;t++){var e=analytics.methods[t];analytics[e]=analytics.factory(e)}analytics.load=function(t){var e=document.createElement("script");e.type="text/javascript";e.async=!0;e.src=("https:"===document.location.protocol?"https://":"http://")+"cdn.segment.com/analytics.js/v1/"+t+"/analytics.min.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n)};analytics.SNIPPET_VERSION="3.1.0";
analytics.load("8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA");
analytics.page();
}}();

analytics.ready(function () {
    ga('require', 'linker');
    ga('linker:autoLink', ['scrapinghub.com', 'crawlera.com']);
});
</script>



<div id="rtd-wxu46iyy"></div></body></html>