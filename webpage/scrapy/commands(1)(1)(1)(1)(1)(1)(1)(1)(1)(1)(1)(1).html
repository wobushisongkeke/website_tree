<!DOCTYPE html><!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]--><!--[if gt IE 8]><!--><html xmlns="http://www.w3.org/1999/xhtml" class=" js flexbox canvas canvastext webgl no-touch geolocation postmessage websqldatabase indexeddb hashchange history draganddrop websockets rgba hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients cssreflections csstransforms csstransforms3d csstransitions fontface generatedcontent video audio localstorage sessionstorage webworkers applicationcache svg inlinesvg smil svgclippaths" lang="en" style=""><!--<![endif]--><head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Command line tool — Scrapy 1.6.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Spiders" href="spiders.html" />
    <link rel="prev" title="Examples" href="../intro/examples.html" /> 

  
  <script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script type="text/javascript" async="" src="https://www.google-analytics.com/plugins/ua/linkid.js"></script><script type="text/javascript" async="" src="https://cdn.segment.com/analytics.js/v1/8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA/analytics.min.js"></script><script async="" src="https://www.google-analytics.com/analytics.js"></script><script src="../_static/js/modernizr.min.js"></script>


<!-- RTD Extra Head -->

<!-- 
Always link to the latest version, as canonical.
http://docs.readthedocs.org/en/latest/canonical.html
-->
<link rel="canonical" href="http://doc.scrapy.org/en/latest/topics/commands.html" />

<link rel="stylesheet" href="https://assets.readthedocs.org/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="text/javascript" src="../_static/readthedocs-data.js"></script>

<!-- Add page-specific data, which must exist in the page js, not global -->
<script type="text/javascript">
READTHEDOCS_DATA['page'] = 'topics/commands'
READTHEDOCS_DATA['source_suffix'] = '.rst'
</script>

<script type="text/javascript" src="https://assets.readthedocs.org/static/javascript/readthedocs-analytics.js"></script>

<!-- end RTD <extrahead> -->
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Scrapy
          

          
          </a>

          
            
            
            
              <div class="version">
                stable
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">First steps</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/overview.html">Scrapy at a glance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/install.html">Installation guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/tutorial.html">Scrapy Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/examples.html">Examples</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic concepts</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal current" href="#"><span class="toctree-expand"></span>Command line tool</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#configuration-settings">Configuration settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="#default-structure-of-scrapy-projects">Default structure of Scrapy projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sharing-the-root-directory-between-projects">Sharing the root directory between projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-the-scrapy-tool"><span class="toctree-expand"></span>Using the <code class="docutils literal notranslate"><span class="pre">scrapy</span></code> tool</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#creating-projects">Creating projects</a></li>
<li class="toctree-l3"><a class="reference internal" href="#controlling-projects">Controlling projects</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#available-tool-commands"><span class="toctree-expand"></span>Available tool commands</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#startproject">startproject</a></li>
<li class="toctree-l3"><a class="reference internal" href="#genspider">genspider</a></li>
<li class="toctree-l3"><a class="reference internal" href="#crawl">crawl</a></li>
<li class="toctree-l3"><a class="reference internal" href="#check">check</a></li>
<li class="toctree-l3"><a class="reference internal" href="#list">list</a></li>
<li class="toctree-l3"><a class="reference internal" href="#edit">edit</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fetch">fetch</a></li>
<li class="toctree-l3"><a class="reference internal" href="#view">view</a></li>
<li class="toctree-l3"><a class="reference internal" href="#shell">shell</a></li>
<li class="toctree-l3"><a class="reference internal" href="#parse">parse</a></li>
<li class="toctree-l3"><a class="reference internal" href="#settings">settings</a></li>
<li class="toctree-l3"><a class="reference internal" href="#runspider">runspider</a></li>
<li class="toctree-l3"><a class="reference internal" href="#version">version</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bench">bench</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#custom-project-commands"><span class="toctree-expand"></span>Custom project commands</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#commands-module">COMMANDS_MODULE</a></li>
<li class="toctree-l3"><a class="reference internal" href="#register-commands-via-setup-py-entry-points">Register commands via setup.py entry points</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="spiders.html">Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="selectors.html">Selectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="items.html">Items</a></li>
<li class="toctree-l1"><a class="reference internal" href="loaders.html">Item Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="shell.html">Scrapy shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="item-pipeline.html">Item Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="feed-exports.html">Feed exports</a></li>
<li class="toctree-l1"><a class="reference internal" href="request-response.html">Requests and Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="link-extractors.html">Link Extractors</a></li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">Exceptions</a></li>
</ul>
<p class="caption"><span class="caption-text">Built-in services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="stats.html">Stats Collection</a></li>
<li class="toctree-l1"><a class="reference internal" href="email.html">Sending e-mail</a></li>
<li class="toctree-l1"><a class="reference internal" href="telnetconsole.html">Telnet Console</a></li>
<li class="toctree-l1"><a class="reference internal" href="webservice.html">Web Service</a></li>
</ul>
<p class="caption"><span class="caption-text">Solving specific problems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="debug.html">Debugging Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="contracts.html">Spiders Contracts</a></li>
<li class="toctree-l1"><a class="reference internal" href="practices.html">Common Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="broad-crawls.html">Broad Crawls</a></li>
<li class="toctree-l1"><a class="reference internal" href="developer-tools.html">Using your browser’s Developer Tools for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="leaks.html">Debugging memory leaks</a></li>
<li class="toctree-l1"><a class="reference internal" href="media-pipeline.html">Downloading and processing files and images</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy.html">Deploying Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="autothrottle.html">AutoThrottle extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="jobs.html">Jobs: pausing and resuming crawls</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending Scrapy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="downloader-middleware.html">Downloader Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="spider-middleware.html">Spider Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="extensions.html">Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">Core API</a></li>
<li class="toctree-l1"><a class="reference internal" href="signals.html">Signals</a></li>
<li class="toctree-l1"><a class="reference internal" href="exporters.html">Item Exporters</a></li>
</ul>
<p class="caption"><span class="caption-text">All the rest</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html">Versioning and API Stability</a></li>
</ul>

            
          
        </div>
      <div id="rtd-hx89yckz" class="ethical-rtd ethical-dark-theme"><div class="ethical-sidebar"><div class="ethical-content"><a href="https://readthedocs.org/sustainability/click/305/BedVvRX68riz/" rel="nofollow" target="_blank" class="ethical-image-link"><img src="https://assets.readthedocs.org/sustainability/readthedocs-logo-fs8.png" /></a><div class="ethical-text"><a href="https://readthedocs.org/sustainability/click/305/BedVvRX68riz/" rel="nofollow" target="_blank">Private repos and priority support<br />Try Read the Docs for Business Today!</a></div></div><div class="ethical-callout"><small><em><a href="https://readthedocs.org/sustainability/advertising/">Sponsored</a><span> · </span><a href="https://docs.readthedocs.io/en/latest/ethical-advertising.html">Ads served ethically</a></em></small></div></div></div></div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Scrapy</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> »</li>
        
      <li>Command line tool</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/scrapy/scrapy/blob/b8594353d03be5574f51766c35566b713584302b/docs/topics/commands.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr />
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="command-line-tool">
<span id="topics-commands"></span><h1>Command line tool<a class="headerlink" href="#command-line-tool" title="Permalink to this headline">¶</a></h1>
<div class="versionadded">
<p><span class="versionmodified">New in version 0.10.</span></p>
</div>
<p>Scrapy is controlled through the <code class="docutils literal notranslate"><span class="pre">scrapy</span></code> command-line tool, to be referred
here as the “Scrapy tool” to differentiate it from the sub-commands, which we
just call “commands” or “Scrapy commands”.</p>
<p>The Scrapy tool provides several commands, for multiple purposes, and each one
accepts a different set of arguments and options.</p>
<p>(The <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">deploy</span></code> command has been removed in 1.0 in favor of the
standalone <code class="docutils literal notranslate"><span class="pre">scrapyd-deploy</span></code>. See <a class="reference external" href="https://scrapyd.readthedocs.io/en/latest/deploy.html">Deploying your project</a>.)</p>
<div class="section" id="configuration-settings">
<span id="topics-config-settings"></span><h2>Configuration settings<a class="headerlink" href="#configuration-settings" title="Permalink to this headline">¶</a></h2>
<p>Scrapy will look for configuration parameters in ini-style <code class="docutils literal notranslate"><span class="pre">scrapy.cfg</span></code> files
in standard locations:</p>
<ol class="arabic simple">
<li><code class="docutils literal notranslate"><span class="pre">/etc/scrapy.cfg</span></code> or <code class="docutils literal notranslate"><span class="pre">c:\scrapy\scrapy.cfg</span></code> (system-wide),</li>
<li><code class="docutils literal notranslate"><span class="pre">~/.config/scrapy.cfg</span></code> (<code class="docutils literal notranslate"><span class="pre">$XDG_CONFIG_HOME</span></code>) and <code class="docutils literal notranslate"><span class="pre">~/.scrapy.cfg</span></code> (<code class="docutils literal notranslate"><span class="pre">$HOME</span></code>)
for global (user-wide) settings, and</li>
<li><code class="docutils literal notranslate"><span class="pre">scrapy.cfg</span></code> inside a scrapy project’s root (see next section).</li>
</ol>
<p>Settings from these files are merged in the listed order of preference:
user-defined values have higher priority than system-wide defaults
and project-wide settings will override all others, when defined.</p>
<p>Scrapy also understands, and can be configured through, a number of environment
variables. Currently these are:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">SCRAPY_SETTINGS_MODULE</span></code> (see <a class="reference internal" href="settings.html#topics-settings-module-envvar"><span class="std std-ref">Designating the settings</span></a>)</li>
<li><code class="docutils literal notranslate"><span class="pre">SCRAPY_PROJECT</span></code> (see <a class="reference internal" href="#topics-project-envvar"><span class="std std-ref">Sharing the root directory between projects</span></a>)</li>
<li><code class="docutils literal notranslate"><span class="pre">SCRAPY_PYTHON_SHELL</span></code> (see <a class="reference internal" href="shell.html#topics-shell"><span class="std std-ref">Scrapy shell</span></a>)</li>
</ul>
</div>
<div class="section" id="default-structure-of-scrapy-projects">
<span id="topics-project-structure"></span><h2>Default structure of Scrapy projects<a class="headerlink" href="#default-structure-of-scrapy-projects" title="Permalink to this headline">¶</a></h2>
<p>Before delving into the command-line tool and its sub-commands, let’s first
understand the directory structure of a Scrapy project.</p>
<p>Though it can be modified, all Scrapy projects have the same file
structure by default, similar to this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span><span class="o">.</span><span class="n">cfg</span>
<span class="n">myproject</span><span class="o">/</span>
    <span class="fm">__init__</span><span class="o">.</span><span class="n">py</span>
    <span class="n">items</span><span class="o">.</span><span class="n">py</span>
    <span class="n">middlewares</span><span class="o">.</span><span class="n">py</span>
    <span class="n">pipelines</span><span class="o">.</span><span class="n">py</span>
    <span class="n">settings</span><span class="o">.</span><span class="n">py</span>
    <span class="n">spiders</span><span class="o">/</span>
        <span class="fm">__init__</span><span class="o">.</span><span class="n">py</span>
        <span class="n">spider1</span><span class="o">.</span><span class="n">py</span>
        <span class="n">spider2</span><span class="o">.</span><span class="n">py</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>The directory where the <code class="docutils literal notranslate"><span class="pre">scrapy.cfg</span></code> file resides is known as the <em>project
root directory</em>. That file contains the name of the python module that defines
the project settings. Here is an example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">settings</span><span class="p">]</span>
<span class="n">default</span> <span class="o">=</span> <span class="n">myproject</span><span class="o">.</span><span class="n">settings</span>
</pre></div>
</div>
</div>
<div class="section" id="sharing-the-root-directory-between-projects">
<span id="topics-project-envvar"></span><h2>Sharing the root directory between projects<a class="headerlink" href="#sharing-the-root-directory-between-projects" title="Permalink to this headline">¶</a></h2>
<p>A project root directory, the one that contains the <code class="docutils literal notranslate"><span class="pre">scrapy.cfg</span></code>, may be
shared by multiple Scrapy projects, each with its own settings module.</p>
<p>In that case, you must define one or more aliases for those settings modules
under <code class="docutils literal notranslate"><span class="pre">[settings]</span></code> in your <code class="docutils literal notranslate"><span class="pre">scrapy.cfg</span></code> file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">settings</span><span class="p">]</span>
<span class="n">default</span> <span class="o">=</span> <span class="n">myproject1</span><span class="o">.</span><span class="n">settings</span>
<span class="n">project1</span> <span class="o">=</span> <span class="n">myproject1</span><span class="o">.</span><span class="n">settings</span>
<span class="n">project2</span> <span class="o">=</span> <span class="n">myproject2</span><span class="o">.</span><span class="n">settings</span>
</pre></div>
</div>
<p>By default, the <code class="docutils literal notranslate"><span class="pre">scrapy</span></code> command-line tool will use the <code class="docutils literal notranslate"><span class="pre">default</span></code> settings.
Use the <code class="docutils literal notranslate"><span class="pre">SCRAPY_PROJECT</span></code> environment variable to specify a different project
for <code class="docutils literal notranslate"><span class="pre">scrapy</span></code> to use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scrapy settings --get BOT_NAME
Project 1 Bot
$ export SCRAPY_PROJECT=project2
$ scrapy settings --get BOT_NAME
Project 2 Bot
</pre></div>
</div>
</div>
<div class="section" id="using-the-scrapy-tool">
<h2>Using the <code class="docutils literal notranslate"><span class="pre">scrapy</span></code> tool<a class="headerlink" href="#using-the-scrapy-tool" title="Permalink to this headline">¶</a></h2>
<p>You can start by running the Scrapy tool with no arguments and it will print
some usage help and the available commands:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Scrapy</span> <span class="n">X</span><span class="o">.</span><span class="n">Y</span> <span class="o">-</span> <span class="n">no</span> <span class="n">active</span> <span class="n">project</span>

<span class="n">Usage</span><span class="p">:</span>
  <span class="n">scrapy</span> <span class="o">&lt;</span><span class="n">command</span><span class="o">&gt;</span> <span class="p">[</span><span class="n">options</span><span class="p">]</span> <span class="p">[</span><span class="n">args</span><span class="p">]</span>

<span class="n">Available</span> <span class="n">commands</span><span class="p">:</span>
  <span class="n">crawl</span>         <span class="n">Run</span> <span class="n">a</span> <span class="n">spider</span>
  <span class="n">fetch</span>         <span class="n">Fetch</span> <span class="n">a</span> <span class="n">URL</span> <span class="n">using</span> <span class="n">the</span> <span class="n">Scrapy</span> <span class="n">downloader</span>
<span class="p">[</span><span class="o">...</span><span class="p">]</span>
</pre></div>
</div>
<p>The first line will print the currently active project if you’re inside a
Scrapy project. In this example it was run from outside a project. If run from inside
a project it would have printed something like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Scrapy</span> <span class="n">X</span><span class="o">.</span><span class="n">Y</span> <span class="o">-</span> <span class="n">project</span><span class="p">:</span> <span class="n">myproject</span>

<span class="n">Usage</span><span class="p">:</span>
  <span class="n">scrapy</span> <span class="o">&lt;</span><span class="n">command</span><span class="o">&gt;</span> <span class="p">[</span><span class="n">options</span><span class="p">]</span> <span class="p">[</span><span class="n">args</span><span class="p">]</span>

<span class="p">[</span><span class="o">...</span><span class="p">]</span>
</pre></div>
</div>
<div class="section" id="creating-projects">
<h3>Creating projects<a class="headerlink" href="#creating-projects" title="Permalink to this headline">¶</a></h3>
<p>The first thing you typically do with the <code class="docutils literal notranslate"><span class="pre">scrapy</span></code> tool is create your Scrapy
project:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">startproject</span> <span class="n">myproject</span> <span class="p">[</span><span class="n">project_dir</span><span class="p">]</span>
</pre></div>
</div>
<p>That will create a Scrapy project under the <code class="docutils literal notranslate"><span class="pre">project_dir</span></code> directory.
If <code class="docutils literal notranslate"><span class="pre">project_dir</span></code> wasn’t specified, <code class="docutils literal notranslate"><span class="pre">project_dir</span></code> will be the same as <code class="docutils literal notranslate"><span class="pre">myproject</span></code>.</p>
<p>Next, you go inside the new project directory:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">project_dir</span>
</pre></div>
</div>
<p>And you’re ready to use the <code class="docutils literal notranslate"><span class="pre">scrapy</span></code> command to manage and control your
project from there.</p>
</div>
<div class="section" id="controlling-projects">
<h3>Controlling projects<a class="headerlink" href="#controlling-projects" title="Permalink to this headline">¶</a></h3>
<p>You use the <code class="docutils literal notranslate"><span class="pre">scrapy</span></code> tool from inside your projects to control and manage
them.</p>
<p>For example, to create a new spider:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">genspider</span> <span class="n">mydomain</span> <span class="n">mydomain</span><span class="o">.</span><span class="n">com</span>
</pre></div>
</div>
<p>Some Scrapy commands (like <a class="reference internal" href="#std:command-crawl"><code class="xref std std-command docutils literal notranslate"><span class="pre">crawl</span></code></a>) must be run from inside a Scrapy
project. See the <a class="reference internal" href="#topics-commands-ref"><span class="std std-ref">commands reference</span></a> below for more
information on which commands must be run from inside projects, and which not.</p>
<p>Also keep in mind that some commands may have slightly different behaviours
when running them from inside projects. For example, the fetch command will use
spider-overridden behaviours (such as the <code class="docutils literal notranslate"><span class="pre">user_agent</span></code> attribute to override
the user-agent) if the url being fetched is associated with some specific
spider. This is intentional, as the <code class="docutils literal notranslate"><span class="pre">fetch</span></code> command is meant to be used to
check how spiders are downloading pages.</p>
</div>
</div>
<div class="section" id="available-tool-commands">
<span id="topics-commands-ref"></span><h2>Available tool commands<a class="headerlink" href="#available-tool-commands" title="Permalink to this headline">¶</a></h2>
<p>This section contains a list of the available built-in commands with a
description and some usage examples. Remember, you can always get more info
about each command by running:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="o">&lt;</span><span class="n">command</span><span class="o">&gt;</span> <span class="o">-</span><span class="n">h</span>
</pre></div>
</div>
<p>And you can see all available commands with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="o">-</span><span class="n">h</span>
</pre></div>
</div>
<p>There are two kinds of commands, those that only work from inside a Scrapy
project (Project-specific commands) and those that also work without an active
Scrapy project (Global commands), though they may behave slightly different
when running from inside a project (as they would use the project overridden
settings).</p>
<p>Global commands:</p>
<ul class="simple">
<li><a class="reference internal" href="#std:command-startproject"><code class="xref std std-command docutils literal notranslate"><span class="pre">startproject</span></code></a></li>
<li><a class="reference internal" href="#std:command-genspider"><code class="xref std std-command docutils literal notranslate"><span class="pre">genspider</span></code></a></li>
<li><a class="reference internal" href="#std:command-settings"><code class="xref std std-command docutils literal notranslate"><span class="pre">settings</span></code></a></li>
<li><a class="reference internal" href="#std:command-runspider"><code class="xref std std-command docutils literal notranslate"><span class="pre">runspider</span></code></a></li>
<li><a class="reference internal" href="#std:command-shell"><code class="xref std std-command docutils literal notranslate"><span class="pre">shell</span></code></a></li>
<li><a class="reference internal" href="#std:command-fetch"><code class="xref std std-command docutils literal notranslate"><span class="pre">fetch</span></code></a></li>
<li><a class="reference internal" href="#std:command-view"><code class="xref std std-command docutils literal notranslate"><span class="pre">view</span></code></a></li>
<li><a class="reference internal" href="#std:command-version"><code class="xref std std-command docutils literal notranslate"><span class="pre">version</span></code></a></li>
</ul>
<p>Project-only commands:</p>
<ul class="simple">
<li><a class="reference internal" href="#std:command-crawl"><code class="xref std std-command docutils literal notranslate"><span class="pre">crawl</span></code></a></li>
<li><a class="reference internal" href="#std:command-check"><code class="xref std std-command docutils literal notranslate"><span class="pre">check</span></code></a></li>
<li><a class="reference internal" href="#std:command-list"><code class="xref std std-command docutils literal notranslate"><span class="pre">list</span></code></a></li>
<li><a class="reference internal" href="#std:command-edit"><code class="xref std std-command docutils literal notranslate"><span class="pre">edit</span></code></a></li>
<li><a class="reference internal" href="#std:command-parse"><code class="xref std std-command docutils literal notranslate"><span class="pre">parse</span></code></a></li>
<li><a class="reference internal" href="#std:command-bench"><code class="xref std std-command docutils literal notranslate"><span class="pre">bench</span></code></a></li>
</ul>
<div class="section" id="startproject">
<span id="std:command-startproject"></span><h3>startproject<a class="headerlink" href="#startproject" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">startproject</span> <span class="pre">&lt;project_name&gt;</span> <span class="pre">[project_dir]</span></code></li>
<li>Requires project: <em>no</em></li>
</ul>
<p>Creates a new Scrapy project named <code class="docutils literal notranslate"><span class="pre">project_name</span></code>, under the <code class="docutils literal notranslate"><span class="pre">project_dir</span></code>
directory.
If <code class="docutils literal notranslate"><span class="pre">project_dir</span></code> wasn’t specified, <code class="docutils literal notranslate"><span class="pre">project_dir</span></code> will be the same as <code class="docutils literal notranslate"><span class="pre">project_name</span></code>.</p>
<p>Usage example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scrapy startproject myproject
</pre></div>
</div>
</div>
<div class="section" id="genspider">
<span id="std:command-genspider"></span><h3>genspider<a class="headerlink" href="#genspider" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">genspider</span> <span class="pre">[-t</span> <span class="pre">template]</span> <span class="pre">&lt;name&gt;</span> <span class="pre">&lt;domain&gt;</span></code></li>
<li>Requires project: <em>no</em></li>
</ul>
<p>Create a new spider in the current folder or in the current project’s <code class="docutils literal notranslate"><span class="pre">spiders</span></code> folder, if called from inside a project. The <code class="docutils literal notranslate"><span class="pre">&lt;name&gt;</span></code> parameter is set as the spider’s <code class="docutils literal notranslate"><span class="pre">name</span></code>, while <code class="docutils literal notranslate"><span class="pre">&lt;domain&gt;</span></code> is used to generate the <code class="docutils literal notranslate"><span class="pre">allowed_domains</span></code> and <code class="docutils literal notranslate"><span class="pre">start_urls</span></code> spider’s attributes.</p>
<p>Usage example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scrapy genspider -l
Available templates:
  basic
  crawl
  csvfeed
  xmlfeed

$ scrapy genspider example example.com
Created spider 'example' using template 'basic'

$ scrapy genspider -t crawl scrapyorg scrapy.org
Created spider 'scrapyorg' using template 'crawl'
</pre></div>
</div>
<p>This is just a convenience shortcut command for creating spiders based on
pre-defined templates, but certainly not the only way to create spiders. You
can just create the spider source code files yourself, instead of using this
command.</p>
</div>
<div class="section" id="crawl">
<span id="std:command-crawl"></span><h3>crawl<a class="headerlink" href="#crawl" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">crawl</span> <span class="pre">&lt;spider&gt;</span></code></li>
<li>Requires project: <em>yes</em></li>
</ul>
<p>Start crawling using a spider.</p>
<p>Usage examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scrapy crawl myspider
[ ... myspider starts crawling ... ]
</pre></div>
</div>
</div>
<div class="section" id="check">
<span id="std:command-check"></span><h3>check<a class="headerlink" href="#check" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">check</span> <span class="pre">[-l]</span> <span class="pre">&lt;spider&gt;</span></code></li>
<li>Requires project: <em>yes</em></li>
</ul>
<p>Run contract checks.</p>
<p>Usage examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scrapy check -l
first_spider
  * parse
  * parse_item
second_spider
  * parse
  * parse_item

$ scrapy check
[FAILED] first_spider:parse_item
&gt;&gt;&gt; 'RetailPricex' field is missing

[FAILED] first_spider:parse
&gt;&gt;&gt; Returned 92 requests, expected 0..4
</pre></div>
</div>
</div>
<div class="section" id="list">
<span id="std:command-list"></span><h3>list<a class="headerlink" href="#list" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">list</span></code></li>
<li>Requires project: <em>yes</em></li>
</ul>
<p>List all available spiders in the current project. The output is one spider per
line.</p>
<p>Usage example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scrapy list
spider1
spider2
</pre></div>
</div>
</div>
<div class="section" id="edit">
<span id="std:command-edit"></span><h3>edit<a class="headerlink" href="#edit" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">edit</span> <span class="pre">&lt;spider&gt;</span></code></li>
<li>Requires project: <em>yes</em></li>
</ul>
<p>Edit the given spider using the editor defined in the <code class="docutils literal notranslate"><span class="pre">EDITOR</span></code> environment
variable or (if unset) the <a class="reference internal" href="settings.html#std:setting-EDITOR"><code class="xref std std-setting docutils literal notranslate"><span class="pre">EDITOR</span></code></a> setting.</p>
<p>This command is provided only as a convenience shortcut for the most common
case, the developer is of course free to choose any tool or IDE to write and
debug spiders.</p>
<p>Usage example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scrapy edit spider1
</pre></div>
</div>
</div>
<div class="section" id="fetch">
<span id="std:command-fetch"></span><h3>fetch<a class="headerlink" href="#fetch" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">fetch</span> <span class="pre">&lt;url&gt;</span></code></li>
<li>Requires project: <em>no</em></li>
</ul>
<p>Downloads the given URL using the Scrapy downloader and writes the contents to
standard output.</p>
<p>The interesting thing about this command is that it fetches the page how the
spider would download it. For example, if the spider has a <code class="docutils literal notranslate"><span class="pre">USER_AGENT</span></code>
attribute which overrides the User Agent, it will use that one.</p>
<p>So this command can be used to “see” how your spider would fetch a certain page.</p>
<p>If used outside a project, no particular per-spider behaviour would be applied
and it will just use the default Scrapy downloader settings.</p>
<p>Supported options:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">--spider=SPIDER</span></code>: bypass spider autodetection and force use of specific spider</li>
<li><code class="docutils literal notranslate"><span class="pre">--headers</span></code>: print the response’s HTTP headers instead of the response’s body</li>
<li><code class="docutils literal notranslate"><span class="pre">--no-redirect</span></code>: do not follow HTTP 3xx redirects (default is to follow them)</li>
</ul>
<p>Usage examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scrapy fetch --nolog http://www.example.com/some/page.html
[ ... html content here ... ]

$ scrapy fetch --nolog --headers http://www.example.com/
{'Accept-Ranges': ['bytes'],
 'Age': ['1263   '],
 'Connection': ['close     '],
 'Content-Length': ['596'],
 'Content-Type': ['text/html; charset=UTF-8'],
 'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'],
 'Etag': ['"573c1-254-48c9c87349680"'],
 'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'],
 'Server': ['Apache/2.2.3 (CentOS)']}
</pre></div>
</div>
</div>
<div class="section" id="view">
<span id="std:command-view"></span><h3>view<a class="headerlink" href="#view" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">view</span> <span class="pre">&lt;url&gt;</span></code></li>
<li>Requires project: <em>no</em></li>
</ul>
<p>Opens the given URL in a browser, as your Scrapy spider would “see” it.
Sometimes spiders see pages differently from regular users, so this can be used
to check what the spider “sees” and confirm it’s what you expect.</p>
<p>Supported options:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">--spider=SPIDER</span></code>: bypass spider autodetection and force use of specific spider</li>
<li><code class="docutils literal notranslate"><span class="pre">--no-redirect</span></code>: do not follow HTTP 3xx redirects (default is to follow them)</li>
</ul>
<p>Usage example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scrapy view http://www.example.com/some/page.html
[ ... browser starts ... ]
</pre></div>
</div>
</div>
<div class="section" id="shell">
<span id="std:command-shell"></span><h3>shell<a class="headerlink" href="#shell" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">shell</span> <span class="pre">[url]</span></code></li>
<li>Requires project: <em>no</em></li>
</ul>
<p>Starts the Scrapy shell for the given URL (if given) or empty if no URL is
given. Also supports UNIX-style local file paths, either relative with
<code class="docutils literal notranslate"><span class="pre">./</span></code> or <code class="docutils literal notranslate"><span class="pre">../</span></code> prefixes or absolute file paths.
See <a class="reference internal" href="shell.html#topics-shell"><span class="std std-ref">Scrapy shell</span></a> for more info.</p>
<p>Supported options:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">--spider=SPIDER</span></code>: bypass spider autodetection and force use of specific spider</li>
<li><code class="docutils literal notranslate"><span class="pre">-c</span> <span class="pre">code</span></code>: evaluate the code in the shell, print the result and exit</li>
<li><code class="docutils literal notranslate"><span class="pre">--no-redirect</span></code>: do not follow HTTP 3xx redirects (default is to follow them);
this only affects the URL you may pass as argument on the command line;
once you are inside the shell, <code class="docutils literal notranslate"><span class="pre">fetch(url)</span></code> will still follow HTTP redirects by default.</li>
</ul>
<p>Usage example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scrapy shell http://www.example.com/some/page.html
[ ... scrapy shell starts ... ]

$ scrapy shell --nolog http://www.example.com/ -c '(response.status, response.url)'
(200, 'http://www.example.com/')

# shell follows HTTP redirects by default
$ scrapy shell --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'
(200, 'http://example.com/')

# you can disable this with --no-redirect
# (only for the URL passed as command line argument)
$ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c '(response.status, response.url)'
(302, 'http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F')
</pre></div>
</div>
</div>
<div class="section" id="parse">
<span id="std:command-parse"></span><h3>parse<a class="headerlink" href="#parse" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">parse</span> <span class="pre">&lt;url&gt;</span> <span class="pre">[options]</span></code></li>
<li>Requires project: <em>yes</em></li>
</ul>
<p>Fetches the given URL and parses it with the spider that handles it, using the
method passed with the <code class="docutils literal notranslate"><span class="pre">--callback</span></code> option, or <code class="docutils literal notranslate"><span class="pre">parse</span></code> if not given.</p>
<p>Supported options:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">--spider=SPIDER</span></code>: bypass spider autodetection and force use of specific spider</li>
<li><code class="docutils literal notranslate"><span class="pre">--a</span> <span class="pre">NAME=VALUE</span></code>: set spider argument (may be repeated)</li>
<li><code class="docutils literal notranslate"><span class="pre">--callback</span></code> or <code class="docutils literal notranslate"><span class="pre">-c</span></code>: spider method to use as callback for parsing the
response</li>
<li><code class="docutils literal notranslate"><span class="pre">--meta</span></code> or <code class="docutils literal notranslate"><span class="pre">-m</span></code>: additional request meta that will be passed to the callback
request. This must be a valid json string. Example: –meta=’{“foo” : “bar”}’</li>
<li><code class="docutils literal notranslate"><span class="pre">--pipelines</span></code>: process items through pipelines</li>
<li><code class="docutils literal notranslate"><span class="pre">--rules</span></code> or <code class="docutils literal notranslate"><span class="pre">-r</span></code>: use <a class="reference internal" href="spiders.html#scrapy.spiders.CrawlSpider" title="scrapy.spiders.CrawlSpider"><code class="xref py py-class docutils literal notranslate"><span class="pre">CrawlSpider</span></code></a>
rules to discover the callback (i.e. spider method) to use for parsing the
response</li>
<li><code class="docutils literal notranslate"><span class="pre">--noitems</span></code>: don’t show scraped items</li>
<li><code class="docutils literal notranslate"><span class="pre">--nolinks</span></code>: don’t show extracted links</li>
<li><code class="docutils literal notranslate"><span class="pre">--nocolour</span></code>: avoid using pygments to colorize the output</li>
<li><code class="docutils literal notranslate"><span class="pre">--depth</span></code> or <code class="docutils literal notranslate"><span class="pre">-d</span></code>: depth level for which the requests should be followed
recursively (default: 1)</li>
<li><code class="docutils literal notranslate"><span class="pre">--verbose</span></code> or <code class="docutils literal notranslate"><span class="pre">-v</span></code>: display information for each depth level</li>
</ul>
<p>Usage example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scrapy parse http://www.example.com/ -c parse_item
[ ... scrapy log lines crawling example.com spider ... ]

&gt;&gt;&gt; STATUS DEPTH LEVEL 1 &lt;&lt;&lt;
# Scraped Items  ------------------------------------------------------------
[{'name': 'Example item',
 'category': 'Furniture',
 'length': '12 cm'}]

# Requests  -----------------------------------------------------------------
[]
</pre></div>
</div>
</div>
<div class="section" id="settings">
<span id="std:command-settings"></span><h3>settings<a class="headerlink" href="#settings" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">settings</span> <span class="pre">[options]</span></code></li>
<li>Requires project: <em>no</em></li>
</ul>
<p>Get the value of a Scrapy setting.</p>
<p>If used inside a project it’ll show the project setting value, otherwise it’ll
show the default Scrapy value for that setting.</p>
<p>Example usage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scrapy settings --get BOT_NAME
scrapybot
$ scrapy settings --get DOWNLOAD_DELAY
0
</pre></div>
</div>
</div>
<div class="section" id="runspider">
<span id="std:command-runspider"></span><h3>runspider<a class="headerlink" href="#runspider" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">runspider</span> <span class="pre">&lt;spider_file.py&gt;</span></code></li>
<li>Requires project: <em>no</em></li>
</ul>
<p>Run a spider self-contained in a Python file, without having to create a
project.</p>
<p>Example usage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ scrapy runspider myspider.py
[ ... spider starts crawling ... ]
</pre></div>
</div>
</div>
<div class="section" id="version">
<span id="std:command-version"></span><h3>version<a class="headerlink" href="#version" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">version</span> <span class="pre">[-v]</span></code></li>
<li>Requires project: <em>no</em></li>
</ul>
<p>Prints the Scrapy version. If used with <code class="docutils literal notranslate"><span class="pre">-v</span></code> it also prints Python, Twisted
and Platform info, which is useful for bug reports.</p>
</div>
<div class="section" id="bench">
<span id="std:command-bench"></span><h3>bench<a class="headerlink" href="#bench" title="Permalink to this headline">¶</a></h3>
<div class="versionadded">
<p><span class="versionmodified">New in version 0.17.</span></p>
</div>
<ul class="simple">
<li>Syntax: <code class="docutils literal notranslate"><span class="pre">scrapy</span> <span class="pre">bench</span></code></li>
<li>Requires project: <em>no</em></li>
</ul>
<p>Run a quick benchmark test. <a class="reference internal" href="benchmarking.html#benchmarking"><span class="std std-ref">Benchmarking</span></a>.</p>
</div>
</div>
<div class="section" id="custom-project-commands">
<h2>Custom project commands<a class="headerlink" href="#custom-project-commands" title="Permalink to this headline">¶</a></h2>
<p>You can also add your custom project commands by using the
<a class="reference internal" href="#std:setting-COMMANDS_MODULE"><code class="xref std std-setting docutils literal notranslate"><span class="pre">COMMANDS_MODULE</span></code></a> setting. See the Scrapy commands in
<a class="reference external" href="https://github.com/scrapy/scrapy/tree/master/scrapy/commands">scrapy/commands</a> for examples on how to implement your commands.</p>
<div class="section" id="commands-module">
<span id="std:setting-COMMANDS_MODULE"></span><h3>COMMANDS_MODULE<a class="headerlink" href="#commands-module" title="Permalink to this headline">¶</a></h3>
<p>Default: <code class="docutils literal notranslate"><span class="pre">''</span></code> (empty string)</p>
<p>A module to use for looking up custom Scrapy commands. This is used to add custom
commands for your Scrapy project.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">COMMANDS_MODULE</span> <span class="o">=</span> <span class="s1">'mybot.commands'</span>
</pre></div>
</div>
</div>
<div class="section" id="register-commands-via-setup-py-entry-points">
<h3>Register commands via setup.py entry points<a class="headerlink" href="#register-commands-via-setup-py-entry-points" title="Permalink to this headline">¶</a></h3>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This is an experimental feature, use with caution.</p>
</div>
<p>You can also add Scrapy commands from an external library by adding a
<code class="docutils literal notranslate"><span class="pre">scrapy.commands</span></code> section in the entry points of the library <code class="docutils literal notranslate"><span class="pre">setup.py</span></code>
file.</p>
<p>The following example adds <code class="docutils literal notranslate"><span class="pre">my_command</span></code> command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">setuptools</span> <span class="k">import</span> <span class="n">setup</span><span class="p">,</span> <span class="n">find_packages</span>

<span class="n">setup</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">'scrapy-mymodule'</span><span class="p">,</span>
  <span class="n">entry_points</span><span class="o">=</span><span class="p">{</span>
    <span class="s1">'scrapy.commands'</span><span class="p">:</span> <span class="p">[</span>
      <span class="s1">'my_command=my_scrapy_module.commands:MyCommand'</span><span class="p">,</span>
    <span class="p">],</span>
  <span class="p">},</span>
 <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="spiders.html" class="btn btn-neutral float-right" title="Spiders" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../intro/examples.html" class="btn btn-neutral" title="Examples" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr /><div><div id="rtd-049i4l51" class="ethical-rtd"></div></div>

  <div role="contentinfo">
    <p>
        © Copyright 2008–2018, Scrapy developers
      
        <span class="commit">
          Revision <code>b8594353</code>.
        </span>
      

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: stable
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Versions</dt>
        
          <dd><a href="/en/latest/">latest</a></dd>
        
          <dd><a href="/en/stable/">stable</a></dd>
        
          <dd><a href="/en/1.5/">1.5</a></dd>
        
          <dd><a href="/en/1.4/">1.4</a></dd>
        
          <dd><a href="/en/1.3/">1.3</a></dd>
        
          <dd><a href="/en/1.2/">1.2</a></dd>
        
          <dd><a href="/en/1.1/">1.1</a></dd>
        
          <dd><a href="/en/1.0/">1.0</a></dd>
        
          <dd><a href="/en/0.24/">0.24</a></dd>
        
          <dd><a href="/en/0.22/">0.22</a></dd>
        
          <dd><a href="/en/0.20/">0.20</a></dd>
        
          <dd><a href="/en/0.18/">0.18</a></dd>
        
          <dd><a href="/en/0.16/">0.16</a></dd>
        
          <dd><a href="/en/0.14/">0.14</a></dd>
        
          <dd><a href="/en/0.12/">0.12</a></dd>
        
          <dd><a href="/en/0.10.3/">0.10.3</a></dd>
        
          <dd><a href="/en/0.9/">0.9</a></dd>
        
          <dd><a href="/en/xpath-tutorial/">xpath-tutorial</a></dd>
        
          <dd><a href="/en/master/">master</a></dd>
        
      </dl>
      <dl>
        <dt>Downloads</dt>
        
          <dd><a href="//readthedocs.org/projects/scrapy/downloads/pdf/stable/">pdf</a></dd>
        
          <dd><a href="//readthedocs.org/projects/scrapy/downloads/htmlzip/stable/">htmlzip</a></dd>
        
          <dd><a href="//readthedocs.org/projects/scrapy/downloads/epub/stable/">epub</a></dd>
        
      </dl>
      <dl>
        <dt>On Read the Docs</dt>
          <dd>
            <a href="//readthedocs.org/projects/scrapy/?fromdocs=scrapy">Project Home</a>
          </dd>
          <dd>
            <a href="//readthedocs.org/builds/scrapy/?fromdocs=scrapy">Builds</a>
          </dd>
      </dl>
      <hr />
      Free document hosting provided by <a href="http://www.readthedocs.org">Read the Docs</a>.

    </div>
  </div>



  

    
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'../',
              VERSION:'1.6.0',
              LANGUAGE:'en',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="https://assets.readthedocs.org/static/javascript/readthedocs-doc-embed.js"></script>
    

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script type="text/javascript">
!function(){var analytics=window.analytics=window.analytics||[];if(!analytics.initialize)if(analytics.invoked)window.console&amp;&amp;console.error&amp;&amp;console.error("Segment snippet included twice.");else{analytics.invoked=!0;analytics.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","page","once","off","on"];analytics.factory=function(t){return function(){var e=Array.prototype.slice.call(arguments);e.unshift(t);analytics.push(e);return analytics}};for(var t=0;t&lt;analytics.methods.length;t++){var e=analytics.methods[t];analytics[e]=analytics.factory(e)}analytics.load=function(t){var e=document.createElement("script");e.type="text/javascript";e.async=!0;e.src=("https:"===document.location.protocol?"https://":"http://")+"cdn.segment.com/analytics.js/v1/"+t+"/analytics.min.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n)};analytics.SNIPPET_VERSION="3.1.0";
analytics.load("8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA");
analytics.page();
}}();

analytics.ready(function () {
    ga('require', 'linker');
    ga('linker:autoLink', ['scrapinghub.com', 'crawlera.com']);
});
</script>



<div id="rtd-98y9ac9c"></div></body></html>