<!DOCTYPE html><!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]--><!--[if gt IE 8]><!--><html xmlns="http://www.w3.org/1999/xhtml" class=" js flexbox canvas canvastext webgl no-touch geolocation postmessage websqldatabase indexeddb hashchange history draganddrop websockets rgba hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients cssreflections csstransforms csstransforms3d csstransitions fontface generatedcontent video audio localstorage sessionstorage webworkers applicationcache svg inlinesvg smil svgclippaths" lang="en" style=""><!--<![endif]--><head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Frequently Asked Questions — Scrapy 0.12.0 documentation</title>
  

  
  

  

  
  
    

  

  
  

  
    <link rel="stylesheet" href="https://media.readthedocs.org/css/sphinx_rtd_theme.css" type="text/css" />
  

  
    <link rel="top" title="Scrapy 0.12.0 documentation" href="index.html" />
        <link rel="next" title="Using Firefox for scraping" href="topics/firefox.html" />
        <link rel="prev" title="Web Service" href="topics/webservice.html" /> 

  
  <script type="text/javascript" async="" src="https://ssl.google-analytics.com/ga.js"></script><script src="_static/js/modernizr.min.js"></script>


<!-- RTD Extra Head -->

<!-- 
Always link to the latest version, as canonical.
http://docs.readthedocs.org/en/latest/canonical.html
-->
<link rel="canonical" href="http://doc.scrapy.org/en/latest/faq.html" />

<link rel="stylesheet" href="https://media.readthedocs.org/css/readthedocs-doc-embed.css" type="text/css" />

<script type="text/javascript" src="_static/readthedocs-data.js"></script>

<!-- Add page-specific data, which must exist in the page js, not global -->
<script type="text/javascript">
READTHEDOCS_DATA['page'] = 'faq'
</script>

<script type="text/javascript" src="_static/readthedocs-dynamic-include.js"></script>

<!-- end RTD <extrahead> --></head>

<body class="wy-body-for-nav" role="document" style="">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Scrapy
          

          
          </a>

          
            
            
            
              <div class="version">
                0.12
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="intro/overview.html">Scrapy at a glance</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro/install.html">Installation guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro/tutorial.html">Scrapy Tutorial</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="topics/commands.html">Command line tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/items.html">Items</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/spiders.html">Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/link-extractors.html">Link Extractors</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/selectors.html">XPath Selectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/loaders.html">Item Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/shell.html">Scrapy shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/item-pipeline.html">Item Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/feed-exports.html">Feed exports</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="topics/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/stats.html">Stats Collection</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/email.html">Sending e-mail</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/telnetconsole.html">Telnet Console</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/webservice.html">Web Service</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href=""><span class="toctree-expand"></span>Frequently Asked Questions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#how-does-scrapy-compare-to-beautifulsoul-or-lxml">How does Scrapy compare to BeautifulSoul or lxml?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-python-versions-does-scrapy-support">What Python versions does Scrapy support?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#does-scrapy-work-with-python-3-0">Does Scrapy work with Python 3.0?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#did-scrapy-steal-x-from-django">Did Scrapy “steal” X from Django?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#does-scrapy-work-with-http-proxies">Does Scrapy work with HTTP proxies?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-crashes-with-importerror-no-module-named-win32api">Scrapy crashes with: ImportError: No module named win32api</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-can-i-simulate-a-user-login-in-my-spider">How can I simulate a user login in my spider?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#can-i-crawl-in-breadth-first-order-instead-of-depth-first-order">Can I crawl in breadth-first order instead of depth-first order?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#my-scrapy-crawler-has-memory-leaks-what-can-i-do">My Scrapy crawler has memory leaks. What can I do?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#how-can-i-make-scrapy-consume-less-memory">How can I make Scrapy consume less memory?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#can-i-use-basic-http-authentication-in-my-spiders">Can I use Basic HTTP Authentication in my spiders?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#why-does-scrapy-download-pages-in-english-instead-of-my-native-language">Why does Scrapy download pages in English instead of my native language?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#where-can-i-find-some-example-code-using-scrapy">Where can I find some example code using Scrapy?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#can-i-run-a-spider-without-creating-a-project">Can I run a spider without creating a project?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#i-get-filtered-offsite-request-messages-how-can-i-fix-them">I get “Filtered offsite request” messages. How can I fix them?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-is-the-recommended-way-to-deploy-a-scrapy-crawler-in-production">What is the recommended way to deploy a Scrapy crawler in production?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#can-i-use-json-for-large-exports">Can I use JSON for large exports?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#can-i-return-twisted-deferreds-from-signal-handlers">Can I return (Twisted) deferreds from signal handlers?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-does-the-response-status-code-999-means">What does the response status code 999 means?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#can-i-call-pdb-set-trace-from-my-spiders-to-debug-them">Can I call <code class="docutils literal"><span class="pre">pdb.set_trace()</span></code> from my spiders to debug them?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#simplest-way-to-dump-all-my-scraped-items-into-a-json-csv-xml-file">Simplest way to dump all my scraped items into a JSON/CSV/XML file?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-s-this-huge-cryptic-viewstate-parameter-used-in-some-forms">What’s this huge cryptic <code class="docutils literal"><span class="pre">__VIEWSTATE</span></code> parameter used in some forms?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#what-s-the-best-way-to-parse-big-xml-csv-data-feeds">What’s the best way to parse big XML/CSV data feeds?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/firefox.html">Using Firefox for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/firebug.html">Using Firebug for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/leaks.html">Debugging memory leaks</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/images.html">Downloading Item Images</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/ubuntu.html">Ubuntu packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/scrapyd.html">Scrapy Service (scrapyd)</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="topics/architecture.html">Architecture overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/downloader-middleware.html">Downloader Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/spider-middleware.html">Spider Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/extensions.html">Extensions</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="topics/request-response.html">Requests and Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/settings.html">Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/signals.html">Signals</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/exceptions.html">Exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/exporters.html">Item Exporters</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing to Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="api-stability.html">Versioning and API Stability</a></li>
<li class="toctree-l1"><a class="reference internal" href="experimental/index.html">Experimental features</a></li>
</ul>

            
          
        </div>
      <div id="rtd-6iiffng3" class="ethical-rtd ethical-dark-theme"><div class="ethical-sidebar"><div class="ethical-content"><a href="https://readthedocs.org/sustainability/click/305/y988a2K3cuML/" rel="nofollow" target="_blank" class="ethical-image-link"><img src="https://assets.readthedocs.org/sustainability/readthedocs-logo-fs8.png" /></a><div class="ethical-text"><a href="https://readthedocs.org/sustainability/click/305/y988a2K3cuML/" rel="nofollow" target="_blank">Private repos and priority support<br />Try Read the Docs for Business Today!</a></div></div><div class="ethical-callout"><small><em><a href="https://readthedocs.org/sustainability/advertising/">Sponsored</a><span> · </span><a href="https://docs.readthedocs.io/en/latest/ethical-advertising.html">Ads served ethically</a></em></small></div></div></div></div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">Scrapy</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> »</li>
      
    <li>Frequently Asked Questions</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="https://github.com/scrapy/scrapy/blob/0.12/docs/faq.rst" class="fa fa-github"> Edit on GitHub</a>
          
        
      </li>
  </ul>
  <hr />
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="frequently-asked-questions">
<span id="faq"></span><h1>Frequently Asked Questions<a class="headerlink" href="#frequently-asked-questions" title="Permalink to this headline">¶</a></h1>
<div class="section" id="how-does-scrapy-compare-to-beautifulsoul-or-lxml">
<h2>How does Scrapy compare to BeautifulSoul or lxml?<a class="headerlink" href="#how-does-scrapy-compare-to-beautifulsoul-or-lxml" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a> and <a class="reference external" href="http://codespeak.net/lxml/">lxml</a> are libraries for parsing HTML and XML. Scrapy is
an application framework for writing web spiders that crawl web sites and
extract data from them.</p>
<p>Scrapy provides a built-in mechanism for extracting data (called
<a class="reference internal" href="topics/selectors.html#topics-selectors"><span>selectors</span></a>) but you can easily use <a class="reference external" href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a>
(or <a class="reference external" href="http://codespeak.net/lxml/">lxml</a>) instead, if you feel more comfortable working with them. After
all, they’re just parsing libraries which can be imported and used from any
Python code.</p>
<p>In other words, comparing <a class="reference external" href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a> (or <a class="reference external" href="http://codespeak.net/lxml/">lxml</a>) to Scrapy is like
comparing <a class="reference external" href="http://jinja.pocoo.org/2/">jinja2</a> to <a class="reference external" href="http://www.djangoproject.com">Django</a>.</p>
</div>
<div class="section" id="what-python-versions-does-scrapy-support">
<span id="faq-python-versions"></span><h2>What Python versions does Scrapy support?<a class="headerlink" href="#what-python-versions-does-scrapy-support" title="Permalink to this headline">¶</a></h2>
<p>Scrapy runs in Python 2.5, 2.6 and 2.7. But it’s recommended you use Python 2.6
or above, since the Python 2.5 standard library has a few bugs in their URL
handling libraries. Some of these Python 2.5 bugs not only affect Scrapy but
any user code, such as spiders. You can see a list of <a class="reference external" href="http://dev.scrapy.org/query?status=accepted&amp;status=assigned&amp;status=new&amp;status=reopened&amp;order=priority&amp;keywords=~py25-bug">Python 2.5 bugs that
affect Scrapy</a> in the issue tracker.</p>
</div>
<div class="section" id="does-scrapy-work-with-python-3-0">
<h2>Does Scrapy work with Python 3.0?<a class="headerlink" href="#does-scrapy-work-with-python-3-0" title="Permalink to this headline">¶</a></h2>
<p>No, and there are no plans to port Scrapy to Python 3.0 yet. At the moment,
Scrapy works with Python 2.5, 2.6 and 2.7.</p>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><a class="reference internal" href="#faq-python-versions"><span>What Python versions does Scrapy support?</span></a>.</p>
</div>
</div>
<div class="section" id="did-scrapy-steal-x-from-django">
<h2>Did Scrapy “steal” X from Django?<a class="headerlink" href="#did-scrapy-steal-x-from-django" title="Permalink to this headline">¶</a></h2>
<p>Probably, but we don’t like that word. We think <a class="reference external" href="http://www.djangoproject.com">Django</a> is a great open source
project and an example to follow, so we’ve used it as an inspiration for
Scrapy.</p>
<p>We believe that, if something is already done well, there’s no need to reinvent
it. This concept, besides being one of the foundations for open source and free
software, not only applies to software but also to documentation, procedures,
policies, etc. So, instead of going through each problem ourselves, we choose
to copy ideas from those projects that have already solved them properly, and
focus on the real problems we need to solve.</p>
<p>We’d be proud if Scrapy serves as an inspiration for other projects. Feel free
to steal from us!</p>
</div>
<div class="section" id="does-scrapy-work-with-http-proxies">
<h2>Does Scrapy work with HTTP proxies?<a class="headerlink" href="#does-scrapy-work-with-http-proxies" title="Permalink to this headline">¶</a></h2>
<p>Yes. Support for HTTP proxies is provided (since Scrapy 0.8) through the HTTP
Proxy downloader middleware. See
<a class="reference internal" href="topics/downloader-middleware.html#scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware" title="scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware"><code class="xref py py-class docutils literal"><span class="pre">HttpProxyMiddleware</span></code></a>.</p>
</div>
<div class="section" id="scrapy-crashes-with-importerror-no-module-named-win32api">
<h2>Scrapy crashes with: ImportError: No module named win32api<a class="headerlink" href="#scrapy-crashes-with-importerror-no-module-named-win32api" title="Permalink to this headline">¶</a></h2>
<p>You need to install <a class="reference external" href="http://sourceforge.net/projects/pywin32/">pywin32</a> because of <a class="reference external" href="http://twistedmatrix.com/trac/ticket/3707">this Twisted bug</a>.</p>
</div>
<div class="section" id="how-can-i-simulate-a-user-login-in-my-spider">
<h2>How can I simulate a user login in my spider?<a class="headerlink" href="#how-can-i-simulate-a-user-login-in-my-spider" title="Permalink to this headline">¶</a></h2>
<p>See <a class="reference internal" href="topics/request-response.html#topics-request-response-ref-request-userlogin"><span>Using FormRequest.from_response() to simulate a user login</span></a>.</p>
</div>
<div class="section" id="can-i-crawl-in-breadth-first-order-instead-of-depth-first-order">
<h2>Can I crawl in breadth-first order instead of depth-first order?<a class="headerlink" href="#can-i-crawl-in-breadth-first-order-instead-of-depth-first-order" title="Permalink to this headline">¶</a></h2>
<p>Yes, there’s a setting for that: <a class="reference internal" href="topics/settings.html#std:setting-SCHEDULER_ORDER"><code class="xref std std-setting docutils literal"><span class="pre">SCHEDULER_ORDER</span></code></a>.</p>
</div>
<div class="section" id="my-scrapy-crawler-has-memory-leaks-what-can-i-do">
<h2>My Scrapy crawler has memory leaks. What can I do?<a class="headerlink" href="#my-scrapy-crawler-has-memory-leaks-what-can-i-do" title="Permalink to this headline">¶</a></h2>
<p>See <a class="reference internal" href="topics/leaks.html#topics-leaks"><span>Debugging memory leaks</span></a>.</p>
<p>Also, Python has a builtin memory leak issue which is described in
<a class="reference internal" href="topics/leaks.html#topics-leaks-without-leaks"><span>Leaks without leaks</span></a>.</p>
</div>
<div class="section" id="how-can-i-make-scrapy-consume-less-memory">
<h2>How can I make Scrapy consume less memory?<a class="headerlink" href="#how-can-i-make-scrapy-consume-less-memory" title="Permalink to this headline">¶</a></h2>
<p>See previous question.</p>
</div>
<div class="section" id="can-i-use-basic-http-authentication-in-my-spiders">
<h2>Can I use Basic HTTP Authentication in my spiders?<a class="headerlink" href="#can-i-use-basic-http-authentication-in-my-spiders" title="Permalink to this headline">¶</a></h2>
<p>Yes, see <a class="reference internal" href="topics/downloader-middleware.html#scrapy.contrib.downloadermiddleware.httpauth.HttpAuthMiddleware" title="scrapy.contrib.downloadermiddleware.httpauth.HttpAuthMiddleware"><code class="xref py py-class docutils literal"><span class="pre">HttpAuthMiddleware</span></code></a>.</p>
</div>
<div class="section" id="why-does-scrapy-download-pages-in-english-instead-of-my-native-language">
<h2>Why does Scrapy download pages in English instead of my native language?<a class="headerlink" href="#why-does-scrapy-download-pages-in-english-instead-of-my-native-language" title="Permalink to this headline">¶</a></h2>
<p>Try changing the default <a class="reference external" href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.4">Accept-Language</a> request header by overriding the
<a class="reference internal" href="topics/settings.html#std:setting-DEFAULT_REQUEST_HEADERS"><code class="xref std std-setting docutils literal"><span class="pre">DEFAULT_REQUEST_HEADERS</span></code></a> setting.</p>
</div>
<div class="section" id="where-can-i-find-some-example-code-using-scrapy">
<h2>Where can I find some example code using Scrapy?<a class="headerlink" href="#where-can-i-find-some-example-code-using-scrapy" title="Permalink to this headline">¶</a></h2>
<p>Scrapy comes with a built-in, fully functional project to scrape the <a class="reference external" href="http://www.google.com/dirhp">Google
Directory</a>. You can find it in the <a class="reference external" href="http://dev.scrapy.org/browser/examples/googledir">examples/googledir</a> directory of the
Scrapy distribution.</p>
<p>Also, there’s a site for sharing code snippets (spiders, middlewares,
extensions) called <a class="reference external" href="http://snippets.scrapy.org/">Scrapy snippets</a>.</p>
<p>Finally, you can find some example code for performing not-so-trivial tasks in
the <a class="reference external" href="http://dev.scrapy.org/wiki/ScrapyRecipes">Scrapy Recipes</a> wiki page.</p>
</div>
<div class="section" id="can-i-run-a-spider-without-creating-a-project">
<h2>Can I run a spider without creating a project?<a class="headerlink" href="#can-i-run-a-spider-without-creating-a-project" title="Permalink to this headline">¶</a></h2>
<p>Yes. You can use the <a class="reference internal" href="topics/commands.html#std:command-runspider"><code class="xref std std-command docutils literal"><span class="pre">runspider</span></code></a> command. For example, if you have a
spider written in a <code class="docutils literal"><span class="pre">my_spider.py</span></code> file you can run it with:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>scrapy runspider my_spider.py
</pre></div>
</div>
<p>See <a class="reference internal" href="topics/commands.html#std:command-runspider"><code class="xref std std-command docutils literal"><span class="pre">runspider</span></code></a> command for more info.</p>
</div>
<div class="section" id="i-get-filtered-offsite-request-messages-how-can-i-fix-them">
<h2>I get “Filtered offsite request” messages. How can I fix them?<a class="headerlink" href="#i-get-filtered-offsite-request-messages-how-can-i-fix-them" title="Permalink to this headline">¶</a></h2>
<p>Those messages (logged with <code class="docutils literal"><span class="pre">DEBUG</span></code> level) don’t necessarily mean there is a
problem, so you may not need to fix them.</p>
<p>Those message are thrown by the Offsite Spider Middleware, which is a spider
middleware (enabled by default) whose purpose is to filter out requests to
domains outside the ones covered by the spider.</p>
<p>For more info see:
<a class="reference internal" href="topics/spider-middleware.html#scrapy.contrib.spidermiddleware.offsite.OffsiteMiddleware" title="scrapy.contrib.spidermiddleware.offsite.OffsiteMiddleware"><code class="xref py py-class docutils literal"><span class="pre">OffsiteMiddleware</span></code></a>.</p>
</div>
<div class="section" id="what-is-the-recommended-way-to-deploy-a-scrapy-crawler-in-production">
<h2>What is the recommended way to deploy a Scrapy crawler in production?<a class="headerlink" href="#what-is-the-recommended-way-to-deploy-a-scrapy-crawler-in-production" title="Permalink to this headline">¶</a></h2>
<p>See <a class="reference internal" href="topics/scrapyd.html#topics-scrapyd"><span>Scrapy Service (scrapyd)</span></a>.</p>
</div>
<div class="section" id="can-i-use-json-for-large-exports">
<h2>Can I use JSON for large exports?<a class="headerlink" href="#can-i-use-json-for-large-exports" title="Permalink to this headline">¶</a></h2>
<p>It’ll depend on how large your output is. See <a class="reference internal" href="topics/exporters.html#json-with-large-data"><span>this warning</span></a> in <a class="reference internal" href="topics/exporters.html#scrapy.contrib.exporter.JsonItemExporter" title="scrapy.contrib.exporter.JsonItemExporter"><code class="xref py py-class docutils literal"><span class="pre">JsonItemExporter</span></code></a>
documentation.</p>
</div>
<div class="section" id="can-i-return-twisted-deferreds-from-signal-handlers">
<h2>Can I return (Twisted) deferreds from signal handlers?<a class="headerlink" href="#can-i-return-twisted-deferreds-from-signal-handlers" title="Permalink to this headline">¶</a></h2>
<p>Some signals support returning deferreds from their handlers, others don’t. See
the <a class="reference internal" href="topics/signals.html#topics-signals-ref"><span>Built-in signals reference</span></a> to know which ones.</p>
</div>
<div class="section" id="what-does-the-response-status-code-999-means">
<h2>What does the response status code 999 means?<a class="headerlink" href="#what-does-the-response-status-code-999-means" title="Permalink to this headline">¶</a></h2>
<p>999 is a custom reponse status code used by Yahoo sites to throttle requests.
Try slowing down the crawling speed by using a download delay of <code class="docutils literal"><span class="pre">2</span></code> (or
higher) in your spider:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">CrawlSpider</span><span class="p">):</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s1">'myspider'</span>

    <span class="n">DOWNLOAD_DELAY</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="c1"># [ ... rest of the spider code ... ]</span>
</pre></div>
</div>
<p>Or by setting a global download delay in your project with the
<a class="reference internal" href="topics/settings.html#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_DELAY</span></code></a> setting.</p>
</div>
<div class="section" id="can-i-call-pdb-set-trace-from-my-spiders-to-debug-them">
<h2>Can I call <code class="docutils literal"><span class="pre">pdb.set_trace()</span></code> from my spiders to debug them?<a class="headerlink" href="#can-i-call-pdb-set-trace-from-my-spiders-to-debug-them" title="Permalink to this headline">¶</a></h2>
<p>Yes, but you can also use the Scrapy shell which allows you too quickly analyze
(and even modify) the response being processed by your spider, which is, quite
often, more useful than plain old <code class="docutils literal"><span class="pre">pdb.set_trace()</span></code>.</p>
<p>For more info see <a class="reference internal" href="topics/shell.html#topics-shell-inspect-response"><span>Invoking the shell from spiders to inspect responses</span></a>.</p>
</div>
<div class="section" id="simplest-way-to-dump-all-my-scraped-items-into-a-json-csv-xml-file">
<h2>Simplest way to dump all my scraped items into a JSON/CSV/XML file?<a class="headerlink" href="#simplest-way-to-dump-all-my-scraped-items-into-a-json-csv-xml-file" title="Permalink to this headline">¶</a></h2>
<p>To dump into a JSON file:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>scrapy crawl myspider --set FEED_URI=items.json --set FEED_FORMAT=json
</pre></div>
</div>
<p>To dump into a CSV file:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>scrapy crawl myspider --set FEED_URI=items.csv --set FEED_FORMAT=csv
</pre></div>
</div>
<p>To dump into a XML file:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span>scrapy crawl myspider --set FEED_URI=items.xml --set FEED_FORMAT=xml
</pre></div>
</div>
<p>For more information see <a class="reference internal" href="topics/feed-exports.html#topics-feed-exports"><span>Feed exports</span></a></p>
</div>
<div class="section" id="what-s-this-huge-cryptic-viewstate-parameter-used-in-some-forms">
<h2>What’s this huge cryptic <code class="docutils literal"><span class="pre">__VIEWSTATE</span></code> parameter used in some forms?<a class="headerlink" href="#what-s-this-huge-cryptic-viewstate-parameter-used-in-some-forms" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal"><span class="pre">__VIEWSTATE</span></code> parameter is used in sites built with ASP.NET/VB.NET. For
more info on how it works see <a class="reference external" href="http://search.cpan.org/~ecarroll/HTML-TreeBuilderX-ASP_NET-0.09/lib/HTML/TreeBuilderX/ASP_NET.pm">this page</a>. Also, here’s an <a class="reference external" href="http://github.com/AmbientLighter/rpn-fas/blob/master/fas/spiders/rnp.py">example spider</a>
which scrapes one of these sites.</p>
</div>
<div class="section" id="what-s-the-best-way-to-parse-big-xml-csv-data-feeds">
<h2>What’s the best way to parse big XML/CSV data feeds?<a class="headerlink" href="#what-s-the-best-way-to-parse-big-xml-csv-data-feeds" title="Permalink to this headline">¶</a></h2>
<p>Parsing big feeds with XPath selectors can be problematic since they need to
build the DOM of the entire feed in memory, and this can be quite slow and
consume a lot of memory.</p>
<p>In order to avoid parsing all the entire feed at once in memory, you can use
the functions <code class="docutils literal"><span class="pre">xmliter</span></code> and <code class="docutils literal"><span class="pre">csviter</span></code> from <code class="docutils literal"><span class="pre">scrapy.utils.iterators</span></code>
module. In fact, this is what the feed spiders (see <a class="reference internal" href="topics/spiders.html#topics-spiders"><span>Spiders</span></a>) use
under the cover.</p>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="topics/firefox.html" class="btn btn-neutral float-right" title="Using Firefox for scraping" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="topics/webservice.html" class="btn btn-neutral" title="Web Service" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr /><div><div id="rtd-u885j0uv" class="ethical-rtd"></div></div>

  <div role="contentinfo">
    <p>
        © Copyright 2008-2011, Insophia.
      
        <span class="commit">
          Revision <code>fac5e5ea</code>.
        </span>
      

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: 0.12
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Versions</dt>
        
          <dd><a href="/en/latest/">latest</a></dd>
        
          <dd><a href="/en/stable/">stable</a></dd>
        
          <dd><a href="/en/master/">master</a></dd>
        
          <dd><a href="/en/1.1/">1.1</a></dd>
        
          <dd><a href="/en/1.0/">1.0</a></dd>
        
          <dd><a href="/en/0.24/">0.24</a></dd>
        
          <dd><a href="/en/0.22/">0.22</a></dd>
        
          <dd><a href="/en/0.20/">0.20</a></dd>
        
          <dd><a href="/en/0.18/">0.18</a></dd>
        
          <dd><a href="/en/0.16/">0.16</a></dd>
        
          <dd><a href="/en/0.14/">0.14</a></dd>
        
          <dd><a href="/en/0.12/">0.12</a></dd>
        
          <dd><a href="/en/0.10.3/">0.10.3</a></dd>
        
          <dd><a href="/en/0.9/">0.9</a></dd>
        
      </dl>
      <dl>
        <dt>Downloads</dt>
        
          <dd><a href="//readthedocs.org/projects/scrapy/downloads/pdf/0.12/">pdf</a></dd>
        
      </dl>
      <dl>
        <dt>On Read the Docs</dt>
          <dd>
            <a href="//readthedocs.org/projects/scrapy/?fromdocs=scrapy">Project Home</a>
          </dd>
          <dd>
            <a href="//readthedocs.org/builds/scrapy/?fromdocs=scrapy">Builds</a>
          </dd>
      </dl>
      <hr />
      Free document hosting provided by <a href="http://www.readthedocs.org">Read the Docs</a>.

    </div>
  </div>



  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.12.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-2.0.3.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-migrate-1.2.1.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/underscore.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/doctools.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/readthedocs-doc-embed.js"></script>

  

  
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   


<div id="rtd-iylw5edw"></div></body></html>