<!DOCTYPE html><!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]--><!--[if gt IE 8]><!--><html xmlns="http://www.w3.org/1999/xhtml" class=" js flexbox canvas canvastext webgl no-touch geolocation postmessage websqldatabase indexeddb hashchange history draganddrop websockets rgba hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients cssreflections csstransforms csstransforms3d csstransitions fontface generatedcontent video audio localstorage sessionstorage webworkers applicationcache svg inlinesvg smil svgclippaths" lang="en" style=""><!--<![endif]--><head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Release notes — Scrapy 1.2.3 documentation</title>
  

  
  

  

  
  
    

  

  
  

  
    <link rel="stylesheet" href="https://media.readthedocs.org/css/sphinx_rtd_theme.css" type="text/css" />
  

  
        <link rel="index" title="Index" href="genindex.html" />
        <link rel="search" title="Search" href="search.html" />
    <link rel="top" title="Scrapy 1.2.3 documentation" href="index.html" />
        <link rel="next" title="Contributing to Scrapy" href="contributing.html" />
        <link rel="prev" title="Item Exporters" href="topics/exporters.html" /> 

  
  <script type="text/javascript" async="" src="https://www.google-analytics.com/plugins/ua/linkid.js"></script><script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script type="text/javascript" async="" src="https://cdn.segment.com/analytics.js/v1/8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA/analytics.min.js"></script><script type="text/javascript" async="" src="https://ssl.google-analytics.com/ga.js"></script><script src="_static/js/modernizr.min.js"></script>


<!-- RTD Extra Head -->

<!-- 
Always link to the latest version, as canonical.
http://docs.readthedocs.org/en/latest/canonical.html
-->
<link rel="canonical" href="http://doc.scrapy.org/en/latest/news.html" />

<link rel="stylesheet" href="https://media.readthedocs.org/css/readthedocs-doc-embed.css" type="text/css" />

<script type="text/javascript" src="_static/readthedocs-data.js"></script>

<!-- Add page-specific data, which must exist in the page js, not global -->
<script type="text/javascript">
READTHEDOCS_DATA['page'] = 'news' 		
READTHEDOCS_DATA['source_suffix'] = '.rst'
</script>

<script type="text/javascript" src="_static/readthedocs-dynamic-include.js"></script>

<!-- end RTD <extrahead> --></head>

<body class="wy-body-for-nav" role="document" style="">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Scrapy
          

          
          </a>

          
            
            
            
              <div class="version">
                1.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">First steps</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro/overview.html">Scrapy at a glance</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro/install.html">Installation guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro/tutorial.html">Scrapy Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro/examples.html">Examples</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="topics/commands.html">Command line tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/spiders.html">Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/selectors.html">Selectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/items.html">Items</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/loaders.html">Item Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/shell.html">Scrapy shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/item-pipeline.html">Item Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/feed-exports.html">Feed exports</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/request-response.html">Requests and Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/link-extractors.html">Link Extractors</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/settings.html">Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/exceptions.html">Exceptions</a></li>
</ul>
<p class="caption"><span class="caption-text">Built-in services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="topics/logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/stats.html">Stats Collection</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/email.html">Sending e-mail</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/telnetconsole.html">Telnet Console</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/webservice.html">Web Service</a></li>
</ul>
<p class="caption"><span class="caption-text">Solving specific problems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/debug.html">Debugging Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/contracts.html">Spiders Contracts</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/practices.html">Common Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/broad-crawls.html">Broad Crawls</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/firefox.html">Using Firefox for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/firebug.html">Using Firebug for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/leaks.html">Debugging memory leaks</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/media-pipeline.html">Downloading and processing files and images</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/deploy.html">Deploying Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/autothrottle.html">AutoThrottle extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/jobs.html">Jobs: pausing and resuming crawls</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending Scrapy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="topics/architecture.html">Architecture overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/downloader-middleware.html">Downloader Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/spider-middleware.html">Spider Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/extensions.html">Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/api.html">Core API</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/signals.html">Signals</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/exporters.html">Item Exporters</a></li>
</ul>
<p class="caption"><span class="caption-text">All the rest</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal current" href="#"><span class="toctree-expand"></span>Release notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-2-3-2017-03-03">Scrapy 1.2.3 (2017-03-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-2-2-2016-12-06"><span class="toctree-expand"></span>Scrapy 1.2.2 (2016-12-06)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#bug-fixes">Bug fixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#documentation">Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#other-changes">Other changes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-2-1-2016-10-21"><span class="toctree-expand"></span>Scrapy 1.2.1 (2016-10-21)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Bug fixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">Other changes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-2-0-2016-10-03"><span class="toctree-expand"></span>Scrapy 1.2.0 (2016-10-03)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#new-features">New Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">Bug fixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#refactoring">Refactoring</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tests-requirements">Tests &amp; Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id5">Documentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-1-4-2017-03-03">Scrapy 1.1.4 (2017-03-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-1-3-2016-09-22"><span class="toctree-expand"></span>Scrapy 1.1.3 (2016-09-22)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id6">Bug fixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">Documentation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-1-2-2016-08-18"><span class="toctree-expand"></span>Scrapy 1.1.2 (2016-08-18)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id8">Bug fixes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-1-1-2016-07-13"><span class="toctree-expand"></span>Scrapy 1.1.1 (2016-07-13)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id9">Bug fixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id10">New features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id11">Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tests">Tests</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-1-0-2016-05-11"><span class="toctree-expand"></span>Scrapy 1.1.0 (2016-05-11)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#beta-python-3-support">Beta Python 3 Support</a></li>
<li class="toctree-l3"><a class="reference internal" href="#additional-new-features-and-enhancements">Additional New Features and Enhancements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deprecations-and-removals">Deprecations and Removals</a></li>
<li class="toctree-l3"><a class="reference internal" href="#relocations">Relocations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bugfixes">Bugfixes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-0-7-2017-03-03">Scrapy 1.0.7 (2017-03-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-0-6-2016-05-04">Scrapy 1.0.6 (2016-05-04)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-0-5-2016-02-04">Scrapy 1.0.5 (2016-02-04)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-0-4-2015-12-30">Scrapy 1.0.4 (2015-12-30)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-0-3-2015-08-11">Scrapy 1.0.3 (2015-08-11)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-0-2-2015-08-06">Scrapy 1.0.2 (2015-08-06)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-0-1-2015-07-01">Scrapy 1.0.1 (2015-07-01)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-1-0-0-2015-06-19"><span class="toctree-expand"></span>Scrapy 1.0.0 (2015-06-19)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#support-for-returning-dictionaries-in-spiders">Support for returning dictionaries in spiders</a></li>
<li class="toctree-l3"><a class="reference internal" href="#per-spider-settings-gsoc-2014">Per-spider settings (GSoC 2014)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#python-logging">Python Logging</a></li>
<li class="toctree-l3"><a class="reference internal" href="#crawler-api-refactoring-gsoc-2014">Crawler API refactoring (GSoC 2014)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-relocations"><span class="toctree-expand"></span>Module Relocations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#full-list-of-relocations">Full list of relocations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#changelog">Changelog</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-24-6-2015-04-20">Scrapy 0.24.6 (2015-04-20)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-24-5-2015-02-25">Scrapy 0.24.5 (2015-02-25)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-24-4-2014-08-09">Scrapy 0.24.4 (2014-08-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-24-3-2014-08-09">Scrapy 0.24.3 (2014-08-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-24-2-2014-07-08">Scrapy 0.24.2 (2014-07-08)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-24-1-2014-06-27">Scrapy 0.24.1 (2014-06-27)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-24-0-2014-06-26"><span class="toctree-expand"></span>Scrapy 0.24.0 (2014-06-26)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#enhancements">Enhancements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id12">Bugfixes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-22-2-released-2014-02-14">Scrapy 0.22.2 (released 2014-02-14)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-22-1-released-2014-02-08">Scrapy 0.22.1 (released 2014-02-08)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-22-0-released-2014-01-17"><span class="toctree-expand"></span>Scrapy 0.22.0 (released 2014-01-17)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id13">Enhancements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fixes">Fixes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-20-2-released-2013-12-09">Scrapy 0.20.2 (released 2013-12-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-20-1-released-2013-11-28">Scrapy 0.20.1 (released 2013-11-28)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-20-0-released-2013-11-08"><span class="toctree-expand"></span>Scrapy 0.20.0 (released 2013-11-08)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id14">Enhancements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id15">Bugfixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#other">Other</a></li>
<li class="toctree-l3"><a class="reference internal" href="#thanks">Thanks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-18-4-released-2013-10-10">Scrapy 0.18.4 (released 2013-10-10)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-18-3-released-2013-10-03">Scrapy 0.18.3 (released 2013-10-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-18-2-released-2013-09-03">Scrapy 0.18.2 (released 2013-09-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-18-1-released-2013-08-27">Scrapy 0.18.1 (released 2013-08-27)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-18-0-released-2013-08-09">Scrapy 0.18.0 (released 2013-08-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-16-5-released-2013-05-30">Scrapy 0.16.5 (released 2013-05-30)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-16-4-released-2013-01-23">Scrapy 0.16.4 (released 2013-01-23)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-16-3-released-2012-12-07">Scrapy 0.16.3 (released 2012-12-07)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-16-2-released-2012-11-09">Scrapy 0.16.2 (released 2012-11-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-16-1-released-2012-10-26">Scrapy 0.16.1 (released 2012-10-26)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-16-0-released-2012-10-18">Scrapy 0.16.0 (released 2012-10-18)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-14-4">Scrapy 0.14.4</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-14-3">Scrapy 0.14.3</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-14-2">Scrapy 0.14.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-14-1">Scrapy 0.14.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-14"><span class="toctree-expand"></span>Scrapy 0.14</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#new-features-and-settings">New features and settings</a></li>
<li class="toctree-l3"><a class="reference internal" href="#code-rearranged-and-removed">Code rearranged and removed</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-12"><span class="toctree-expand"></span>Scrapy 0.12</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#new-features-and-improvements">New features and improvements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scrapyd-changes">Scrapyd changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#changes-to-settings">Changes to settings</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deprecated-obsoleted-functionality">Deprecated/obsoleted functionality</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-10"><span class="toctree-expand"></span>Scrapy 0.10</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id16">New features and improvements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#command-line-tool-changes">Command-line tool changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#api-changes">API changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id17">Changes to settings</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-9"><span class="toctree-expand"></span>Scrapy 0.9</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id18">New features and improvements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id19">API changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#changes-to-default-settings">Changes to default settings</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-8"><span class="toctree-expand"></span>Scrapy 0.8</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id20">New features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#backwards-incompatible-changes">Backwards-incompatible changes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scrapy-0-7">Scrapy 0.7</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing to Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="versioning.html">Versioning and API Stability</a></li>
</ul>

            
          
        </div>
      <div id="rtd-lpf61d5j" class="ethical-rtd ethical-dark-theme"><div class="ethical-sidebar"><div class="ethical-content"><a href="https://readthedocs.org/sustainability/click/305/F6Kpnra8Ya5R/" rel="nofollow" target="_blank" class="ethical-image-link"><img src="https://assets.readthedocs.org/sustainability/readthedocs-logo-fs8.png" /></a><div class="ethical-text"><a href="https://readthedocs.org/sustainability/click/305/F6Kpnra8Ya5R/" rel="nofollow" target="_blank">Private repos and priority support<br />Try Read the Docs for Business Today!</a></div></div><div class="ethical-callout"><small><em><a href="https://readthedocs.org/sustainability/advertising/">Sponsored</a><span> · </span><a href="https://docs.readthedocs.io/en/latest/ethical-advertising.html">Ads served ethically</a></em></small></div></div></div></div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Scrapy</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> »</li>
        
      <li>Release notes</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/scrapy/scrapy/blob/1.2/docs/news.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr />
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article"><div class="admonition warning"> <p class="first admonition-title">Note</p> <p class="last"> You are not reading the most recent version of this documentation. <a href="/en/1.6/news.html">1.6</a> is the latest version available.</p></div>
           <div itemprop="articleBody">
            
  <div class="section" id="release-notes">
<span id="news"></span><h1>Release notes<a class="headerlink" href="#release-notes" title="Permalink to this headline">¶</a></h1>
<div class="section" id="scrapy-1-2-3-2017-03-03">
<h2>Scrapy 1.2.3 (2017-03-03)<a class="headerlink" href="#scrapy-1-2-3-2017-03-03" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Packaging fix: disallow unsupported Twisted versions in setup.py</li>
</ul>
</div>
<div class="section" id="scrapy-1-2-2-2016-12-06">
<h2>Scrapy 1.2.2 (2016-12-06)<a class="headerlink" href="#scrapy-1-2-2-2016-12-06" title="Permalink to this headline">¶</a></h2>
<div class="section" id="bug-fixes">
<h3>Bug fixes<a class="headerlink" href="#bug-fixes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Fix a cryptic traceback when a pipeline fails on <code class="docutils literal"><span class="pre">open_spider()</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2011">issue 2011</a>)</li>
<li>Fix embedded IPython shell variables (fixing <a class="reference external" href="https://github.com/scrapy/scrapy/issues/396">issue 396</a> that re-appeared
in 1.2.0, fixed in <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2418">issue 2418</a>)</li>
<li>A couple of patches when dealing with robots.txt:<ul>
<li>handle (non-standard) relative sitemap URLs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2390">issue 2390</a>)</li>
<li>handle non-ASCII URLs and User-Agents in Python 2 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2373">issue 2373</a>)</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="documentation">
<h3>Documentation<a class="headerlink" href="#documentation" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Document <code class="docutils literal"><span class="pre">"download_latency"</span></code> key in <code class="docutils literal"><span class="pre">Request</span></code>‘s <code class="docutils literal"><span class="pre">meta</span></code> dict (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2033">issue 2033</a>)</li>
<li>Remove page on (deprecated &amp; unsupported) Ubuntu packages from ToC (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2335">issue 2335</a>)</li>
<li>A few fixed typos (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2346">issue 2346</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2369">issue 2369</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2369">issue 2369</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2380">issue 2380</a>)
and clarifications (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2354">issue 2354</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2325">issue 2325</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2414">issue 2414</a>)</li>
</ul>
</div>
<div class="section" id="other-changes">
<h3>Other changes<a class="headerlink" href="#other-changes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Advertize <a class="reference external" href="https://anaconda.org/conda-forge/scrapy">conda-forge</a> as Scrapy’s official conda channel (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2387">issue 2387</a>)</li>
<li>More helpful error messages when trying to use <code class="docutils literal"><span class="pre">.css()</span></code> or <code class="docutils literal"><span class="pre">.xpath()</span></code>
on non-Text Responses (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2264">issue 2264</a>)</li>
<li><code class="docutils literal"><span class="pre">startproject</span></code> command now generates a sample <code class="docutils literal"><span class="pre">middlewares.py</span></code> file (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2335">issue 2335</a>)</li>
<li>Add more dependencies’ version info in <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">version</span></code> verbose output (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2404">issue 2404</a>)</li>
<li>Remove all <code class="docutils literal"><span class="pre">*.pyc</span></code> files from source distribution (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2386">issue 2386</a>)</li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-2-1-2016-10-21">
<h2>Scrapy 1.2.1 (2016-10-21)<a class="headerlink" href="#scrapy-1-2-1-2016-10-21" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id1">
<h3>Bug fixes<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Include OpenSSL’s more permissive default ciphers when establishing
TLS/SSL connections (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2314">issue 2314</a>).</li>
<li>Fix “Location” HTTP header decoding on non-ASCII URL redirects (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2321">issue 2321</a>).</li>
</ul>
</div>
<div class="section" id="id2">
<h3>Documentation<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Fix JsonWriterPipeline example (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2302">issue 2302</a>).</li>
<li>Various notes: <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2330">issue 2330</a> on spider names,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2329">issue 2329</a> on middleware methods processing order,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2327">issue 2327</a> on getting multi-valued HTTP headers as lists.</li>
</ul>
</div>
<div class="section" id="id3">
<h3>Other changes<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Removed <code class="docutils literal"><span class="pre">www.</span></code> from <code class="docutils literal"><span class="pre">start_urls</span></code> in built-in spider templates (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2299">issue 2299</a>).</li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-2-0-2016-10-03">
<h2>Scrapy 1.2.0 (2016-10-03)<a class="headerlink" href="#scrapy-1-2-0-2016-10-03" title="Permalink to this headline">¶</a></h2>
<div class="section" id="new-features">
<h3>New Features<a class="headerlink" href="#new-features" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>New <a class="reference internal" href="topics/feed-exports.html#std:setting-FEED_EXPORT_ENCODING"><code class="xref std std-setting docutils literal"><span class="pre">FEED_EXPORT_ENCODING</span></code></a> setting to customize the encoding
used when writing items to a file.
This can be used to turn off <code class="docutils literal"><span class="pre">\uXXXX</span></code> escapes in JSON output.
This is also useful for those wanting something else than UTF-8
for XML or CSV output (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2034">issue 2034</a>).</li>
<li><code class="docutils literal"><span class="pre">startproject</span></code> command now supports an optional destination directory
to override the default one based on the project name (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2005">issue 2005</a>).</li>
<li>New <a class="reference internal" href="topics/settings.html#std:setting-SCHEDULER_DEBUG"><code class="xref std std-setting docutils literal"><span class="pre">SCHEDULER_DEBUG</span></code></a> setting to log requests serialization
failures (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1610">issue 1610</a>).</li>
<li>JSON encoder now supports serialization of <code class="docutils literal"><span class="pre">set</span></code> instances (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2058">issue 2058</a>).</li>
<li>Interpret <code class="docutils literal"><span class="pre">application/json-amazonui-streaming</span></code> as <code class="docutils literal"><span class="pre">TextResponse</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1503">issue 1503</a>).</li>
<li><code class="docutils literal"><span class="pre">scrapy</span></code> is imported by default when using shell tools (<a class="reference internal" href="topics/commands.html#std:command-shell"><code class="xref std std-command docutils literal"><span class="pre">shell</span></code></a>,
<a class="reference internal" href="topics/shell.html#topics-shell-inspect-response"><span class="std std-ref">inspect_response</span></a>) (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2248">issue 2248</a>).</li>
</ul>
</div>
<div class="section" id="id4">
<h3>Bug fixes<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>DefaultRequestHeaders middleware now runs before UserAgent middleware
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2088">issue 2088</a>). <strong>Warning: this is technically backwards incompatible</strong>,
though we consider this a bug fix.</li>
<li>HTTP cache extension and plugins that use the <code class="docutils literal"><span class="pre">.scrapy</span></code> data directory now
work outside projects (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1581">issue 1581</a>).  <strong>Warning: this is technically
backwards incompatible</strong>, though we consider this a bug fix.</li>
<li><code class="docutils literal"><span class="pre">Selector</span></code> does not allow passing both <code class="docutils literal"><span class="pre">response</span></code> and <code class="docutils literal"><span class="pre">text</span></code> anymore
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2153">issue 2153</a>).</li>
<li>Fixed logging of wrong callback name with <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">parse</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2169">issue 2169</a>).</li>
<li>Fix for an odd gzip decompression bug (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1606">issue 1606</a>).</li>
<li>Fix for selected callbacks when using <code class="docutils literal"><span class="pre">CrawlSpider</span></code> with <a class="reference internal" href="topics/commands.html#std:command-parse"><code class="xref std std-command docutils literal"><span class="pre">scrapy</span> <span class="pre">parse</span></code></a>
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2225">issue 2225</a>).</li>
<li>Fix for invalid JSON and XML files when spider yields no items (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/872">issue 872</a>).</li>
<li>Implement <code class="docutils literal"><span class="pre">flush()</span></code> fpr <code class="docutils literal"><span class="pre">StreamLogger</span></code> avoiding a warning in logs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2125">issue 2125</a>).</li>
</ul>
</div>
<div class="section" id="refactoring">
<h3>Refactoring<a class="headerlink" href="#refactoring" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">canonicalize_url</span></code> has been moved to <a class="reference external" href="http://w3lib.readthedocs.io/en/latest/w3lib.html#w3lib.url.canonicalize_url">w3lib.url</a> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2168">issue 2168</a>).</li>
</ul>
</div>
<div class="section" id="tests-requirements">
<h3>Tests &amp; Requirements<a class="headerlink" href="#tests-requirements" title="Permalink to this headline">¶</a></h3>
<p>Scrapy’s new requirements baseline is Debian 8 “Jessie”. It was previously
Ubuntu 12.04 Precise.
What this means in practice is that we run continuous integration tests
with these (main) packages versions at a minimum:
Twisted 14.0, pyOpenSSL 0.14, lxml 3.4.</p>
<p>Scrapy may very well work with older versions of these packages
(the code base still has switches for older Twisted versions for example)
but it is not guaranteed (because it’s not tested anymore).</p>
</div>
<div class="section" id="id5">
<h3>Documentation<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Grammar fixes: <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2128">issue 2128</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1566">issue 1566</a>.</li>
<li>Download stats badge removed from README (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2160">issue 2160</a>).</li>
<li>New scrapy <a class="reference internal" href="topics/architecture.html#topics-architecture"><span class="std std-ref">architecture diagram</span></a> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2165">issue 2165</a>).</li>
<li>Updated <code class="docutils literal"><span class="pre">Response</span></code> parameters documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2197">issue 2197</a>).</li>
<li>Reworded misleading <a class="reference internal" href="topics/settings.html#std:setting-RANDOMIZE_DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal"><span class="pre">RANDOMIZE_DOWNLOAD_DELAY</span></code></a> description (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2190">issue 2190</a>).</li>
<li>Add StackOverflow as a support channel (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2257">issue 2257</a>).</li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-1-4-2017-03-03">
<h2>Scrapy 1.1.4 (2017-03-03)<a class="headerlink" href="#scrapy-1-1-4-2017-03-03" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Packaging fix: disallow unsupported Twisted versions in setup.py</li>
</ul>
</div>
<div class="section" id="scrapy-1-1-3-2016-09-22">
<h2>Scrapy 1.1.3 (2016-09-22)<a class="headerlink" href="#scrapy-1-1-3-2016-09-22" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id6">
<h3>Bug fixes<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Class attributes for subclasses of <code class="docutils literal"><span class="pre">ImagesPipeline</span></code> and <code class="docutils literal"><span class="pre">FilesPipeline</span></code>
work as they did before 1.1.1 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2243">issue 2243</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2198">issue 2198</a>)</li>
</ul>
</div>
<div class="section" id="id7">
<h3>Documentation<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><a class="reference internal" href="intro/overview.html#intro-overview"><span class="std std-ref">Overview</span></a> and <a class="reference internal" href="intro/tutorial.html#intro-tutorial"><span class="std std-ref">tutorial</span></a>
rewritten to use <a class="reference external" href="http://toscrape.com">http://toscrape.com</a> websites
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2236">issue 2236</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2249">issue 2249</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2252">issue 2252</a>).</li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-1-2-2016-08-18">
<h2>Scrapy 1.1.2 (2016-08-18)<a class="headerlink" href="#scrapy-1-1-2-2016-08-18" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id8">
<h3>Bug fixes<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Introduce a missing <a class="reference internal" href="topics/media-pipeline.html#std:setting-IMAGES_STORE_S3_ACL"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_STORE_S3_ACL</span></code></a> setting to override
the default ACL policy in <code class="docutils literal"><span class="pre">ImagesPipeline</span></code> when uploading images to S3
(note that default ACL policy is “private” – instead of “public-read” –
since Scrapy 1.1.0)</li>
<li><a class="reference internal" href="topics/media-pipeline.html#std:setting-IMAGES_EXPIRES"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_EXPIRES</span></code></a> default value set back to 90
(the regression was introduced in 1.1.1)</li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-1-1-2016-07-13">
<h2>Scrapy 1.1.1 (2016-07-13)<a class="headerlink" href="#scrapy-1-1-1-2016-07-13" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id9">
<h3>Bug fixes<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Add “Host” header in CONNECT requests to HTTPS proxies (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2069">issue 2069</a>)</li>
<li>Use response <code class="docutils literal"><span class="pre">body</span></code> when choosing response class
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2001">issue 2001</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2000">issue 2000</a>)</li>
<li>Do not fail on canonicalizing URLs with wrong netlocs
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2038">issue 2038</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2010">issue 2010</a>)</li>
<li>a few fixes for <code class="docutils literal"><span class="pre">HttpCompressionMiddleware</span></code> (and <code class="docutils literal"><span class="pre">SitemapSpider</span></code>):<ul>
<li>Do not decode HEAD responses (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2008">issue 2008</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1899">issue 1899</a>)</li>
<li>Handle charset parameter in gzip Content-Type header
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2050">issue 2050</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2049">issue 2049</a>)</li>
<li>Do not decompress gzip octet-stream responses
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2065">issue 2065</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2063">issue 2063</a>)</li>
</ul>
</li>
<li>Catch (and ignore with a warning) exception when verifying certificate
against IP-address hosts (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2094">issue 2094</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2092">issue 2092</a>)</li>
<li>Make <code class="docutils literal"><span class="pre">FilesPipeline</span></code> and <code class="docutils literal"><span class="pre">ImagesPipeline</span></code> backward compatible again
regarding the use of legacy class attributes for customization
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1989">issue 1989</a>, fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1985">issue 1985</a>)</li>
</ul>
</div>
<div class="section" id="id10">
<h3>New features<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Enable genspider command outside project folder (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2052">issue 2052</a>)</li>
<li>Retry HTTPS CONNECT <code class="docutils literal"><span class="pre">TunnelError</span></code> by default (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1974">issue 1974</a>)</li>
</ul>
</div>
<div class="section" id="id11">
<h3>Documentation<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">FEED_TEMPDIR</span></code> setting at lexicographical position (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/9b3c72c">commit 9b3c72c</a>)</li>
<li>Use idiomatic <code class="docutils literal"><span class="pre">.extract_first()</span></code> in overview (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1994">issue 1994</a>)</li>
<li>Update years in copyright notice (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c2c8036">commit c2c8036</a>)</li>
<li>Add information and example on errbacks (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1995">issue 1995</a>)</li>
<li>Use “url” variable in downloader middleware example (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2015">issue 2015</a>)</li>
<li>Grammar fixes (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2054">issue 2054</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/2120">issue 2120</a>)</li>
<li>New FAQ entry on using BeautifulSoup in spider callbacks (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2048">issue 2048</a>)</li>
<li>Add notes about scrapy not working on Windows with Python 3 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2060">issue 2060</a>)</li>
<li>Encourage complete titles in pull requests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2026">issue 2026</a>)</li>
</ul>
</div>
<div class="section" id="tests">
<h3>Tests<a class="headerlink" href="#tests" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Upgrade py.test requirement on Travis CI and Pin pytest-cov to 2.2.1 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/2095">issue 2095</a>)</li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-1-0-2016-05-11">
<h2>Scrapy 1.1.0 (2016-05-11)<a class="headerlink" href="#scrapy-1-1-0-2016-05-11" title="Permalink to this headline">¶</a></h2>
<p>This 1.1 release brings a lot of interesting features and bug fixes:</p>
<ul class="simple">
<li>Scrapy 1.1 has beta Python 3 support (requires Twisted &gt;= 15.5). See
<a class="reference internal" href="#news-betapy3"><span class="std std-ref">Beta Python 3 Support</span></a> for more details and some limitations.</li>
<li>Hot new features:<ul>
<li>Item loaders now support nested loaders (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1467">issue 1467</a>).</li>
<li><code class="docutils literal"><span class="pre">FormRequest.from_response</span></code> improvements (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1382">issue 1382</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1137">issue 1137</a>).</li>
<li>Added setting <a class="reference internal" href="topics/autothrottle.html#std:setting-AUTOTHROTTLE_TARGET_CONCURRENCY"><code class="xref std std-setting docutils literal"><span class="pre">AUTOTHROTTLE_TARGET_CONCURRENCY</span></code></a> and improved
AutoThrottle docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1324">issue 1324</a>).</li>
<li>Added <code class="docutils literal"><span class="pre">response.text</span></code> to get body as unicode (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1730">issue 1730</a>).</li>
<li>Anonymous S3 connections (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1358">issue 1358</a>).</li>
<li>Deferreds in downloader middlewares (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1473">issue 1473</a>). This enables better
robots.txt handling (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1471">issue 1471</a>).</li>
<li>HTTP caching now follows RFC2616 more closely, added settings
<a class="reference internal" href="topics/downloader-middleware.html#std:setting-HTTPCACHE_ALWAYS_STORE"><code class="xref std std-setting docutils literal"><span class="pre">HTTPCACHE_ALWAYS_STORE</span></code></a> and
<a class="reference internal" href="topics/downloader-middleware.html#std:setting-HTTPCACHE_IGNORE_RESPONSE_CACHE_CONTROLS"><code class="xref std std-setting docutils literal"><span class="pre">HTTPCACHE_IGNORE_RESPONSE_CACHE_CONTROLS</span></code></a> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1151">issue 1151</a>).</li>
<li>Selectors were extracted to the <a class="reference external" href="https://github.com/scrapy/parsel">parsel</a> library (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1409">issue 1409</a>). This means
you can use Scrapy Selectors without Scrapy and also upgrade the
selectors engine without needing to upgrade Scrapy.</li>
<li>HTTPS downloader now does TLS protocol negotiation by default,
instead of forcing TLS 1.0. You can also set the SSL/TLS method
using the new <a class="reference internal" href="topics/settings.html#std:setting-DOWNLOADER_CLIENT_TLS_METHOD"><code class="xref std std-setting docutils literal"><span class="pre">DOWNLOADER_CLIENT_TLS_METHOD</span></code></a>.</li>
</ul>
</li>
<li>These bug fixes may require your attention:<ul>
<li>Don’t retry bad requests (HTTP 400) by default (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1289">issue 1289</a>).
If you need the old behavior, add <code class="docutils literal"><span class="pre">400</span></code> to <a class="reference internal" href="topics/downloader-middleware.html#std:setting-RETRY_HTTP_CODES"><code class="xref std std-setting docutils literal"><span class="pre">RETRY_HTTP_CODES</span></code></a>.</li>
<li>Fix shell files argument handling (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1710">issue 1710</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1550">issue 1550</a>).
If you try <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">shell</span> <span class="pre">index.html</span></code> it will try to load the URL <a class="reference external" href="http://index.html">http://index.html</a>,
use <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">shell</span> <span class="pre">./index.html</span></code> to load a local file.</li>
<li>Robots.txt compliance is now enabled by default for newly-created projects
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1724">issue 1724</a>). Scrapy will also wait for robots.txt to be downloaded
before proceeding with the crawl (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1735">issue 1735</a>). If you want to disable
this behavior, update <a class="reference internal" href="topics/settings.html#std:setting-ROBOTSTXT_OBEY"><code class="xref std std-setting docutils literal"><span class="pre">ROBOTSTXT_OBEY</span></code></a> in <code class="docutils literal"><span class="pre">settings.py</span></code> file
after creating a new project.</li>
<li>Exporters now work on unicode, instead of bytes by default (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1080">issue 1080</a>).
If you use <code class="docutils literal"><span class="pre">PythonItemExporter</span></code>, you may want to update your code to
disable binary mode which is now deprecated.</li>
<li>Accept XML node names containing dots as valid (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1533">issue 1533</a>).</li>
<li>When uploading files or images to S3 (with <code class="docutils literal"><span class="pre">FilesPipeline</span></code> or
<code class="docutils literal"><span class="pre">ImagesPipeline</span></code>), the default ACL policy is now “private” instead
of “public” <strong>Warning: backwards incompatible!</strong>.
You can use <a class="reference internal" href="topics/media-pipeline.html#std:setting-FILES_STORE_S3_ACL"><code class="xref std std-setting docutils literal"><span class="pre">FILES_STORE_S3_ACL</span></code></a> to change it.</li>
<li>We’ve reimplemented <code class="docutils literal"><span class="pre">canonicalize_url()</span></code> for more correct output,
especially for URLs with non-ASCII characters (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1947">issue 1947</a>).
This could change link extractors output compared to previous scrapy versions.
This may also invalidate some cache entries you could still have from pre-1.1 runs.
<strong>Warning: backwards incompatible!</strong>.</li>
</ul>
</li>
</ul>
<p>Keep reading for more details on other improvements and bug fixes.</p>
<div class="section" id="beta-python-3-support">
<span id="news-betapy3"></span><h3>Beta Python 3 Support<a class="headerlink" href="#beta-python-3-support" title="Permalink to this headline">¶</a></h3>
<p>We have been <a class="reference external" href="https://github.com/scrapy/scrapy/wiki/Python-3-Porting">hard at work to make Scrapy run on Python 3</a>. As a result, now
you can run spiders on Python 3.3, 3.4 and 3.5 (Twisted &gt;= 15.5 required). Some
features are still missing (and some may never be ported).</p>
<p>Almost all builtin extensions/middlewares are expected to work.
However, we are aware of some limitations in Python 3:</p>
<ul class="simple">
<li>Scrapy does not work on Windows with Python 3</li>
<li>Sending emails is not supported</li>
<li>FTP download handler is not supported</li>
<li>Telnet console is not supported</li>
</ul>
</div>
<div class="section" id="additional-new-features-and-enhancements">
<h3>Additional New Features and Enhancements<a class="headerlink" href="#additional-new-features-and-enhancements" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Scrapy now has a <a class="reference external" href="https://github.com/scrapy/scrapy/blob/master/CODE_OF_CONDUCT.md">Code of Conduct</a> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1681">issue 1681</a>).</li>
<li>Command line tool now has completion for zsh (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/934">issue 934</a>).</li>
<li>Improvements to <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">shell</span></code>:<ul>
<li>Support for bpython and configure preferred Python shell via
<code class="docutils literal"><span class="pre">SCRAPY_PYTHON_SHELL</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1100">issue 1100</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1444">issue 1444</a>).</li>
<li>Support URLs without scheme (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1498">issue 1498</a>)
<strong>Warning: backwards incompatible!</strong></li>
<li>Bring back support for relative file path (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1710">issue 1710</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1550">issue 1550</a>).</li>
</ul>
</li>
<li>Added <a class="reference internal" href="topics/settings.html#std:setting-MEMUSAGE_CHECK_INTERVAL_SECONDS"><code class="xref std std-setting docutils literal"><span class="pre">MEMUSAGE_CHECK_INTERVAL_SECONDS</span></code></a> setting to change default check
interval (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1282">issue 1282</a>).</li>
<li>Download handlers are now lazy-loaded on first request using their
scheme (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1390">issue 1390</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1421">issue 1421</a>).</li>
<li>HTTPS download handlers do not force TLS 1.0 anymore; instead,
OpenSSL’s <code class="docutils literal"><span class="pre">SSLv23_method()/TLS_method()</span></code> is used allowing to try
negotiating with the remote hosts the highest TLS protocol version
it can (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1794">issue 1794</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1629">issue 1629</a>).</li>
<li><code class="docutils literal"><span class="pre">RedirectMiddleware</span></code> now skips the status codes from
<code class="docutils literal"><span class="pre">handle_httpstatus_list</span></code> on spider attribute
or in <code class="docutils literal"><span class="pre">Request</span></code>‘s <code class="docutils literal"><span class="pre">meta</span></code> key (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1334">issue 1334</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1364">issue 1364</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1447">issue 1447</a>).</li>
<li>Form submission:<ul>
<li>now works with <code class="docutils literal"><span class="pre">&lt;button&gt;</span></code> elements too (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1469">issue 1469</a>).</li>
<li>an empty string is now used for submit buttons without a value
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1472">issue 1472</a>)</li>
</ul>
</li>
<li>Dict-like settings now have per-key priorities
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1135">issue 1135</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1149">issue 1149</a> and <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1586">issue 1586</a>).</li>
<li>Sending non-ASCII emails (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1662">issue 1662</a>)</li>
<li><code class="docutils literal"><span class="pre">CloseSpider</span></code> and <code class="docutils literal"><span class="pre">SpiderState</span></code> extensions now get disabled if no relevant
setting is set (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1723">issue 1723</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1725">issue 1725</a>).</li>
<li>Added method <code class="docutils literal"><span class="pre">ExecutionEngine.close</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1423">issue 1423</a>).</li>
<li>Added method <code class="docutils literal"><span class="pre">CrawlerRunner.create_crawler</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1528">issue 1528</a>).</li>
<li>Scheduler priority queue can now be customized via
<a class="reference internal" href="topics/settings.html#std:setting-SCHEDULER_PRIORITY_QUEUE"><code class="xref std std-setting docutils literal"><span class="pre">SCHEDULER_PRIORITY_QUEUE</span></code></a> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1822">issue 1822</a>).</li>
<li><code class="docutils literal"><span class="pre">.pps</span></code> links are now ignored by default in link extractors (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1835">issue 1835</a>).</li>
<li>temporary data folder for FTP and S3 feed storages can be customized
using a new <a class="reference internal" href="topics/settings.html#std:setting-FEED_TEMPDIR"><code class="xref std std-setting docutils literal"><span class="pre">FEED_TEMPDIR</span></code></a> setting (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1847">issue 1847</a>).</li>
<li><code class="docutils literal"><span class="pre">FilesPipeline</span></code> and <code class="docutils literal"><span class="pre">ImagesPipeline</span></code> settings are now instance attributes
instead of class attributes, enabling spider-specific behaviors (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1891">issue 1891</a>).</li>
<li><code class="docutils literal"><span class="pre">JsonItemExporter</span></code> now formats opening and closing square brackets
on their own line (first and last lines of output file) (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1950">issue 1950</a>).</li>
<li>If available, <code class="docutils literal"><span class="pre">botocore</span></code> is used for <code class="docutils literal"><span class="pre">S3FeedStorage</span></code>, <code class="docutils literal"><span class="pre">S3DownloadHandler</span></code>
and <code class="docutils literal"><span class="pre">S3FilesStore</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1761">issue 1761</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1883">issue 1883</a>).</li>
<li>Tons of documentation updates and related fixes (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1291">issue 1291</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1302">issue 1302</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1335">issue 1335</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1683">issue 1683</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1660">issue 1660</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1642">issue 1642</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1721">issue 1721</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1727">issue 1727</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1879">issue 1879</a>).</li>
<li>Other refactoring, optimizations and cleanup (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1476">issue 1476</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1481">issue 1481</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1477">issue 1477</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1315">issue 1315</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1290">issue 1290</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1750">issue 1750</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1881">issue 1881</a>).</li>
</ul>
</div>
<div class="section" id="deprecations-and-removals">
<h3>Deprecations and Removals<a class="headerlink" href="#deprecations-and-removals" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Added <code class="docutils literal"><span class="pre">to_bytes</span></code> and <code class="docutils literal"><span class="pre">to_unicode</span></code>, deprecated <code class="docutils literal"><span class="pre">str_to_unicode</span></code> and
<code class="docutils literal"><span class="pre">unicode_to_str</span></code> functions (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/778">issue 778</a>).</li>
<li><code class="docutils literal"><span class="pre">binary_is_text</span></code> is introduced, to replace use of <code class="docutils literal"><span class="pre">isbinarytext</span></code>
(but with inverse return value) (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1851">issue 1851</a>)</li>
<li>The <code class="docutils literal"><span class="pre">optional_features</span></code> set has been removed (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1359">issue 1359</a>).</li>
<li>The <code class="docutils literal"><span class="pre">--lsprof</span></code> command line option has been removed (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1689">issue 1689</a>).
<strong>Warning: backward incompatible</strong>, but doesn’t break user code.</li>
<li>The following datatypes were deprecated (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1720">issue 1720</a>):<ul>
<li><code class="docutils literal"><span class="pre">scrapy.utils.datatypes.MultiValueDictKeyError</span></code></li>
<li><code class="docutils literal"><span class="pre">scrapy.utils.datatypes.MultiValueDict</span></code></li>
<li><code class="docutils literal"><span class="pre">scrapy.utils.datatypes.SiteNode</span></code></li>
</ul>
</li>
<li>The previously bundled <code class="docutils literal"><span class="pre">scrapy.xlib.pydispatch</span></code> library was deprecated and
replaced by <a class="reference external" href="https://pypi.python.org/pypi/PyDispatcher">pydispatcher</a>.</li>
</ul>
</div>
<div class="section" id="relocations">
<h3>Relocations<a class="headerlink" href="#relocations" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">telnetconsole</span></code> was relocated to <code class="docutils literal"><span class="pre">extensions/</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1524">issue 1524</a>).<ul>
<li>Note: telnet is not enabled on Python 3
(<a class="reference external" href="https://github.com/scrapy/scrapy/pull/1524#issuecomment-146985595">https://github.com/scrapy/scrapy/pull/1524#issuecomment-146985595</a>)</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="bugfixes">
<h3>Bugfixes<a class="headerlink" href="#bugfixes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Scrapy does not retry requests that got a <code class="docutils literal"><span class="pre">HTTP</span> <span class="pre">400</span> <span class="pre">Bad</span> <span class="pre">Request</span></code>
response anymore (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1289">issue 1289</a>). <strong>Warning: backwards incompatible!</strong></li>
<li>Support empty password for http_proxy config (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1274">issue 1274</a>).</li>
<li>Interpret <code class="docutils literal"><span class="pre">application/x-json</span></code> as <code class="docutils literal"><span class="pre">TextResponse</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1333">issue 1333</a>).</li>
<li>Support link rel attribute with multiple values (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1201">issue 1201</a>).</li>
<li>Fixed <code class="docutils literal"><span class="pre">scrapy.http.FormRequest.from_response</span></code> when there is a <code class="docutils literal"><span class="pre">&lt;base&gt;</span></code>
tag (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1564">issue 1564</a>).</li>
<li>Fixed <a class="reference internal" href="topics/settings.html#std:setting-TEMPLATES_DIR"><code class="xref std std-setting docutils literal"><span class="pre">TEMPLATES_DIR</span></code></a> handling (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1575">issue 1575</a>).</li>
<li>Various <code class="docutils literal"><span class="pre">FormRequest</span></code> fixes (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1595">issue 1595</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1596">issue 1596</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1597">issue 1597</a>).</li>
<li>Makes <code class="docutils literal"><span class="pre">_monkeypatches</span></code> more robust (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1634">issue 1634</a>).</li>
<li>Fixed bug on <code class="docutils literal"><span class="pre">XMLItemExporter</span></code> with non-string fields in
items (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1738">issue 1738</a>).</li>
<li>Fixed startproject command in OS X (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1635">issue 1635</a>).</li>
<li>Fixed PythonItemExporter and CSVExporter for non-string item
types (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1737">issue 1737</a>).</li>
<li>Various logging related fixes (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1294">issue 1294</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1419">issue 1419</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1263">issue 1263</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1624">issue 1624</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1654">issue 1654</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1722">issue 1722</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1726">issue 1726</a> and <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1303">issue 1303</a>).</li>
<li>Fixed bug in <code class="docutils literal"><span class="pre">utils.template.render_templatefile()</span></code> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1212">issue 1212</a>).</li>
<li>sitemaps extraction from <code class="docutils literal"><span class="pre">robots.txt</span></code> is now case-insensitive (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1902">issue 1902</a>).</li>
<li>HTTPS+CONNECT tunnels could get mixed up when using multiple proxies
to same remote host (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1912">issue 1912</a>).</li>
</ul>
</div>
</div>
<div class="section" id="scrapy-1-0-7-2017-03-03">
<h2>Scrapy 1.0.7 (2017-03-03)<a class="headerlink" href="#scrapy-1-0-7-2017-03-03" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Packaging fix: disallow unsupported Twisted versions in setup.py</li>
</ul>
</div>
<div class="section" id="scrapy-1-0-6-2016-05-04">
<h2>Scrapy 1.0.6 (2016-05-04)<a class="headerlink" href="#scrapy-1-0-6-2016-05-04" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>FIX: RetryMiddleware is now robust to non-standard HTTP status codes (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1857">issue 1857</a>)</li>
<li>FIX: Filestorage HTTP cache was checking wrong modified time (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1875">issue 1875</a>)</li>
<li>DOC: Support for Sphinx 1.4+ (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1893">issue 1893</a>)</li>
<li>DOC: Consistency in selectors examples (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1869">issue 1869</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-1-0-5-2016-02-04">
<h2>Scrapy 1.0.5 (2016-02-04)<a class="headerlink" href="#scrapy-1-0-5-2016-02-04" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>FIX: [Backport] Ignore bogus links in LinkExtractors (fixes <a class="reference external" href="https://github.com/scrapy/scrapy/issues/907">issue 907</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/commit/108195e">commit 108195e</a>)</li>
<li>TST: Changed buildbot makefile to use ‘pytest’ (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1f3d90a">commit 1f3d90a</a>)</li>
<li>DOC: Fixed typos in tutorial and media-pipeline (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/808a9ea">commit 808a9ea</a> and <a class="reference external" href="https://github.com/scrapy/scrapy/commit/803bd87">commit 803bd87</a>)</li>
<li>DOC: Add AjaxCrawlMiddleware to DOWNLOADER_MIDDLEWARES_BASE in settings docs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/aa94121">commit aa94121</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-1-0-4-2015-12-30">
<h2>Scrapy 1.0.4 (2015-12-30)<a class="headerlink" href="#scrapy-1-0-4-2015-12-30" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Ignoring xlib/tx folder, depending on Twisted version. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7dfa979">commit 7dfa979</a>)</li>
<li>Run on new travis-ci infra (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6e42f0b">commit 6e42f0b</a>)</li>
<li>Spelling fixes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/823a1cc">commit 823a1cc</a>)</li>
<li>escape nodename in xmliter regex (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/da3c155">commit da3c155</a>)</li>
<li>test xml nodename with dots (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/4418fc3">commit 4418fc3</a>)</li>
<li>TST don’t use broken Pillow version in tests (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a55078c">commit a55078c</a>)</li>
<li>disable log on version command. closes #1426 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/86fc330">commit 86fc330</a>)</li>
<li>disable log on startproject command (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/db4c9fe">commit db4c9fe</a>)</li>
<li>Add PyPI download stats badge (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/df2b944">commit df2b944</a>)</li>
<li>don’t run tests twice on Travis if a PR is made from a scrapy/scrapy branch (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a83ab41">commit a83ab41</a>)</li>
<li>Add Python 3 porting status badge to the README (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/73ac80d">commit 73ac80d</a>)</li>
<li>fixed RFPDupeFilter persistence (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/97d080e">commit 97d080e</a>)</li>
<li>TST a test to show that dupefilter persistence is not working (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/97f2fb3">commit 97f2fb3</a>)</li>
<li>explicit close file on <a class="reference external" href="file://">file://</a> scheme handler (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d9b4850">commit d9b4850</a>)</li>
<li>Disable dupefilter in shell (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c0d0734">commit c0d0734</a>)</li>
<li>DOC: Add captions to toctrees which appear in sidebar (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/aa239ad">commit aa239ad</a>)</li>
<li>DOC Removed pywin32 from install instructions as it’s already declared as dependency. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/10eb400">commit 10eb400</a>)</li>
<li>Added installation notes about using Conda for Windows and other OSes. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1c3600a">commit 1c3600a</a>)</li>
<li>Fixed minor grammar issues. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7f4ddd5">commit 7f4ddd5</a>)</li>
<li>fixed a typo in the documentation. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b71f677">commit b71f677</a>)</li>
<li>Version 1 now exists (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5456c0e">commit 5456c0e</a>)</li>
<li>fix another invalid xpath error (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0a1366e">commit 0a1366e</a>)</li>
<li>fix ValueError: Invalid XPath: //div/[id=”not-exists”]/text() on selectors.rst (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ca8d60f">commit ca8d60f</a>)</li>
<li>Typos corrections (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7067117">commit 7067117</a>)</li>
<li>fix typos in downloader-middleware.rst and exceptions.rst, middlware -&gt; middleware (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/32f115c">commit 32f115c</a>)</li>
<li>Add note to ubuntu install section about debian compatibility (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/23fda69">commit 23fda69</a>)</li>
<li>Replace alternative OSX install workaround with virtualenv (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/98b63ee">commit 98b63ee</a>)</li>
<li>Reference Homebrew’s homepage for installation instructions (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1925db1">commit 1925db1</a>)</li>
<li>Add oldest supported tox version to contributing docs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5d10d6d">commit 5d10d6d</a>)</li>
<li>Note in install docs about pip being already included in python&gt;=2.7.9 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/85c980e">commit 85c980e</a>)</li>
<li>Add non-python dependencies to Ubuntu install section in the docs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fbd010d">commit fbd010d</a>)</li>
<li>Add OS X installation section to docs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d8f4cba">commit d8f4cba</a>)</li>
<li>DOC(ENH): specify path to rtd theme explicitly (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/de73b1a">commit de73b1a</a>)</li>
<li>minor: scrapy.Spider docs grammar (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1ddcc7b">commit 1ddcc7b</a>)</li>
<li>Make common practices sample code match the comments (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1b85bcf">commit 1b85bcf</a>)</li>
<li>nextcall repetitive calls (heartbeats). (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/55f7104">commit 55f7104</a>)</li>
<li>Backport fix compatibility with Twisted 15.4.0 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b262411">commit b262411</a>)</li>
<li>pin pytest to 2.7.3 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a6535c2">commit a6535c2</a>)</li>
<li>Merge pull request #1512 from mgedmin/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8876111">commit 8876111</a>)</li>
<li>Merge pull request #1513 from mgedmin/patch-2 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5d4daf8">commit 5d4daf8</a>)</li>
<li>Typo (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/f8d0682">commit f8d0682</a>)</li>
<li>Fix list formatting (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5f83a93">commit 5f83a93</a>)</li>
<li>fix scrapy squeue tests after recent changes to queuelib (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3365c01">commit 3365c01</a>)</li>
<li>Merge pull request #1475 from rweindl/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2d688cd">commit 2d688cd</a>)</li>
<li>Update tutorial.rst (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fbc1f25">commit fbc1f25</a>)</li>
<li>Merge pull request #1449 from rhoekman/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7d6538c">commit 7d6538c</a>)</li>
<li>Small grammatical change (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8752294">commit 8752294</a>)</li>
<li>Add openssl version to version command (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/13c45ac">commit 13c45ac</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-1-0-3-2015-08-11">
<h2>Scrapy 1.0.3 (2015-08-11)<a class="headerlink" href="#scrapy-1-0-3-2015-08-11" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>add service_identity to scrapy install_requires (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/cbc2501">commit cbc2501</a>)</li>
<li>Workaround for travis#296 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/66af9cd">commit 66af9cd</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-1-0-2-2015-08-06">
<h2>Scrapy 1.0.2 (2015-08-06)<a class="headerlink" href="#scrapy-1-0-2-2015-08-06" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Twisted 15.3.0 does not raises PicklingError serializing lambda functions (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b04dd7d">commit b04dd7d</a>)</li>
<li>Minor method name fix (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6f85c7f">commit 6f85c7f</a>)</li>
<li>minor: scrapy.Spider grammar and clarity (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/9c9d2e0">commit 9c9d2e0</a>)</li>
<li>Put a blurb about support channels in CONTRIBUTING (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c63882b">commit c63882b</a>)</li>
<li>Fixed typos (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a9ae7b0">commit a9ae7b0</a>)</li>
<li>Fix doc reference. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7c8a4fe">commit 7c8a4fe</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-1-0-1-2015-07-01">
<h2>Scrapy 1.0.1 (2015-07-01)<a class="headerlink" href="#scrapy-1-0-1-2015-07-01" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Unquote request path before passing to FTPClient, it already escape paths (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/cc00ad2">commit cc00ad2</a>)</li>
<li>include tests/ to source distribution in MANIFEST.in (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/eca227e">commit eca227e</a>)</li>
<li>DOC Fix SelectJmes documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b8567bc">commit b8567bc</a>)</li>
<li>DOC Bring Ubuntu and Archlinux outside of Windows subsection (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/392233f">commit 392233f</a>)</li>
<li>DOC remove version suffix from ubuntu package (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5303c66">commit 5303c66</a>)</li>
<li>DOC Update release date for 1.0 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c89fa29">commit c89fa29</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-1-0-0-2015-06-19">
<h2>Scrapy 1.0.0 (2015-06-19)<a class="headerlink" href="#scrapy-1-0-0-2015-06-19" title="Permalink to this headline">¶</a></h2>
<p>You will find a lot of new features and bugfixes in this major release.  Make
sure to check our updated <a class="reference internal" href="intro/overview.html#intro-overview"><span class="std std-ref">overview</span></a> to get a glance of
some of the changes, along with our brushed <a class="reference internal" href="intro/tutorial.html#intro-tutorial"><span class="std std-ref">tutorial</span></a>.</p>
<div class="section" id="support-for-returning-dictionaries-in-spiders">
<h3>Support for returning dictionaries in spiders<a class="headerlink" href="#support-for-returning-dictionaries-in-spiders" title="Permalink to this headline">¶</a></h3>
<p>Declaring and returning Scrapy Items is no longer necessary to collect the
scraped data from your spider, you can now return explicit dictionaries
instead.</p>
<p><em>Classic version</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
    <span class="n">url</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">MyItem</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>
</pre></div>
</div>
<p><em>New version</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">'url'</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="per-spider-settings-gsoc-2014">
<h3>Per-spider settings (GSoC 2014)<a class="headerlink" href="#per-spider-settings-gsoc-2014" title="Permalink to this headline">¶</a></h3>
<p>Last Google Summer of Code project accomplished an important redesign of the
mechanism used for populating settings, introducing explicit priorities to
override any given setting. As an extension of that goal, we included a new
level of priority for settings that act exclusively for a single spider,
allowing them to redefine project settings.</p>
<p>Start using it by defining a <a class="reference internal" href="topics/spiders.html#scrapy.spiders.Spider.custom_settings" title="scrapy.spiders.Spider.custom_settings"><code class="xref py py-attr docutils literal"><span class="pre">custom_settings</span></code></a>
class variable in your spider:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">custom_settings</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">"DOWNLOAD_DELAY"</span><span class="p">:</span> <span class="mf">5.0</span><span class="p">,</span>
        <span class="s2">"RETRY_ENABLED"</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">}</span>
</pre></div>
</div>
<p>Read more about settings population: <a class="reference internal" href="topics/settings.html#topics-settings"><span class="std std-ref">Settings</span></a></p>
</div>
<div class="section" id="python-logging">
<h3>Python Logging<a class="headerlink" href="#python-logging" title="Permalink to this headline">¶</a></h3>
<p>Scrapy 1.0 has moved away from Twisted logging to support Python built in’s
as default logging system. We’re maintaining backward compatibility for most
of the old custom interface to call logging functions, but you’ll get
warnings to switch to the Python logging API entirely.</p>
<p><em>Old version</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scrapy</span> <span class="k">import</span> <span class="n">log</span>
<span class="n">log</span><span class="o">.</span><span class="n">msg</span><span class="p">(</span><span class="s1">'MESSAGE'</span><span class="p">,</span> <span class="n">log</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
</pre></div>
</div>
<p><em>New version</em></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'MESSAGE'</span><span class="p">)</span>
</pre></div>
</div>
<p>Logging with spiders remains the same, but on top of the
<a class="reference internal" href="topics/spiders.html#scrapy.spiders.Spider.log" title="scrapy.spiders.Spider.log"><code class="xref py py-meth docutils literal"><span class="pre">log()</span></code></a> method you’ll have access to a custom
<a class="reference internal" href="topics/spiders.html#scrapy.spiders.Spider.logger" title="scrapy.spiders.Spider.logger"><code class="xref py py-attr docutils literal"><span class="pre">logger</span></code></a> created for the spider to issue log
events:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'Response received'</span><span class="p">)</span>
</pre></div>
</div>
<p>Read more in the logging documentation: <a class="reference internal" href="topics/logging.html#topics-logging"><span class="std std-ref">Logging</span></a></p>
</div>
<div class="section" id="crawler-api-refactoring-gsoc-2014">
<h3>Crawler API refactoring (GSoC 2014)<a class="headerlink" href="#crawler-api-refactoring-gsoc-2014" title="Permalink to this headline">¶</a></h3>
<p>Another milestone for last Google Summer of Code was a refactoring of the
internal API, seeking a simpler and easier usage. Check new core interface
in: <a class="reference internal" href="topics/api.html#topics-api"><span class="std std-ref">Core API</span></a></p>
<p>A common situation where you will face these changes is while running Scrapy
from scripts. Here’s a quick example of how to run a Spider manually with the
new API:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scrapy.crawler</span> <span class="k">import</span> <span class="n">CrawlerProcess</span>

<span class="n">process</span> <span class="o">=</span> <span class="n">CrawlerProcess</span><span class="p">({</span>
    <span class="s1">'USER_AGENT'</span><span class="p">:</span> <span class="s1">'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'</span>
<span class="p">})</span>
<span class="n">process</span><span class="o">.</span><span class="n">crawl</span><span class="p">(</span><span class="n">MySpider</span><span class="p">)</span>
<span class="n">process</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</pre></div>
</div>
<p>Bear in mind this feature is still under development and its API may change
until it reaches a stable status.</p>
<p>See more examples for scripts running Scrapy: <a class="reference internal" href="topics/practices.html#topics-practices"><span class="std std-ref">Common Practices</span></a></p>
</div>
<div class="section" id="module-relocations">
<h3>Module Relocations<a class="headerlink" href="#module-relocations" title="Permalink to this headline">¶</a></h3>
<p>There’s been a large rearrangement of modules trying to improve the general
structure of Scrapy. Main changes were separating various subpackages into
new projects and dissolving both <cite>scrapy.contrib</cite> and <cite>scrapy.contrib_exp</cite>
into top level packages. Backward compatibility was kept among internal
relocations, while importing deprecated modules expect warnings indicating
their new place.</p>
<div class="section" id="full-list-of-relocations">
<h4>Full list of relocations<a class="headerlink" href="#full-list-of-relocations" title="Permalink to this headline">¶</a></h4>
<p>Outsourced packages</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">These extensions went through some minor changes, e.g. some setting names
were changed. Please check the documentation in each new repository to
get familiar with the new usage.</p>
</div>
<div class="wy-table-responsive"><table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Old location</th>
<th class="head">New location</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>scrapy.commands.deploy</td>
<td><a class="reference external" href="https://github.com/scrapy/scrapyd-client">scrapyd-client</a>
(See other alternatives here:
<a class="reference internal" href="topics/deploy.html#topics-deploy"><span class="std std-ref">Deploying Spiders</span></a>)</td>
</tr>
<tr class="row-odd"><td>scrapy.contrib.djangoitem</td>
<td><a class="reference external" href="https://github.com/scrapy-plugins/scrapy-djangoitem">scrapy-djangoitem</a></td>
</tr>
<tr class="row-even"><td>scrapy.webservice</td>
<td><a class="reference external" href="https://github.com/scrapy-plugins/scrapy-jsonrpc">scrapy-jsonrpc</a></td>
</tr>
</tbody>
</table></div>
<p><cite>scrapy.contrib_exp</cite> and <cite>scrapy.contrib</cite> dissolutions</p>
<div class="wy-table-responsive"><table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Old location</th>
<th class="head">New location</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>scrapy.contrib_exp.downloadermiddleware.decompression</td>
<td>scrapy.downloadermiddlewares.decompression</td>
</tr>
<tr class="row-odd"><td>scrapy.contrib_exp.iterators</td>
<td>scrapy.utils.iterators</td>
</tr>
<tr class="row-even"><td>scrapy.contrib.downloadermiddleware</td>
<td>scrapy.downloadermiddlewares</td>
</tr>
<tr class="row-odd"><td>scrapy.contrib.exporter</td>
<td>scrapy.exporters</td>
</tr>
<tr class="row-even"><td>scrapy.contrib.linkextractors</td>
<td>scrapy.linkextractors</td>
</tr>
<tr class="row-odd"><td>scrapy.contrib.loader</td>
<td>scrapy.loader</td>
</tr>
<tr class="row-even"><td>scrapy.contrib.loader.processor</td>
<td>scrapy.loader.processors</td>
</tr>
<tr class="row-odd"><td>scrapy.contrib.pipeline</td>
<td>scrapy.pipelines</td>
</tr>
<tr class="row-even"><td>scrapy.contrib.spidermiddleware</td>
<td>scrapy.spidermiddlewares</td>
</tr>
<tr class="row-odd"><td>scrapy.contrib.spiders</td>
<td>scrapy.spiders</td>
</tr>
<tr class="row-even"><td><ul class="first last simple">
<li>scrapy.contrib.closespider</li>
<li>scrapy.contrib.corestats</li>
<li>scrapy.contrib.debug</li>
<li>scrapy.contrib.feedexport</li>
<li>scrapy.contrib.httpcache</li>
<li>scrapy.contrib.logstats</li>
<li>scrapy.contrib.memdebug</li>
<li>scrapy.contrib.memusage</li>
<li>scrapy.contrib.spiderstate</li>
<li>scrapy.contrib.statsmailer</li>
<li>scrapy.contrib.throttle</li>
</ul>
</td>
<td>scrapy.extensions.*</td>
</tr>
</tbody>
</table></div>
<p>Plural renames and Modules unification</p>
<div class="wy-table-responsive"><table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Old location</th>
<th class="head">New location</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>scrapy.command</td>
<td>scrapy.commands</td>
</tr>
<tr class="row-odd"><td>scrapy.dupefilter</td>
<td>scrapy.dupefilters</td>
</tr>
<tr class="row-even"><td>scrapy.linkextractor</td>
<td>scrapy.linkextractors</td>
</tr>
<tr class="row-odd"><td>scrapy.spider</td>
<td>scrapy.spiders</td>
</tr>
<tr class="row-even"><td>scrapy.squeue</td>
<td>scrapy.squeues</td>
</tr>
<tr class="row-odd"><td>scrapy.statscol</td>
<td>scrapy.statscollectors</td>
</tr>
<tr class="row-even"><td>scrapy.utils.decorator</td>
<td>scrapy.utils.decorators</td>
</tr>
</tbody>
</table></div>
<p>Class renames</p>
<div class="wy-table-responsive"><table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Old location</th>
<th class="head">New location</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>scrapy.spidermanager.SpiderManager</td>
<td>scrapy.spiderloader.SpiderLoader</td>
</tr>
</tbody>
</table></div>
<p>Settings renames</p>
<div class="wy-table-responsive"><table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Old location</th>
<th class="head">New location</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>SPIDER_MANAGER_CLASS</td>
<td>SPIDER_LOADER_CLASS</td>
</tr>
</tbody>
</table></div>
</div>
</div>
<div class="section" id="changelog">
<h3>Changelog<a class="headerlink" href="#changelog" title="Permalink to this headline">¶</a></h3>
<p>New Features and Enhancements</p>
<ul class="simple">
<li>Python logging (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1060">issue 1060</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1235">issue 1235</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1236">issue 1236</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1240">issue 1240</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1259">issue 1259</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1278">issue 1278</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1286">issue 1286</a>)</li>
<li>FEED_EXPORT_FIELDS option (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1159">issue 1159</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1224">issue 1224</a>)</li>
<li>Dns cache size and timeout options (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1132">issue 1132</a>)</li>
<li>support namespace prefix in xmliter_lxml (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/963">issue 963</a>)</li>
<li>Reactor threadpool max size setting (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1123">issue 1123</a>)</li>
<li>Allow spiders to return dicts. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1081">issue 1081</a>)</li>
<li>Add Response.urljoin() helper (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1086">issue 1086</a>)</li>
<li>look in ~/.config/scrapy.cfg for user config (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1098">issue 1098</a>)</li>
<li>handle TLS SNI (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1101">issue 1101</a>)</li>
<li>Selectorlist extract first (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/624">issue 624</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1145">issue 1145</a>)</li>
<li>Added JmesSelect (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1016">issue 1016</a>)</li>
<li>add gzip compression to filesystem http cache backend (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1020">issue 1020</a>)</li>
<li>CSS support in link extractors (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/983">issue 983</a>)</li>
<li>httpcache dont_cache meta #19 #689 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/821">issue 821</a>)</li>
<li>add signal to be sent when request is dropped by the scheduler
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/961">issue 961</a>)</li>
<li>avoid download large response (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/946">issue 946</a>)</li>
<li>Allow to specify the quotechar in CSVFeedSpider (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/882">issue 882</a>)</li>
<li>Add referer to “Spider error processing” log message (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/795">issue 795</a>)</li>
<li>process robots.txt once (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/896">issue 896</a>)</li>
<li>GSoC Per-spider settings (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/854">issue 854</a>)</li>
<li>Add project name validation (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/817">issue 817</a>)</li>
<li>GSoC API cleanup (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/816">issue 816</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1128">issue 1128</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1147">issue 1147</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1148">issue 1148</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1156">issue 1156</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1185">issue 1185</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1187">issue 1187</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1258">issue 1258</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1268">issue 1268</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1276">issue 1276</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1285">issue 1285</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1284">issue 1284</a>)</li>
<li>Be more responsive with IO operations (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1074">issue 1074</a> and <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1075">issue 1075</a>)</li>
<li>Do leveldb compaction for httpcache on closing (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1297">issue 1297</a>)</li>
</ul>
<p>Deprecations and Removals</p>
<ul class="simple">
<li>Deprecate htmlparser link extractor (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1205">issue 1205</a>)</li>
<li>remove deprecated code from FeedExporter (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1155">issue 1155</a>)</li>
<li>a leftover for.15 compatibility (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/925">issue 925</a>)</li>
<li>drop support for CONCURRENT_REQUESTS_PER_SPIDER (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/895">issue 895</a>)</li>
<li>Drop old engine code (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/911">issue 911</a>)</li>
<li>Deprecate SgmlLinkExtractor (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/777">issue 777</a>)</li>
</ul>
<p>Relocations</p>
<ul class="simple">
<li>Move exporters/__init__.py to exporters.py (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1242">issue 1242</a>)</li>
<li>Move base classes to their packages (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1218">issue 1218</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1233">issue 1233</a>)</li>
<li>Module relocation (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1181">issue 1181</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1210">issue 1210</a>)</li>
<li>rename SpiderManager to SpiderLoader (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1166">issue 1166</a>)</li>
<li>Remove djangoitem (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1177">issue 1177</a>)</li>
<li>remove scrapy deploy command (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1102">issue 1102</a>)</li>
<li>dissolve contrib_exp (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1134">issue 1134</a>)</li>
<li>Deleted bin folder from root, fixes #913 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/914">issue 914</a>)</li>
<li>Remove jsonrpc based webservice (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/859">issue 859</a>)</li>
<li>Move Test cases under project root dir (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/827">issue 827</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/841">issue 841</a>)</li>
<li>Fix backward incompatibility for relocated paths in settings
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1267">issue 1267</a>)</li>
</ul>
<p>Documentation</p>
<ul class="simple">
<li>CrawlerProcess documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1190">issue 1190</a>)</li>
<li>Favoring web scraping over screen scraping in the descriptions
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1188">issue 1188</a>)</li>
<li>Some improvements for Scrapy tutorial (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1180">issue 1180</a>)</li>
<li>Documenting Files Pipeline together with Images Pipeline (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1150">issue 1150</a>)</li>
<li>deployment docs tweaks (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1164">issue 1164</a>)</li>
<li>Added deployment section covering scrapyd-deploy and shub (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1124">issue 1124</a>)</li>
<li>Adding more settings to project template (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1073">issue 1073</a>)</li>
<li>some improvements to overview page (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1106">issue 1106</a>)</li>
<li>Updated link in docs/topics/architecture.rst (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/647">issue 647</a>)</li>
<li>DOC reorder topics (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1022">issue 1022</a>)</li>
<li>updating list of Request.meta special keys (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1071">issue 1071</a>)</li>
<li>DOC document download_timeout (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/898">issue 898</a>)</li>
<li>DOC simplify extension docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/893">issue 893</a>)</li>
<li>Leaks docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/894">issue 894</a>)</li>
<li>DOC document from_crawler method for item pipelines (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/904">issue 904</a>)</li>
<li>Spider_error doesn’t support deferreds (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1292">issue 1292</a>)</li>
<li>Corrections &amp; Sphinx related fixes (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1220">issue 1220</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1219">issue 1219</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1196">issue 1196</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1172">issue 1172</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1171">issue 1171</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1169">issue 1169</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1160">issue 1160</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1154">issue 1154</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1127">issue 1127</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1112">issue 1112</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1105">issue 1105</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1041">issue 1041</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1082">issue 1082</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1033">issue 1033</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/944">issue 944</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/866">issue 866</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/864">issue 864</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/796">issue 796</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1260">issue 1260</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1271">issue 1271</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1293">issue 1293</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1298">issue 1298</a>)</li>
</ul>
<p>Bugfixes</p>
<ul class="simple">
<li>Item multi inheritance fix (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/353">issue 353</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/1228">issue 1228</a>)</li>
<li>ItemLoader.load_item: iterate over copy of fields (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/722">issue 722</a>)</li>
<li>Fix Unhandled error in Deferred (RobotsTxtMiddleware) (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1131">issue 1131</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1197">issue 1197</a>)</li>
<li>Force to read DOWNLOAD_TIMEOUT as int (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/954">issue 954</a>)</li>
<li>scrapy.utils.misc.load_object should print full traceback (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/902">issue 902</a>)</li>
<li>Fix bug for ”.local” host name (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/878">issue 878</a>)</li>
<li>Fix for Enabled extensions, middlewares, pipelines info not printed
anymore (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/879">issue 879</a>)</li>
<li>fix dont_merge_cookies bad behaviour when set to false on meta
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/846">issue 846</a>)</li>
</ul>
<p>Python 3 In Progress Support</p>
<ul class="simple">
<li>disable scrapy.telnet if twisted.conch is not available (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1161">issue 1161</a>)</li>
<li>fix Python 3 syntax errors in ajaxcrawl.py (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1162">issue 1162</a>)</li>
<li>more python3 compatibility changes for urllib (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1121">issue 1121</a>)</li>
<li>assertItemsEqual was renamed to assertCountEqual in Python 3.
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1070">issue 1070</a>)</li>
<li>Import unittest.mock if available. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1066">issue 1066</a>)</li>
<li>updated deprecated cgi.parse_qsl to use six’s parse_qsl (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/909">issue 909</a>)</li>
<li>Prevent Python 3 port regressions (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/830">issue 830</a>)</li>
<li>PY3: use MutableMapping for python 3 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/810">issue 810</a>)</li>
<li>PY3: use six.BytesIO and six.moves.cStringIO (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/803">issue 803</a>)</li>
<li>PY3: fix xmlrpclib and email imports (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/801">issue 801</a>)</li>
<li>PY3: use six for robotparser and urlparse (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/800">issue 800</a>)</li>
<li>PY3: use six.iterkeys, six.iteritems, and tempfile (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/799">issue 799</a>)</li>
<li>PY3: fix has_key and use six.moves.configparser (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/798">issue 798</a>)</li>
<li>PY3: use six.moves.cPickle (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/797">issue 797</a>)</li>
<li>PY3 make it possible to run some tests in Python3 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/776">issue 776</a>)</li>
</ul>
<p>Tests</p>
<ul class="simple">
<li>remove unnecessary lines from py3-ignores (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1243">issue 1243</a>)</li>
<li>Fix remaining warnings from pytest while collecting tests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1206">issue 1206</a>)</li>
<li>Add docs build to travis (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1234">issue 1234</a>)</li>
<li>TST don’t collect tests from deprecated modules. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1165">issue 1165</a>)</li>
<li>install service_identity package in tests to prevent warnings
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1168">issue 1168</a>)</li>
<li>Fix deprecated settings API in tests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1152">issue 1152</a>)</li>
<li>Add test for webclient with POST method and no body given (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1089">issue 1089</a>)</li>
<li>py3-ignores.txt supports comments (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1044">issue 1044</a>)</li>
<li>modernize some of the asserts (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/835">issue 835</a>)</li>
<li>selector.__repr__ test (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/779">issue 779</a>)</li>
</ul>
<p>Code refactoring</p>
<ul class="simple">
<li>CSVFeedSpider cleanup: use iterate_spider_output (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1079">issue 1079</a>)</li>
<li>remove unnecessary check from scrapy.utils.spider.iter_spider_output
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/1078">issue 1078</a>)</li>
<li>Pydispatch pep8 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/992">issue 992</a>)</li>
<li>Removed unused ‘load=False’ parameter from walk_modules() (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/871">issue 871</a>)</li>
<li>For consistency, use <cite>job_dir</cite> helper in <cite>SpiderState</cite> extension.
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/805">issue 805</a>)</li>
<li>rename “sflo” local variables to less cryptic “log_observer” (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/775">issue 775</a>)</li>
</ul>
</div>
</div>
<div class="section" id="scrapy-0-24-6-2015-04-20">
<h2>Scrapy 0.24.6 (2015-04-20)<a class="headerlink" href="#scrapy-0-24-6-2015-04-20" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>encode invalid xpath with unicode_escape under PY2 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/07cb3e5">commit 07cb3e5</a>)</li>
<li>fix IPython shell scope issue and load IPython user config (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2c8e573">commit 2c8e573</a>)</li>
<li>Fix small typo in the docs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d694019">commit d694019</a>)</li>
<li>Fix small typo (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/f92fa83">commit f92fa83</a>)</li>
<li>Converted sel.xpath() calls to response.xpath() in Extracting the data (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c2c6d15">commit c2c6d15</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-24-5-2015-02-25">
<h2>Scrapy 0.24.5 (2015-02-25)<a class="headerlink" href="#scrapy-0-24-5-2015-02-25" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Support new _getEndpoint Agent signatures on Twisted 15.0.0 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/540b9bc">commit 540b9bc</a>)</li>
<li>DOC a couple more references are fixed (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b4c454b">commit b4c454b</a>)</li>
<li>DOC fix a reference (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e3c1260">commit e3c1260</a>)</li>
<li>t.i.b.ThreadedResolver is now a new-style class (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/9e13f42">commit 9e13f42</a>)</li>
<li>S3DownloadHandler: fix auth for requests with quoted paths/query params (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/cdb9a0b">commit cdb9a0b</a>)</li>
<li>fixed the variable types in mailsender documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bb3a848">commit bb3a848</a>)</li>
<li>Reset items_scraped instead of item_count (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/edb07a4">commit edb07a4</a>)</li>
<li>Tentative attention message about what document to read for contributions (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7ee6f7a">commit 7ee6f7a</a>)</li>
<li>mitmproxy 0.10.1 needs netlib 0.10.1 too (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/874fcdd">commit 874fcdd</a>)</li>
<li>pin mitmproxy 0.10.1 as &gt;0.11 does not work with tests (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c6b21f0">commit c6b21f0</a>)</li>
<li>Test the parse command locally instead of against an external url (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c3a6628">commit c3a6628</a>)</li>
<li>Patches Twisted issue while closing the connection pool on HTTPDownloadHandler (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d0bf957">commit d0bf957</a>)</li>
<li>Updates documentation on dynamic item classes. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/eeb589a">commit eeb589a</a>)</li>
<li>Merge pull request #943 from Lazar-T/patch-3 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5fdab02">commit 5fdab02</a>)</li>
<li>typo (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b0ae199">commit b0ae199</a>)</li>
<li>pywin32 is required by Twisted. closes #937 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5cb0cfb">commit 5cb0cfb</a>)</li>
<li>Update install.rst (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/781286b">commit 781286b</a>)</li>
<li>Merge pull request #928 from Lazar-T/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b415d04">commit b415d04</a>)</li>
<li>comma instead of fullstop (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/627b9ba">commit 627b9ba</a>)</li>
<li>Merge pull request #885 from jsma/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/de909ad">commit de909ad</a>)</li>
<li>Update request-response.rst (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3f3263d">commit 3f3263d</a>)</li>
<li>SgmlLinkExtractor - fix for parsing &lt;area&gt; tag with Unicode present (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/49b40f0">commit 49b40f0</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-24-4-2014-08-09">
<h2>Scrapy 0.24.4 (2014-08-09)<a class="headerlink" href="#scrapy-0-24-4-2014-08-09" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>pem file is used by mockserver and required by scrapy bench (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5eddc68">commit 5eddc68</a>)</li>
<li>scrapy bench needs scrapy.tests* (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d6cb999">commit d6cb999</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-24-3-2014-08-09">
<h2>Scrapy 0.24.3 (2014-08-09)<a class="headerlink" href="#scrapy-0-24-3-2014-08-09" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>no need to waste travis-ci time on py3 for 0.24 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8e080c1">commit 8e080c1</a>)</li>
<li>Update installation docs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1d0c096">commit 1d0c096</a>)</li>
<li>There is a trove classifier for Scrapy framework! (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/4c701d7">commit 4c701d7</a>)</li>
<li>update other places where w3lib version is mentioned (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d109c13">commit d109c13</a>)</li>
<li>Update w3lib requirement to 1.8.0 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/39d2ce5">commit 39d2ce5</a>)</li>
<li>Use w3lib.html.replace_entities() (remove_entities() is deprecated) (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/180d3ad">commit 180d3ad</a>)</li>
<li>set zip_safe=False (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a51ee8b">commit a51ee8b</a>)</li>
<li>do not ship tests package (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ee3b371">commit ee3b371</a>)</li>
<li>scrapy.bat is not needed anymore (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c3861cf">commit c3861cf</a>)</li>
<li>Modernize setup.py (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/362e322">commit 362e322</a>)</li>
<li>headers can not handle non-string values (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/94a5c65">commit 94a5c65</a>)</li>
<li>fix ftp test cases (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a274a7f">commit a274a7f</a>)</li>
<li>The sum up of travis-ci builds are taking like 50min to complete (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ae1e2cc">commit ae1e2cc</a>)</li>
<li>Update shell.rst typo (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e49c96a">commit e49c96a</a>)</li>
<li>removes weird indentation in the shell results (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1ca489d">commit 1ca489d</a>)</li>
<li>improved explanations, clarified blog post as source, added link for XPath string functions in the spec (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/65c8f05">commit 65c8f05</a>)</li>
<li>renamed UserTimeoutError and ServerTimeouterror #583 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/037f6ab">commit 037f6ab</a>)</li>
<li>adding some xpath tips to selectors docs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2d103e0">commit 2d103e0</a>)</li>
<li>fix tests to account for <a class="reference external" href="https://github.com/scrapy/w3lib/pull/23">https://github.com/scrapy/w3lib/pull/23</a> (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/f8d366a">commit f8d366a</a>)</li>
<li>get_func_args maximum recursion fix #728 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/81344ea">commit 81344ea</a>)</li>
<li>Updated input/ouput processor example according to #560. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/f7c4ea8">commit f7c4ea8</a>)</li>
<li>Fixed Python syntax in tutorial. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/db59ed9">commit db59ed9</a>)</li>
<li>Add test case for tunneling proxy (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/f090260">commit f090260</a>)</li>
<li>Bugfix for leaking Proxy-Authorization header to remote host when using tunneling (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d8793af">commit d8793af</a>)</li>
<li>Extract links from XHTML documents with MIME-Type “application/xml” (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ed1f376">commit ed1f376</a>)</li>
<li>Merge pull request #793 from roysc/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/91a1106">commit 91a1106</a>)</li>
<li>Fix typo in commands.rst (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/743e1e2">commit 743e1e2</a>)</li>
<li>better testcase for settings.overrides.setdefault (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e22daaf">commit e22daaf</a>)</li>
<li>Using CRLF as line marker according to http 1.1 definition (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5ec430b">commit 5ec430b</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-24-2-2014-07-08">
<h2>Scrapy 0.24.2 (2014-07-08)<a class="headerlink" href="#scrapy-0-24-2-2014-07-08" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Use a mutable mapping to proxy deprecated settings.overrides and settings.defaults attribute (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e5e8133">commit e5e8133</a>)</li>
<li>there is not support for python3 yet (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3cd6146">commit 3cd6146</a>)</li>
<li>Update python compatible version set to debian packages (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fa5d76b">commit fa5d76b</a>)</li>
<li>DOC fix formatting in release notes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c6a9e20">commit c6a9e20</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-24-1-2014-06-27">
<h2>Scrapy 0.24.1 (2014-06-27)<a class="headerlink" href="#scrapy-0-24-1-2014-06-27" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Fix deprecated CrawlerSettings and increase backwards compatibility with
.defaults attribute (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8e3f20a">commit 8e3f20a</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-24-0-2014-06-26">
<h2>Scrapy 0.24.0 (2014-06-26)<a class="headerlink" href="#scrapy-0-24-0-2014-06-26" title="Permalink to this headline">¶</a></h2>
<div class="section" id="enhancements">
<h3>Enhancements<a class="headerlink" href="#enhancements" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Improve Scrapy top-level namespace (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/494">issue 494</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/684">issue 684</a>)</li>
<li>Add selector shortcuts to responses (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/554">issue 554</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/690">issue 690</a>)</li>
<li>Add new lxml based LinkExtractor to replace unmantained SgmlLinkExtractor
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/559">issue 559</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/761">issue 761</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/763">issue 763</a>)</li>
<li>Cleanup settings API - part of per-spider settings <strong>GSoC project</strong> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/737">issue 737</a>)</li>
<li>Add UTF8 encoding header to templates (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/688">issue 688</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/762">issue 762</a>)</li>
<li>Telnet console now binds to 127.0.0.1 by default (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/699">issue 699</a>)</li>
<li>Update debian/ubuntu install instructions (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/509">issue 509</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/549">issue 549</a>)</li>
<li>Disable smart strings in lxml XPath evaluations (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/535">issue 535</a>)</li>
<li>Restore filesystem based cache as default for http
cache middleware (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/541">issue 541</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/500">issue 500</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/571">issue 571</a>)</li>
<li>Expose current crawler in Scrapy shell (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/557">issue 557</a>)</li>
<li>Improve testsuite comparing CSV and XML exporters (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/570">issue 570</a>)</li>
<li>New <cite>offsite/filtered</cite> and <cite>offsite/domains</cite> stats (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/566">issue 566</a>)</li>
<li>Support process_links as generator in CrawlSpider (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/555">issue 555</a>)</li>
<li>Verbose logging and new stats counters for DupeFilter (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/553">issue 553</a>)</li>
<li>Add a mimetype parameter to <cite>MailSender.send()</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/602">issue 602</a>)</li>
<li>Generalize file pipeline log messages (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/622">issue 622</a>)</li>
<li>Replace unencodeable codepoints with html entities in SGMLLinkExtractor (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/565">issue 565</a>)</li>
<li>Converted SEP documents to rst format (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/629">issue 629</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/630">issue 630</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/638">issue 638</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/632">issue 632</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/636">issue 636</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/640">issue 640</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/635">issue 635</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/634">issue 634</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/639">issue 639</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/637">issue 637</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/631">issue 631</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/633">issue 633</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/641">issue 641</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/642">issue 642</a>)</li>
<li>Tests and docs for clickdata’s nr index in FormRequest (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/646">issue 646</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/645">issue 645</a>)</li>
<li>Allow to disable a downloader handler just like any other component (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/650">issue 650</a>)</li>
<li>Log when a request is discarded after too many redirections (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/654">issue 654</a>)</li>
<li>Log error responses if they are not handled by spider callbacks
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/612">issue 612</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/656">issue 656</a>)</li>
<li>Add content-type check to http compression mw (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/193">issue 193</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/660">issue 660</a>)</li>
<li>Run pypy tests using latest pypi from ppa (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/674">issue 674</a>)</li>
<li>Run test suite using pytest instead of trial (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/679">issue 679</a>)</li>
<li>Build docs and check for dead links in tox environment (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/687">issue 687</a>)</li>
<li>Make scrapy.version_info a tuple of integers (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/681">issue 681</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/692">issue 692</a>)</li>
<li>Infer exporter’s output format from filename extensions
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/546">issue 546</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/659">issue 659</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/760">issue 760</a>)</li>
<li>Support case-insensitive domains in <cite>url_is_from_any_domain()</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/693">issue 693</a>)</li>
<li>Remove pep8 warnings in project and spider templates (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/698">issue 698</a>)</li>
<li>Tests and docs for <cite>request_fingerprint</cite> function (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/597">issue 597</a>)</li>
<li>Update SEP-19 for GSoC project <cite>per-spider settings</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/705">issue 705</a>)</li>
<li>Set exit code to non-zero when contracts fails (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/727">issue 727</a>)</li>
<li>Add a setting to control what class is instanciated as Downloader component
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/738">issue 738</a>)</li>
<li>Pass response in <cite>item_dropped</cite> signal (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/724">issue 724</a>)</li>
<li>Improve <cite>scrapy check</cite> contracts command (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/733">issue 733</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/752">issue 752</a>)</li>
<li>Document <cite>spider.closed()</cite> shortcut (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/719">issue 719</a>)</li>
<li>Document <cite>request_scheduled</cite> signal (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/746">issue 746</a>)</li>
<li>Add a note about reporting security issues (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/697">issue 697</a>)</li>
<li>Add LevelDB http cache storage backend (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/626">issue 626</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/500">issue 500</a>)</li>
<li>Sort spider list output of <cite>scrapy list</cite> command (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/742">issue 742</a>)</li>
<li>Multiple documentation enhancemens and fixes
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/575">issue 575</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/587">issue 587</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/590">issue 590</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/596">issue 596</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/610">issue 610</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/617">issue 617</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/618">issue 618</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/627">issue 627</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/613">issue 613</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/643">issue 643</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/654">issue 654</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/675">issue 675</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/663">issue 663</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/711">issue 711</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/714">issue 714</a>)</li>
</ul>
</div>
<div class="section" id="id12">
<h3>Bugfixes<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Encode unicode URL value when creating Links in RegexLinkExtractor (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/561">issue 561</a>)</li>
<li>Ignore None values in ItemLoader processors (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/556">issue 556</a>)</li>
<li>Fix link text when there is an inner tag in SGMLLinkExtractor and
HtmlParserLinkExtractor (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/485">issue 485</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/574">issue 574</a>)</li>
<li>Fix wrong checks on subclassing of deprecated classes
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/581">issue 581</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/584">issue 584</a>)</li>
<li>Handle errors caused by inspect.stack() failures (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/582">issue 582</a>)</li>
<li>Fix a reference to unexistent engine attribute (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/593">issue 593</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/594">issue 594</a>)</li>
<li>Fix dynamic itemclass example usage of type() (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/603">issue 603</a>)</li>
<li>Use lucasdemarchi/codespell to fix typos (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/628">issue 628</a>)</li>
<li>Fix default value of attrs argument in SgmlLinkExtractor to be tuple (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/661">issue 661</a>)</li>
<li>Fix XXE flaw in sitemap reader (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/676">issue 676</a>)</li>
<li>Fix engine to support filtered start requests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/707">issue 707</a>)</li>
<li>Fix offsite middleware case on urls with no hostnames (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/745">issue 745</a>)</li>
<li>Testsuite doesn’t require PIL anymore (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/585">issue 585</a>)</li>
</ul>
</div>
</div>
<div class="section" id="scrapy-0-22-2-released-2014-02-14">
<h2>Scrapy 0.22.2 (released 2014-02-14)<a class="headerlink" href="#scrapy-0-22-2-released-2014-02-14" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>fix a reference to unexistent engine.slots. closes #593 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/13c099a">commit 13c099a</a>)</li>
<li>downloaderMW doc typo (spiderMW doc copy remnant) (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8ae11bf">commit 8ae11bf</a>)</li>
<li>Correct typos (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1346037">commit 1346037</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-22-1-released-2014-02-08">
<h2>Scrapy 0.22.1 (released 2014-02-08)<a class="headerlink" href="#scrapy-0-22-1-released-2014-02-08" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>localhost666 can resolve under certain circumstances (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2ec2279">commit 2ec2279</a>)</li>
<li>test inspect.stack failure (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/cc3eda3">commit cc3eda3</a>)</li>
<li>Handle cases when inspect.stack() fails (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8cb44f9">commit 8cb44f9</a>)</li>
<li>Fix wrong checks on subclassing of deprecated classes. closes #581 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/46d98d6">commit 46d98d6</a>)</li>
<li>Docs: 4-space indent for final spider example (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/13846de">commit 13846de</a>)</li>
<li>Fix HtmlParserLinkExtractor and tests after #485 merge (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/368a946">commit 368a946</a>)</li>
<li>BaseSgmlLinkExtractor: Fixed the missing space when the link has an inner tag (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b566388">commit b566388</a>)</li>
<li>BaseSgmlLinkExtractor: Added unit test of a link with an inner tag (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c1cb418">commit c1cb418</a>)</li>
<li>BaseSgmlLinkExtractor: Fixed unknown_endtag() so that it only set current_link=None when the end tag match the opening tag (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7e4d627">commit 7e4d627</a>)</li>
<li>Fix tests for Travis-CI build (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/76c7e20">commit 76c7e20</a>)</li>
<li>replace unencodeable codepoints with html entities. fixes #562 and #285 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5f87b17">commit 5f87b17</a>)</li>
<li>RegexLinkExtractor: encode URL unicode value when creating Links (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d0ee545">commit d0ee545</a>)</li>
<li>Updated the tutorial crawl output with latest output. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8da65de">commit 8da65de</a>)</li>
<li>Updated shell docs with the crawler reference and fixed the actual shell output. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/875b9ab">commit 875b9ab</a>)</li>
<li>PEP8 minor edits. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/f89efaf">commit f89efaf</a>)</li>
<li>Expose current crawler in the scrapy shell. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5349cec">commit 5349cec</a>)</li>
<li>Unused re import and PEP8 minor edits. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/387f414">commit 387f414</a>)</li>
<li>Ignore None’s values when using the ItemLoader. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0632546">commit 0632546</a>)</li>
<li>DOC Fixed HTTPCACHE_STORAGE typo in the default value which is now Filesystem instead Dbm. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/cde9a8c">commit cde9a8c</a>)</li>
<li>show ubuntu setup instructions as literal code (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fb5c9c5">commit fb5c9c5</a>)</li>
<li>Update Ubuntu installation instructions (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/70fb105">commit 70fb105</a>)</li>
<li>Merge pull request #550 from stray-leone/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6f70b6a">commit 6f70b6a</a>)</li>
<li>modify the version of scrapy ubuntu package (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/725900d">commit 725900d</a>)</li>
<li>fix 0.22.0 release date (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/af0219a">commit af0219a</a>)</li>
<li>fix typos in news.rst and remove (not released yet) header (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b7f58f4">commit b7f58f4</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-22-0-released-2014-01-17">
<h2>Scrapy 0.22.0 (released 2014-01-17)<a class="headerlink" href="#scrapy-0-22-0-released-2014-01-17" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id13">
<h3>Enhancements<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>[<strong>Backwards incompatible</strong>] Switched HTTPCacheMiddleware backend to filesystem (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/541">issue 541</a>)
To restore old backend set <cite>HTTPCACHE_STORAGE</cite> to <cite>scrapy.contrib.httpcache.DbmCacheStorage</cite></li>
<li>Proxy https:// urls using CONNECT method (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/392">issue 392</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/397">issue 397</a>)</li>
<li>Add a middleware to crawl ajax crawleable pages as defined by google (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/343">issue 343</a>)</li>
<li>Rename scrapy.spider.BaseSpider to scrapy.spider.Spider (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/510">issue 510</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/519">issue 519</a>)</li>
<li>Selectors register EXSLT namespaces by default (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/472">issue 472</a>)</li>
<li>Unify item loaders similar to selectors renaming (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/461">issue 461</a>)</li>
<li>Make <cite>RFPDupeFilter</cite> class easily subclassable (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/533">issue 533</a>)</li>
<li>Improve test coverage and forthcoming Python 3 support (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/525">issue 525</a>)</li>
<li>Promote startup info on settings and middleware to INFO level (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/520">issue 520</a>)</li>
<li>Support partials in <cite>get_func_args</cite> util (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/506">issue 506</a>, issue:<cite>504</cite>)</li>
<li>Allow running indiviual tests via tox (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/503">issue 503</a>)</li>
<li>Update extensions ignored by link extractors (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/498">issue 498</a>)</li>
<li>Add middleware methods to get files/images/thumbs paths (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/490">issue 490</a>)</li>
<li>Improve offsite middleware tests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/478">issue 478</a>)</li>
<li>Add a way to skip default Referer header set by RefererMiddleware (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/475">issue 475</a>)</li>
<li>Do not send <cite>x-gzip</cite> in default <cite>Accept-Encoding</cite> header (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/469">issue 469</a>)</li>
<li>Support defining http error handling using settings (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/466">issue 466</a>)</li>
<li>Use modern python idioms wherever you find legacies (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/497">issue 497</a>)</li>
<li>Improve and correct documentation
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/527">issue 527</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/524">issue 524</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/521">issue 521</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/517">issue 517</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/512">issue 512</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/505">issue 505</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/502">issue 502</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/489">issue 489</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/465">issue 465</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/460">issue 460</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/425">issue 425</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/536">issue 536</a>)</li>
</ul>
</div>
<div class="section" id="fixes">
<h3>Fixes<a class="headerlink" href="#fixes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Update Selector class imports in CrawlSpider template (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/484">issue 484</a>)</li>
<li>Fix unexistent reference to <cite>engine.slots</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/464">issue 464</a>)</li>
<li>Do not try to call <cite>body_as_unicode()</cite> on a non-TextResponse instance (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/462">issue 462</a>)</li>
<li>Warn when subclassing XPathItemLoader, previously it only warned on
instantiation. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/523">issue 523</a>)</li>
<li>Warn when subclassing XPathSelector, previously it only warned on
instantiation. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/537">issue 537</a>)</li>
<li>Multiple fixes to memory stats (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/531">issue 531</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/530">issue 530</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/529">issue 529</a>)</li>
<li>Fix overriding url in <cite>FormRequest.from_response()</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/507">issue 507</a>)</li>
<li>Fix tests runner under pip 1.5 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/513">issue 513</a>)</li>
<li>Fix logging error when spider name is unicode (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/479">issue 479</a>)</li>
</ul>
</div>
</div>
<div class="section" id="scrapy-0-20-2-released-2013-12-09">
<h2>Scrapy 0.20.2 (released 2013-12-09)<a class="headerlink" href="#scrapy-0-20-2-released-2013-12-09" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Update CrawlSpider Template with Selector changes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6d1457d">commit 6d1457d</a>)</li>
<li>fix method name in tutorial. closes GH-480 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b4fc359">commit b4fc359</a></li>
</ul>
</div>
<div class="section" id="scrapy-0-20-1-released-2013-11-28">
<h2>Scrapy 0.20.1 (released 2013-11-28)<a class="headerlink" href="#scrapy-0-20-1-released-2013-11-28" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>include_package_data is required to build wheels from published sources (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5ba1ad5">commit 5ba1ad5</a>)</li>
<li>process_parallel was leaking the failures on its internal deferreds.  closes #458 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/419a780">commit 419a780</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-20-0-released-2013-11-08">
<h2>Scrapy 0.20.0 (released 2013-11-08)<a class="headerlink" href="#scrapy-0-20-0-released-2013-11-08" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id14">
<h3>Enhancements<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>New Selector’s API including CSS selectors (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/395">issue 395</a> and <a class="reference external" href="https://github.com/scrapy/scrapy/issues/426">issue 426</a>),</li>
<li>Request/Response url/body attributes are now immutable
(modifying them had been deprecated for a long time)</li>
<li><a class="reference internal" href="topics/settings.html#std:setting-ITEM_PIPELINES"><code class="xref std std-setting docutils literal"><span class="pre">ITEM_PIPELINES</span></code></a> is now defined as a dict (instead of a list)</li>
<li>Sitemap spider can fetch alternate URLs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/360">issue 360</a>)</li>
<li><cite>Selector.remove_namespaces()</cite> now remove namespaces from element’s attributes. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/416">issue 416</a>)</li>
<li>Paved the road for Python 3.3+ (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/435">issue 435</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/436">issue 436</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/431">issue 431</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/452">issue 452</a>)</li>
<li>New item exporter using native python types with nesting support (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/366">issue 366</a>)</li>
<li>Tune HTTP1.1 pool size so it matches concurrency defined by settings (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b43b5f575">commit b43b5f575</a>)</li>
<li>scrapy.mail.MailSender now can connect over TLS or upgrade using STARTTLS (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/327">issue 327</a>)</li>
<li>New FilesPipeline with functionality factored out from ImagesPipeline (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/370">issue 370</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/409">issue 409</a>)</li>
<li>Recommend Pillow instead of PIL for image handling (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/317">issue 317</a>)</li>
<li>Added debian packages for Ubuntu quantal and raring (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/86230c0">commit 86230c0</a>)</li>
<li>Mock server (used for tests) can listen for HTTPS requests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/410">issue 410</a>)</li>
<li>Remove multi spider support from multiple core components
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/422">issue 422</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/421">issue 421</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/420">issue 420</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/419">issue 419</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/423">issue 423</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/418">issue 418</a>)</li>
<li>Travis-CI now tests Scrapy changes against development versions of <cite>w3lib</cite> and <cite>queuelib</cite> python packages.</li>
<li>Add pypy 2.1 to continuous integration tests (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ecfa7431">commit ecfa7431</a>)</li>
<li>Pylinted, pep8 and removed old-style exceptions from source (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/430">issue 430</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/432">issue 432</a>)</li>
<li>Use importlib for parametric imports (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/445">issue 445</a>)</li>
<li>Handle a regression introduced in Python 2.7.5 that affects XmlItemExporter (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/372">issue 372</a>)</li>
<li>Bugfix crawling shutdown on SIGINT (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/450">issue 450</a>)</li>
<li>Do not submit <cite>reset</cite> type inputs in FormRequest.from_response (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b326b87">commit b326b87</a>)</li>
<li>Do not silence download errors when request errback raises an exception (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/684cfc0">commit 684cfc0</a>)</li>
</ul>
</div>
<div class="section" id="id15">
<h3>Bugfixes<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Fix tests under Django 1.6 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b6bed44c">commit b6bed44c</a>)</li>
<li>Lot of bugfixes to retry middleware under disconnections using HTTP 1.1 download handler</li>
<li>Fix inconsistencies among Twisted releases (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/406">issue 406</a>)</li>
<li>Fix scrapy shell bugs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/418">issue 418</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/407">issue 407</a>)</li>
<li>Fix invalid variable name in setup.py (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/429">issue 429</a>)</li>
<li>Fix tutorial references (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/387">issue 387</a>)</li>
<li>Improve request-response docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/391">issue 391</a>)</li>
<li>Improve best practices docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/399">issue 399</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/400">issue 400</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/401">issue 401</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/402">issue 402</a>)</li>
<li>Improve django integration docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/404">issue 404</a>)</li>
<li>Document <cite>bindaddress</cite> request meta (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/37c24e01d7">commit 37c24e01d7</a>)</li>
<li>Improve <cite>Request</cite> class documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/226">issue 226</a>)</li>
</ul>
</div>
<div class="section" id="other">
<h3>Other<a class="headerlink" href="#other" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Dropped Python 2.6 support (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/448">issue 448</a>)</li>
<li>Add <a class="reference external" href="https://github.com/SimonSapin/cssselect">cssselect</a> python package as install dependency</li>
<li>Drop libxml2 and multi selector’s backend support, <a class="reference external" href="http://lxml.de/">lxml</a> is required from now on.</li>
<li>Minimum Twisted version increased to 10.0.0, dropped Twisted 8.0 support.</li>
<li>Running test suite now requires <cite>mock</cite> python library (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/390">issue 390</a>)</li>
</ul>
</div>
<div class="section" id="thanks">
<h3>Thanks<a class="headerlink" href="#thanks" title="Permalink to this headline">¶</a></h3>
<p>Thanks to everyone who contribute to this release!</p>
<p>List of contributors sorted by number of commits:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">69</span> <span class="n">Daniel</span> <span class="n">Graña</span> <span class="o">&lt;</span><span class="n">dangra</span><span class="o">@...&gt;</span>
<span class="mi">37</span> <span class="n">Pablo</span> <span class="n">Hoffman</span> <span class="o">&lt;</span><span class="n">pablo</span><span class="o">@...&gt;</span>
<span class="mi">13</span> <span class="n">Mikhail</span> <span class="n">Korobov</span> <span class="o">&lt;</span><span class="n">kmike84</span><span class="o">@...&gt;</span>
 <span class="mi">9</span> <span class="n">Alex</span> <span class="n">Cepoi</span> <span class="o">&lt;</span><span class="n">alex</span><span class="o">.</span><span class="n">cepoi</span><span class="o">@...&gt;</span>
 <span class="mi">9</span> <span class="n">alexanderlukanin13</span> <span class="o">&lt;</span><span class="n">alexander</span><span class="o">.</span><span class="n">lukanin</span><span class="o">.</span><span class="mi">13</span><span class="o">@...&gt;</span>
 <span class="mi">8</span> <span class="n">Rolando</span> <span class="n">Espinoza</span> <span class="n">La</span> <span class="n">fuente</span> <span class="o">&lt;</span><span class="n">darkrho</span><span class="o">@...&gt;</span>
 <span class="mi">8</span> <span class="n">Lukasz</span> <span class="n">Biedrycki</span> <span class="o">&lt;</span><span class="n">lukasz</span><span class="o">.</span><span class="n">biedrycki</span><span class="o">@...&gt;</span>
 <span class="mi">6</span> <span class="n">Nicolas</span> <span class="n">Ramirez</span> <span class="o">&lt;</span><span class="n">nramirez</span><span class="o">.</span><span class="n">uy</span><span class="o">@...&gt;</span>
 <span class="mi">3</span> <span class="n">Paul</span> <span class="n">Tremberth</span> <span class="o">&lt;</span><span class="n">paul</span><span class="o">.</span><span class="n">tremberth</span><span class="o">@...&gt;</span>
 <span class="mi">2</span> <span class="n">Martin</span> <span class="n">Olveyra</span> <span class="o">&lt;</span><span class="n">molveyra</span><span class="o">@...&gt;</span>
 <span class="mi">2</span> <span class="n">Stefan</span> <span class="o">&lt;</span><span class="n">misc</span><span class="o">@...&gt;</span>
 <span class="mi">2</span> <span class="n">Rolando</span> <span class="n">Espinoza</span> <span class="o">&lt;</span><span class="n">darkrho</span><span class="o">@...&gt;</span>
 <span class="mi">2</span> <span class="n">Loren</span> <span class="n">Davie</span> <span class="o">&lt;</span><span class="n">loren</span><span class="o">@...&gt;</span>
 <span class="mi">2</span> <span class="n">irgmedeiros</span> <span class="o">&lt;</span><span class="n">irgmedeiros</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">Stefan</span> <span class="n">Koch</span> <span class="o">&lt;</span><span class="n">taikano</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">Stefan</span> <span class="o">&lt;</span><span class="n">cct</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">scraperdragon</span> <span class="o">&lt;</span><span class="n">dragon</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">Kumara</span> <span class="n">Tharmalingam</span> <span class="o">&lt;</span><span class="n">ktharmal</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">Francesco</span> <span class="n">Piccinno</span> <span class="o">&lt;</span><span class="n">stack</span><span class="o">.</span><span class="n">box</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">Marcos</span> <span class="n">Campal</span> <span class="o">&lt;</span><span class="n">duendex</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">Dragon</span> <span class="n">Dave</span> <span class="o">&lt;</span><span class="n">dragon</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">Capi</span> <span class="n">Etheriel</span> <span class="o">&lt;</span><span class="n">barraponto</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">cacovsky</span> <span class="o">&lt;</span><span class="n">amarquesferraz</span><span class="o">@...&gt;</span>
 <span class="mi">1</span> <span class="n">Berend</span> <span class="n">Iwema</span> <span class="o">&lt;</span><span class="n">berend</span><span class="o">@...&gt;</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="scrapy-0-18-4-released-2013-10-10">
<h2>Scrapy 0.18.4 (released 2013-10-10)<a class="headerlink" href="#scrapy-0-18-4-released-2013-10-10" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>IPython refuses to update the namespace. fix #396 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3d32c4f">commit 3d32c4f</a>)</li>
<li>Fix AlreadyCalledError replacing a request in shell command. closes #407 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b1d8919">commit b1d8919</a>)</li>
<li>Fix start_requests laziness and early hangs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/89faf52">commit 89faf52</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-18-3-released-2013-10-03">
<h2>Scrapy 0.18.3 (released 2013-10-03)<a class="headerlink" href="#scrapy-0-18-3-released-2013-10-03" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>fix regression on lazy evaluation of start requests (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/12693a5">commit 12693a5</a>)</li>
<li>forms: do not submit reset inputs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e429f63">commit e429f63</a>)</li>
<li>increase unittest timeouts to decrease travis false positive failures (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/912202e">commit 912202e</a>)</li>
<li>backport master fixes to json exporter (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/cfc2d46">commit cfc2d46</a>)</li>
<li>Fix permission and set umask before generating sdist tarball (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/06149e0">commit 06149e0</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-18-2-released-2013-09-03">
<h2>Scrapy 0.18.2 (released 2013-09-03)<a class="headerlink" href="#scrapy-0-18-2-released-2013-09-03" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Backport <cite>scrapy check</cite> command fixes and backward compatible multi
crawler process(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/339">issue 339</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-18-1-released-2013-08-27">
<h2>Scrapy 0.18.1 (released 2013-08-27)<a class="headerlink" href="#scrapy-0-18-1-released-2013-08-27" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>remove extra import added by cherry picked changes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d20304e">commit d20304e</a>)</li>
<li>fix crawling tests under twisted pre 11.0.0 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1994f38">commit 1994f38</a>)</li>
<li>py26 can not format zero length fields {} (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/abf756f">commit abf756f</a>)</li>
<li>test PotentiaDataLoss errors on unbound responses (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b15470d">commit b15470d</a>)</li>
<li>Treat responses without content-length or Transfer-Encoding as good responses (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c4bf324">commit c4bf324</a>)</li>
<li>do no include ResponseFailed if http11 handler is not enabled (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6cbe684">commit 6cbe684</a>)</li>
<li>New HTTP client wraps connection losts in ResponseFailed exception. fix #373 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1a20bba">commit 1a20bba</a>)</li>
<li>limit travis-ci build matrix (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3b01bb8">commit 3b01bb8</a>)</li>
<li>Merge pull request #375 from peterarenot/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fa766d7">commit fa766d7</a>)</li>
<li>Fixed so it refers to the correct folder (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3283809">commit 3283809</a>)</li>
<li>added quantal &amp; raring to support ubuntu releases (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1411923">commit 1411923</a>)</li>
<li>fix retry middleware which didn’t retry certain connection errors after the upgrade to http1 client, closes GH-373 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bb35ed0">commit bb35ed0</a>)</li>
<li>fix XmlItemExporter in Python 2.7.4 and 2.7.5 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/de3e451">commit de3e451</a>)</li>
<li>minor updates to 0.18 release notes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c45e5f1">commit c45e5f1</a>)</li>
<li>fix contributters list format (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0b60031">commit 0b60031</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-18-0-released-2013-08-09">
<h2>Scrapy 0.18.0 (released 2013-08-09)<a class="headerlink" href="#scrapy-0-18-0-released-2013-08-09" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Lot of improvements to testsuite run using Tox, including a way to test on pypi</li>
<li>Handle GET parameters for AJAX crawleable urls (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3fe2a32">commit 3fe2a32</a>)</li>
<li>Use lxml recover option to parse sitemaps (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/347">issue 347</a>)</li>
<li>Bugfix cookie merging by hostname and not by netloc (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/352">issue 352</a>)</li>
<li>Support disabling <cite>HttpCompressionMiddleware</cite> using a flag setting (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/359">issue 359</a>)</li>
<li>Support xml namespaces using <cite>iternodes</cite> parser in <cite>XMLFeedSpider</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/12">issue 12</a>)</li>
<li>Support <cite>dont_cache</cite> request meta flag (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/19">issue 19</a>)</li>
<li>Bugfix <cite>scrapy.utils.gz.gunzip</cite> broken by changes in python 2.7.4 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/4dc76e">commit 4dc76e</a>)</li>
<li>Bugfix url encoding on <cite>SgmlLinkExtractor</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/24">issue 24</a>)</li>
<li>Bugfix <cite>TakeFirst</cite> processor shouldn’t discard zero (0) value (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/59">issue 59</a>)</li>
<li>Support nested items in xml exporter (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/66">issue 66</a>)</li>
<li>Improve cookies handling performance (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/77">issue 77</a>)</li>
<li>Log dupe filtered requests once (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/105">issue 105</a>)</li>
<li>Split redirection middleware into status and meta based middlewares (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/78">issue 78</a>)</li>
<li>Use HTTP1.1 as default downloader handler (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/109">issue 109</a> and <a class="reference external" href="https://github.com/scrapy/scrapy/issues/318">issue 318</a>)</li>
<li>Support xpath form selection on <cite>FormRequest.from_response</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/185">issue 185</a>)</li>
<li>Bugfix unicode decoding error on <cite>SgmlLinkExtractor</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/199">issue 199</a>)</li>
<li>Bugfix signal dispatching on pypi interpreter (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/205">issue 205</a>)</li>
<li>Improve request delay and concurrency handling (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/206">issue 206</a>)</li>
<li>Add RFC2616 cache policy to <cite>HttpCacheMiddleware</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/212">issue 212</a>)</li>
<li>Allow customization of messages logged by engine (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/214">issue 214</a>)</li>
<li>Multiples improvements to <cite>DjangoItem</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/217">issue 217</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/218">issue 218</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/221">issue 221</a>)</li>
<li>Extend Scrapy commands using setuptools entry points (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/260">issue 260</a>)</li>
<li>Allow spider <cite>allowed_domains</cite> value to be set/tuple (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/261">issue 261</a>)</li>
<li>Support <cite>settings.getdict</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/269">issue 269</a>)</li>
<li>Simplify internal <cite>scrapy.core.scraper</cite> slot handling (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/271">issue 271</a>)</li>
<li>Added <cite>Item.copy</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/290">issue 290</a>)</li>
<li>Collect idle downloader slots (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/297">issue 297</a>)</li>
<li>Add <cite>ftp://</cite> scheme downloader handler (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/329">issue 329</a>)</li>
<li>Added downloader benchmark webserver and spider tools <a class="reference internal" href="topics/benchmarking.html#benchmarking"><span class="std std-ref">Benchmarking</span></a></li>
<li>Moved persistent (on disk) queues to a separate project (<a class="reference external" href="https://github.com/scrapy/queuelib">queuelib</a>) which scrapy now depends on</li>
<li>Add scrapy commands using external libraries (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/260">issue 260</a>)</li>
<li>Added <code class="docutils literal"><span class="pre">--pdb</span></code> option to <code class="docutils literal"><span class="pre">scrapy</span></code> command line tool</li>
<li>Added <code class="xref py py-meth docutils literal"><span class="pre">XPathSelector.remove_namespaces()</span></code> which allows to remove all namespaces from XML documents for convenience (to work with namespace-less XPaths). Documented in <a class="reference internal" href="topics/selectors.html#topics-selectors"><span class="std std-ref">Selectors</span></a>.</li>
<li>Several improvements to spider contracts</li>
<li>New default middleware named MetaRefreshMiddldeware that handles meta-refresh html tag redirections,</li>
<li>MetaRefreshMiddldeware and RedirectMiddleware have different priorities to address #62</li>
<li>added from_crawler method to spiders</li>
<li>added system tests with mock server</li>
<li>more improvements to Mac OS compatibility (thanks Alex Cepoi)</li>
<li>several more cleanups to singletons and multi-spider support (thanks Nicolas Ramirez)</li>
<li>support custom download slots</li>
<li>added –spider option to “shell” command.</li>
<li>log overridden settings when scrapy starts</li>
</ul>
<p>Thanks to everyone who contribute to this release. Here is a list of
contributors sorted by number of commits:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">130</span> <span class="n">Pablo</span> <span class="n">Hoffman</span> <span class="o">&lt;</span><span class="n">pablo</span><span class="o">@...&gt;</span>
 <span class="mi">97</span> <span class="n">Daniel</span> <span class="n">Graña</span> <span class="o">&lt;</span><span class="n">dangra</span><span class="o">@...&gt;</span>
 <span class="mi">20</span> <span class="n">Nicolás</span> <span class="n">Ramírez</span> <span class="o">&lt;</span><span class="n">nramirez</span><span class="o">.</span><span class="n">uy</span><span class="o">@...&gt;</span>
 <span class="mi">13</span> <span class="n">Mikhail</span> <span class="n">Korobov</span> <span class="o">&lt;</span><span class="n">kmike84</span><span class="o">@...&gt;</span>
 <span class="mi">12</span> <span class="n">Pedro</span> <span class="n">Faustino</span> <span class="o">&lt;</span><span class="n">pedrobandim</span><span class="o">@...&gt;</span>
 <span class="mi">11</span> <span class="n">Steven</span> <span class="n">Almeroth</span> <span class="o">&lt;</span><span class="n">sroth77</span><span class="o">@...&gt;</span>
  <span class="mi">5</span> <span class="n">Rolando</span> <span class="n">Espinoza</span> <span class="n">La</span> <span class="n">fuente</span> <span class="o">&lt;</span><span class="n">darkrho</span><span class="o">@...&gt;</span>
  <span class="mi">4</span> <span class="n">Michal</span> <span class="n">Danilak</span> <span class="o">&lt;</span><span class="n">mimino</span><span class="o">.</span><span class="n">coder</span><span class="o">@...&gt;</span>
  <span class="mi">4</span> <span class="n">Alex</span> <span class="n">Cepoi</span> <span class="o">&lt;</span><span class="n">alex</span><span class="o">.</span><span class="n">cepoi</span><span class="o">@...&gt;</span>
  <span class="mi">4</span> <span class="n">Alexandr</span> <span class="n">N</span> <span class="n">Zamaraev</span> <span class="p">(</span><span class="n">aka</span> <span class="n">tonal</span><span class="p">)</span> <span class="o">&lt;</span><span class="n">tonal</span><span class="o">@...&gt;</span>
  <span class="mi">3</span> <span class="n">paul</span> <span class="o">&lt;</span><span class="n">paul</span><span class="o">.</span><span class="n">tremberth</span><span class="o">@...&gt;</span>
  <span class="mi">3</span> <span class="n">Martin</span> <span class="n">Olveyra</span> <span class="o">&lt;</span><span class="n">molveyra</span><span class="o">@...&gt;</span>
  <span class="mi">3</span> <span class="n">Jordi</span> <span class="n">Llonch</span> <span class="o">&lt;</span><span class="n">llonchj</span><span class="o">@...&gt;</span>
  <span class="mi">3</span> <span class="n">arijitchakraborty</span> <span class="o">&lt;</span><span class="n">myself</span><span class="o">.</span><span class="n">arijit</span><span class="o">@...&gt;</span>
  <span class="mi">2</span> <span class="n">Shane</span> <span class="n">Evans</span> <span class="o">&lt;</span><span class="n">shane</span><span class="o">.</span><span class="n">evans</span><span class="o">@...&gt;</span>
  <span class="mi">2</span> <span class="n">joehillen</span> <span class="o">&lt;</span><span class="n">joehillen</span><span class="o">@...&gt;</span>
  <span class="mi">2</span> <span class="n">Hart</span> <span class="o">&lt;</span><span class="n">HartSimha</span><span class="o">@...&gt;</span>
  <span class="mi">2</span> <span class="n">Dan</span> <span class="o">&lt;</span><span class="n">ellisd23</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Zuhao</span> <span class="n">Wan</span> <span class="o">&lt;</span><span class="n">wanzuhao</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">whodatninja</span> <span class="o">&lt;</span><span class="n">blake</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">vkrest</span> <span class="o">&lt;</span><span class="n">v</span><span class="o">.</span><span class="n">krestiannykov</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">tpeng</span> <span class="o">&lt;</span><span class="n">pengtaoo</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Tom</span> <span class="n">Mortimer</span><span class="o">-</span><span class="n">Jones</span> <span class="o">&lt;</span><span class="n">tom</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Rocio</span> <span class="n">Aramberri</span> <span class="o">&lt;</span><span class="n">roschegel</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Pedro</span> <span class="o">&lt;</span><span class="n">pedro</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">notsobad</span> <span class="o">&lt;</span><span class="n">wangxiaohugg</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Natan</span> <span class="n">L</span> <span class="o">&lt;</span><span class="n">kuyanatan</span><span class="o">.</span><span class="n">nlao</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Mark</span> <span class="n">Grey</span> <span class="o">&lt;</span><span class="n">mark</span><span class="o">.</span><span class="n">grey</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Luan</span> <span class="o">&lt;</span><span class="n">luanpab</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Libor</span> <span class="n">Nenadál</span> <span class="o">&lt;</span><span class="n">libor</span><span class="o">.</span><span class="n">nenadal</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Juan</span> <span class="n">M</span> <span class="n">Uys</span> <span class="o">&lt;</span><span class="n">opyate</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Jonas</span> <span class="n">Brunsgaard</span> <span class="o">&lt;</span><span class="n">jonas</span><span class="o">.</span><span class="n">brunsgaard</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Ilya</span> <span class="n">Baryshev</span> <span class="o">&lt;</span><span class="n">baryshev</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Hasnain</span> <span class="n">Lakhani</span> <span class="o">&lt;</span><span class="n">m</span><span class="o">.</span><span class="n">hasnain</span><span class="o">.</span><span class="n">lakhani</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Emanuel</span> <span class="n">Schorsch</span> <span class="o">&lt;</span><span class="n">emschorsch</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Chris</span> <span class="n">Tilden</span> <span class="o">&lt;</span><span class="n">chris</span><span class="o">.</span><span class="n">tilden</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Capi</span> <span class="n">Etheriel</span> <span class="o">&lt;</span><span class="n">barraponto</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">cacovsky</span> <span class="o">&lt;</span><span class="n">amarquesferraz</span><span class="o">@...&gt;</span>
  <span class="mi">1</span> <span class="n">Berend</span> <span class="n">Iwema</span> <span class="o">&lt;</span><span class="n">berend</span><span class="o">@...&gt;</span>
</pre></div>
</div>
</div>
<div class="section" id="scrapy-0-16-5-released-2013-05-30">
<h2>Scrapy 0.16.5 (released 2013-05-30)<a class="headerlink" href="#scrapy-0-16-5-released-2013-05-30" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>obey request method when scrapy deploy is redirected to a new endpoint (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8c4fcee">commit 8c4fcee</a>)</li>
<li>fix inaccurate downloader middleware documentation. refs #280 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/40667cb">commit 40667cb</a>)</li>
<li>doc: remove links to diveintopython.org, which is no longer available. closes #246 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bd58bfa">commit bd58bfa</a>)</li>
<li>Find form nodes in invalid html5 documents (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e3d6945">commit e3d6945</a>)</li>
<li>Fix typo labeling attrs type bool instead of list (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a274276">commit a274276</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-16-4-released-2013-01-23">
<h2>Scrapy 0.16.4 (released 2013-01-23)<a class="headerlink" href="#scrapy-0-16-4-released-2013-01-23" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>fixes spelling errors in documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6d2b3aa">commit 6d2b3aa</a>)</li>
<li>add doc about disabling an extension. refs #132 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c90de33">commit c90de33</a>)</li>
<li>Fixed error message formatting. log.err() doesn’t support cool formatting and when error occurred, the message was:    “ERROR: Error processing %(item)s” (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c16150c">commit c16150c</a>)</li>
<li>lint and improve images pipeline error logging (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/56b45fc">commit 56b45fc</a>)</li>
<li>fixed doc typos (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/243be84">commit 243be84</a>)</li>
<li>add documentation topics: Broad Crawls &amp; Common Practies (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1fbb715">commit 1fbb715</a>)</li>
<li>fix bug in scrapy parse command when spider is not specified explicitly. closes #209 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c72e682">commit c72e682</a>)</li>
<li>Update docs/topics/commands.rst (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/28eac7a">commit 28eac7a</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-16-3-released-2012-12-07">
<h2>Scrapy 0.16.3 (released 2012-12-07)<a class="headerlink" href="#scrapy-0-16-3-released-2012-12-07" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Remove concurrency limitation when using download delays and still ensure inter-request delays are enforced (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/487b9b5">commit 487b9b5</a>)</li>
<li>add error details when image pipeline fails (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8232569">commit 8232569</a>)</li>
<li>improve mac os compatibility (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8dcf8aa">commit 8dcf8aa</a>)</li>
<li>setup.py: use README.rst to populate long_description (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7b5310d">commit 7b5310d</a>)</li>
<li>doc: removed obsolete references to ClientForm (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/80f9bb6">commit 80f9bb6</a>)</li>
<li>correct docs for default storage backend (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2aa491b">commit 2aa491b</a>)</li>
<li>doc: removed broken proxyhub link from FAQ (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bdf61c4">commit bdf61c4</a>)</li>
<li>Fixed docs typo in SpiderOpenCloseLogging example (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7184094">commit 7184094</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-16-2-released-2012-11-09">
<h2>Scrapy 0.16.2 (released 2012-11-09)<a class="headerlink" href="#scrapy-0-16-2-released-2012-11-09" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>scrapy contracts: python2.6 compat (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a4a9199">commit a4a9199</a>)</li>
<li>scrapy contracts verbose option (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ec41673">commit ec41673</a>)</li>
<li>proper unittest-like output for scrapy contracts (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/86635e4">commit 86635e4</a>)</li>
<li>added open_in_browser to debugging doc (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c9b690d">commit c9b690d</a>)</li>
<li>removed reference to global scrapy stats from settings doc (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/dd55067">commit dd55067</a>)</li>
<li>Fix SpiderState bug in Windows platforms (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/58998f4">commit 58998f4</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-16-1-released-2012-10-26">
<h2>Scrapy 0.16.1 (released 2012-10-26)<a class="headerlink" href="#scrapy-0-16-1-released-2012-10-26" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>fixed LogStats extension, which got broken after a wrong merge before the 0.16 release (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8c780fd">commit 8c780fd</a>)</li>
<li>better backwards compatibility for scrapy.conf.settings (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3403089">commit 3403089</a>)</li>
<li>extended documentation on how to access crawler stats from extensions (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c4da0b5">commit c4da0b5</a>)</li>
<li>removed .hgtags (no longer needed now that scrapy uses git) (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d52c188">commit d52c188</a>)</li>
<li>fix dashes under rst headers (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fa4f7f9">commit fa4f7f9</a>)</li>
<li>set release date for 0.16.0 in news (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e292246">commit e292246</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-16-0-released-2012-10-18">
<h2>Scrapy 0.16.0 (released 2012-10-18)<a class="headerlink" href="#scrapy-0-16-0-released-2012-10-18" title="Permalink to this headline">¶</a></h2>
<p>Scrapy changes:</p>
<ul class="simple">
<li>added <a class="reference internal" href="topics/contracts.html#topics-contracts"><span class="std std-ref">Spiders Contracts</span></a>, a mechanism for testing spiders in a formal/reproducible way</li>
<li>added options <code class="docutils literal"><span class="pre">-o</span></code> and <code class="docutils literal"><span class="pre">-t</span></code> to the <a class="reference internal" href="topics/commands.html#std:command-runspider"><code class="xref std std-command docutils literal"><span class="pre">runspider</span></code></a> command</li>
<li>documented <a class="reference internal" href="topics/autothrottle.html"><span class="doc">AutoThrottle extension</span></a> and added to extensions installed by default. You still need to enable it with <a class="reference internal" href="topics/autothrottle.html#std:setting-AUTOTHROTTLE_ENABLED"><code class="xref std std-setting docutils literal"><span class="pre">AUTOTHROTTLE_ENABLED</span></code></a></li>
<li>major Stats Collection refactoring: removed separation of global/per-spider stats, removed stats-related signals (<code class="docutils literal"><span class="pre">stats_spider_opened</span></code>, etc). Stats are much simpler now, backwards compatibility is kept on the Stats Collector API and signals.</li>
<li>added <code class="xref py py-meth docutils literal"><span class="pre">process_start_requests()</span></code> method to spider middlewares</li>
<li>dropped Signals singleton. Signals should now be accesed through the Crawler.signals attribute. See the signals documentation for more info.</li>
<li>dropped Signals singleton. Signals should now be accesed through the Crawler.signals attribute. See the signals documentation for more info.</li>
<li>dropped Stats Collector singleton. Stats can now be accessed through the Crawler.stats attribute. See the stats collection documentation for more info.</li>
<li>documented <a class="reference internal" href="topics/api.html#topics-api"><span class="std std-ref">Core API</span></a></li>
<li><cite>lxml</cite> is now the default selectors backend instead of <cite>libxml2</cite></li>
<li>ported FormRequest.from_response() to use <a class="reference external" href="http://lxml.de/">lxml</a> instead of <a class="reference external" href="http://wwwsearch.sourceforge.net/old/ClientForm/">ClientForm</a></li>
<li>removed modules: <code class="docutils literal"><span class="pre">scrapy.xlib.BeautifulSoup</span></code> and <code class="docutils literal"><span class="pre">scrapy.xlib.ClientForm</span></code></li>
<li>SitemapSpider: added support for sitemap urls ending in .xml and .xml.gz, even if they advertise a wrong content type (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/10ed28b">commit 10ed28b</a>)</li>
<li>StackTraceDump extension: also dump trackref live references (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fe2ce93">commit fe2ce93</a>)</li>
<li>nested items now fully supported in JSON and JSONLines exporters</li>
<li>added <a class="reference internal" href="topics/downloader-middleware.html#std:reqmeta-cookiejar"><code class="xref std std-reqmeta docutils literal"><span class="pre">cookiejar</span></code></a> Request meta key to support multiple cookie sessions per spider</li>
<li>decoupled encoding detection code to <a class="reference external" href="https://github.com/scrapy/w3lib/blob/master/w3lib/encoding.py">w3lib.encoding</a>, and ported Scrapy code to use that module</li>
<li>dropped support for Python 2.5. See <a class="reference external" href="https://blog.scrapinghub.com/2012/02/27/scrapy-0-15-dropping-support-for-python-2-5/">https://blog.scrapinghub.com/2012/02/27/scrapy-0-15-dropping-support-for-python-2-5/</a></li>
<li>dropped support for Twisted 2.5</li>
<li>added <a class="reference internal" href="topics/spider-middleware.html#std:setting-REFERER_ENABLED"><code class="xref std std-setting docutils literal"><span class="pre">REFERER_ENABLED</span></code></a> setting, to control referer middleware</li>
<li>changed default user agent to: <code class="docutils literal"><span class="pre">Scrapy/VERSION</span> <span class="pre">(+http://scrapy.org)</span></code></li>
<li>removed (undocumented) <code class="docutils literal"><span class="pre">HTMLImageLinkExtractor</span></code> class from <code class="docutils literal"><span class="pre">scrapy.contrib.linkextractors.image</span></code></li>
<li>removed per-spider settings (to be replaced by instantiating multiple crawler objects)</li>
<li><code class="docutils literal"><span class="pre">USER_AGENT</span></code> spider attribute will no longer work, use <code class="docutils literal"><span class="pre">user_agent</span></code> attribute instead</li>
<li><code class="docutils literal"><span class="pre">DOWNLOAD_TIMEOUT</span></code> spider attribute will no longer work, use <code class="docutils literal"><span class="pre">download_timeout</span></code> attribute instead</li>
<li>removed <code class="docutils literal"><span class="pre">ENCODING_ALIASES</span></code> setting, as encoding auto-detection has been moved to the <a class="reference external" href="https://github.com/scrapy/w3lib">w3lib</a> library</li>
<li>promoted <a class="reference internal" href="topics/djangoitem.html#topics-djangoitem"><span class="std std-ref">DjangoItem</span></a> to main contrib</li>
<li>LogFormatter method now return dicts(instead of strings) to support lazy formatting (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/164">issue 164</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/commit/dcef7b0">commit dcef7b0</a>)</li>
<li>downloader handlers (<a class="reference internal" href="topics/settings.html#std:setting-DOWNLOAD_HANDLERS"><code class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_HANDLERS</span></code></a> setting) now receive settings as the first argument of the constructor</li>
<li>replaced memory usage acounting with (more portable) <a class="reference external" href="https://docs.python.org/2/library/resource.html">resource</a> module, removed <code class="docutils literal"><span class="pre">scrapy.utils.memory</span></code> module</li>
<li>removed signal: <code class="docutils literal"><span class="pre">scrapy.mail.mail_sent</span></code></li>
<li>removed <code class="docutils literal"><span class="pre">TRACK_REFS</span></code> setting, now <a class="reference internal" href="topics/leaks.html#topics-leaks-trackrefs"><span class="std std-ref">trackrefs</span></a> is always enabled</li>
<li>DBM is now the default storage backend for HTTP cache middleware</li>
<li>number of log messages (per level) are now tracked through Scrapy stats (stat name: <code class="docutils literal"><span class="pre">log_count/LEVEL</span></code>)</li>
<li>number received responses are now tracked through Scrapy stats (stat name: <code class="docutils literal"><span class="pre">response_received_count</span></code>)</li>
<li>removed <code class="docutils literal"><span class="pre">scrapy.log.started</span></code> attribute</li>
</ul>
</div>
<div class="section" id="scrapy-0-14-4">
<h2>Scrapy 0.14.4<a class="headerlink" href="#scrapy-0-14-4" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>added precise to supported ubuntu distros (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b7e46df">commit b7e46df</a>)</li>
<li>fixed bug in json-rpc webservice reported in <a class="reference external" href="https://groups.google.com/forum/#!topic/scrapy-users/qgVBmFybNAQ/discussion">https://groups.google.com/forum/#!topic/scrapy-users/qgVBmFybNAQ/discussion</a>. also removed no longer supported ‘run’ command from extras/scrapy-ws.py (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/340fbdb">commit 340fbdb</a>)</li>
<li>meta tag attributes for content-type http equiv can be in any order. #123 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0cb68af">commit 0cb68af</a>)</li>
<li>replace “import Image” by more standard “from PIL import Image”. closes #88 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/4d17048">commit 4d17048</a>)</li>
<li>return trial status as bin/runtests.sh exit value. #118 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b7b2e7f">commit b7b2e7f</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-14-3">
<h2>Scrapy 0.14.3<a class="headerlink" href="#scrapy-0-14-3" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>forgot to include pydispatch license. #118 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fd85f9c">commit fd85f9c</a>)</li>
<li>include egg files used by testsuite in source distribution. #118 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c897793">commit c897793</a>)</li>
<li>update docstring in project template to avoid confusion with genspider command, which may be considered as an advanced feature. refs #107 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2548dcc">commit 2548dcc</a>)</li>
<li>added note to docs/topics/firebug.rst about google directory being shut down (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/668e352">commit 668e352</a>)</li>
<li>dont discard slot when empty, just save in another dict in order to recycle if needed again. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8e9f607">commit 8e9f607</a>)</li>
<li>do not fail handling unicode xpaths in libxml2 backed selectors (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b830e95">commit b830e95</a>)</li>
<li>fixed minor mistake in Request objects documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bf3c9ee">commit bf3c9ee</a>)</li>
<li>fixed minor defect in link extractors documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ba14f38">commit ba14f38</a>)</li>
<li>removed some obsolete remaining code related to sqlite support in scrapy (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0665175">commit 0665175</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-14-2">
<h2>Scrapy 0.14.2<a class="headerlink" href="#scrapy-0-14-2" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>move buffer pointing to start of file before computing checksum. refs #92 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6a5bef2">commit 6a5bef2</a>)</li>
<li>Compute image checksum before persisting images. closes #92 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/9817df1">commit 9817df1</a>)</li>
<li>remove leaking references in cached failures (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/673a120">commit 673a120</a>)</li>
<li>fixed bug in MemoryUsage extension: get_engine_status() takes exactly 1 argument (0 given) (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/11133e9">commit 11133e9</a>)</li>
<li>fixed struct.error on http compression middleware. closes #87 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1423140">commit 1423140</a>)</li>
<li>ajax crawling wasn’t expanding for unicode urls (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0de3fb4">commit 0de3fb4</a>)</li>
<li>Catch start_requests iterator errors. refs #83 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/454a21d">commit 454a21d</a>)</li>
<li>Speed-up libxml2 XPathSelector (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2fbd662">commit 2fbd662</a>)</li>
<li>updated versioning doc according to recent changes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0a070f5">commit 0a070f5</a>)</li>
<li>scrapyd: fixed documentation link (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2b4e4c3">commit 2b4e4c3</a>)</li>
<li>extras/makedeb.py: no longer obtaining version from git (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/caffe0e">commit caffe0e</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-14-1">
<h2>Scrapy 0.14.1<a class="headerlink" href="#scrapy-0-14-1" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>extras/makedeb.py: no longer obtaining version from git (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/caffe0e">commit caffe0e</a>)</li>
<li>bumped version to 0.14.1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6cb9e1c">commit 6cb9e1c</a>)</li>
<li>fixed reference to tutorial directory (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/4b86bd6">commit 4b86bd6</a>)</li>
<li>doc: removed duplicated callback argument from Request.replace() (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1aeccdd">commit 1aeccdd</a>)</li>
<li>fixed formatting of scrapyd doc (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8bf19e6">commit 8bf19e6</a>)</li>
<li>Dump stacks for all running threads and fix engine status dumped by StackTraceDump extension (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/14a8e6e">commit 14a8e6e</a>)</li>
<li>added comment about why we disable ssl on boto images upload (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5223575">commit 5223575</a>)</li>
<li>SSL handshaking hangs when doing too many parallel connections to S3 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/63d583d">commit 63d583d</a>)</li>
<li>change tutorial to follow changes on dmoz site (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bcb3198">commit bcb3198</a>)</li>
<li>Avoid _disconnectedDeferred AttributeError exception in Twisted&gt;=11.1.0 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/98f3f87">commit 98f3f87</a>)</li>
<li>allow spider to set autothrottle max concurrency (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/175a4b5">commit 175a4b5</a>)</li>
</ul>
</div>
<div class="section" id="scrapy-0-14">
<h2>Scrapy 0.14<a class="headerlink" href="#scrapy-0-14" title="Permalink to this headline">¶</a></h2>
<div class="section" id="new-features-and-settings">
<h3>New features and settings<a class="headerlink" href="#new-features-and-settings" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Support for <a class="reference external" href="https://developers.google.com/webmasters/ajax-crawling/docs/getting-started?csw=1">AJAX crawleable urls</a></li>
<li>New persistent scheduler that stores requests on disk, allowing to suspend and resume crawls (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2737">r2737</a>)</li>
<li>added <code class="docutils literal"><span class="pre">-o</span></code> option to <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">crawl</span></code>, a shortcut for dumping scraped items into a file (or standard output using <code class="docutils literal"><span class="pre">-</span></code>)</li>
<li>Added support for passing custom settings to Scrapyd <code class="docutils literal"><span class="pre">schedule.json</span></code> api (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2779">r2779</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2783">r2783</a>)</li>
<li>New <code class="docutils literal"><span class="pre">ChunkedTransferMiddleware</span></code> (enabled by default) to support <a class="reference external" href="https://en.wikipedia.org/wiki/Chunked_transfer_encoding">chunked transfer encoding</a> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2769">r2769</a>)</li>
<li>Add boto 2.0 support for S3 downloader handler (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2763">r2763</a>)</li>
<li>Added <a class="reference external" href="https://docs.python.org/2/library/marshal.html">marshal</a> to formats supported by feed exports (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2744">r2744</a>)</li>
<li>In request errbacks, offending requests are now received in <cite>failure.request</cite> attribute (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2738">r2738</a>)</li>
<li><dl class="first docutils">
<dt>Big downloader refactoring to support per domain/ip concurrency limits (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2732">r2732</a>)</dt>
<dd><ul class="first last">
<li><dl class="first docutils">
<dt><code class="docutils literal"><span class="pre">CONCURRENT_REQUESTS_PER_SPIDER</span></code> setting has been deprecated and replaced by:</dt>
<dd><ul class="first last">
<li><a class="reference internal" href="topics/settings.html#std:setting-CONCURRENT_REQUESTS"><code class="xref std std-setting docutils literal"><span class="pre">CONCURRENT_REQUESTS</span></code></a>, <a class="reference internal" href="topics/settings.html#std:setting-CONCURRENT_REQUESTS_PER_DOMAIN"><code class="xref std std-setting docutils literal"><span class="pre">CONCURRENT_REQUESTS_PER_DOMAIN</span></code></a>, <a class="reference internal" href="topics/settings.html#std:setting-CONCURRENT_REQUESTS_PER_IP"><code class="xref std std-setting docutils literal"><span class="pre">CONCURRENT_REQUESTS_PER_IP</span></code></a></li>
</ul>
</dd>
</dl>
</li>
<li>check the documentation for more details</li>
</ul>
</dd>
</dl>
</li>
<li>Added builtin caching DNS resolver (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2728">r2728</a>)</li>
<li>Moved Amazon AWS-related components/extensions (SQS spider queue, SimpleDB stats collector) to a separate project: [scaws](<a class="reference external" href="https://github.com/scrapinghub/scaws">https://github.com/scrapinghub/scaws</a>) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2706">r2706</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2714">r2714</a>)</li>
<li>Moved spider queues to scrapyd: <cite>scrapy.spiderqueue</cite> -&gt; <cite>scrapyd.spiderqueue</cite> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2708">r2708</a>)</li>
<li>Moved sqlite utils to scrapyd: <cite>scrapy.utils.sqlite</cite> -&gt; <cite>scrapyd.sqlite</cite> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2781">r2781</a>)</li>
<li>Real support for returning iterators on <cite>start_requests()</cite> method. The iterator is now consumed during the crawl when the spider is getting idle (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2704">r2704</a>)</li>
<li>Added <a class="reference internal" href="topics/downloader-middleware.html#std:setting-REDIRECT_ENABLED"><code class="xref std std-setting docutils literal"><span class="pre">REDIRECT_ENABLED</span></code></a> setting to quickly enable/disable the redirect middleware (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2697">r2697</a>)</li>
<li>Added <a class="reference internal" href="topics/downloader-middleware.html#std:setting-RETRY_ENABLED"><code class="xref std std-setting docutils literal"><span class="pre">RETRY_ENABLED</span></code></a> setting to quickly enable/disable the retry middleware (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2694">r2694</a>)</li>
<li>Added <code class="docutils literal"><span class="pre">CloseSpider</span></code> exception to manually close spiders (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2691">r2691</a>)</li>
<li>Improved encoding detection by adding support for HTML5 meta charset declaration (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2690">r2690</a>)</li>
<li>Refactored close spider behavior to wait for all downloads to finish and be processed by spiders, before closing the spider (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2688">r2688</a>)</li>
<li>Added <code class="docutils literal"><span class="pre">SitemapSpider</span></code> (see documentation in Spiders page) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2658">r2658</a>)</li>
<li>Added <code class="docutils literal"><span class="pre">LogStats</span></code> extension for periodically logging basic stats (like crawled pages and scraped items) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2657">r2657</a>)</li>
<li>Make handling of gzipped responses more robust (#319, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2643">r2643</a>). Now Scrapy will try and decompress as much as possible from a gzipped response, instead of failing with an <cite>IOError</cite>.</li>
<li>Simplified !MemoryDebugger extension to use stats for dumping memory debugging info (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2639">r2639</a>)</li>
<li>Added new command to edit spiders: <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">edit</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2636">r2636</a>) and <cite>-e</cite> flag to <cite>genspider</cite> command that uses it (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2653">r2653</a>)</li>
<li>Changed default representation of items to pretty-printed dicts. (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2631">r2631</a>). This improves default logging by making log more readable in the default case, for both Scraped and Dropped lines.</li>
<li>Added <a class="reference internal" href="topics/signals.html#std:signal-spider_error"><code class="xref std std-signal docutils literal"><span class="pre">spider_error</span></code></a> signal (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2628">r2628</a>)</li>
<li>Added <a class="reference internal" href="topics/downloader-middleware.html#std:setting-COOKIES_ENABLED"><code class="xref std std-setting docutils literal"><span class="pre">COOKIES_ENABLED</span></code></a> setting (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2625">r2625</a>)</li>
<li>Stats are now dumped to Scrapy log (default value of <a class="reference internal" href="topics/settings.html#std:setting-STATS_DUMP"><code class="xref std std-setting docutils literal"><span class="pre">STATS_DUMP</span></code></a> setting has been changed to <cite>True</cite>). This is to make Scrapy users more aware of Scrapy stats and the data that is collected there.</li>
<li>Added support for dynamically adjusting download delay and maximum concurrent requests (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2599">r2599</a>)</li>
<li>Added new DBM HTTP cache storage backend (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2576">r2576</a>)</li>
<li>Added <code class="docutils literal"><span class="pre">listjobs.json</span></code> API to Scrapyd (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2571">r2571</a>)</li>
<li><code class="docutils literal"><span class="pre">CsvItemExporter</span></code>: added <code class="docutils literal"><span class="pre">join_multivalued</span></code> parameter (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2578">r2578</a>)</li>
<li>Added namespace support to <code class="docutils literal"><span class="pre">xmliter_lxml</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2552">r2552</a>)</li>
<li>Improved cookies middleware by making <cite>COOKIES_DEBUG</cite> nicer and documenting it (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2579">r2579</a>)</li>
<li>Several improvements to Scrapyd and Link extractors</li>
</ul>
</div>
<div class="section" id="code-rearranged-and-removed">
<h3>Code rearranged and removed<a class="headerlink" href="#code-rearranged-and-removed" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><dl class="first docutils">
<dt>Merged item passed and item scraped concepts, as they have often proved confusing in the past. This means: (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2630">r2630</a>)</dt>
<dd><ul class="first last">
<li>original item_scraped signal was removed</li>
<li>original item_passed signal was renamed to item_scraped</li>
<li>old log lines <code class="docutils literal"><span class="pre">Scraped</span> <span class="pre">Item...</span></code> were removed</li>
<li>old log lines <code class="docutils literal"><span class="pre">Passed</span> <span class="pre">Item...</span></code> were renamed to <code class="docutils literal"><span class="pre">Scraped</span> <span class="pre">Item...</span></code> lines and downgraded to <code class="docutils literal"><span class="pre">DEBUG</span></code> level</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Reduced Scrapy codebase by striping part of Scrapy code into two new libraries:</dt>
<dd><ul class="first last">
<li><a class="reference external" href="https://github.com/scrapy/w3lib">w3lib</a> (several functions from <code class="docutils literal"><span class="pre">scrapy.utils.{http,markup,multipart,response,url}</span></code>, done in <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2584">r2584</a>)</li>
<li><a class="reference external" href="https://github.com/scrapy/scrapely">scrapely</a> (was <code class="docutils literal"><span class="pre">scrapy.contrib.ibl</span></code>, done in <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2586">r2586</a>)</li>
</ul>
</dd>
</dl>
</li>
<li>Removed unused function: <cite>scrapy.utils.request.request_info()</cite> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2577">r2577</a>)</li>
<li>Removed googledir project from <cite>examples/googledir</cite>. There’s now a new example project called <cite>dirbot</cite> available on github: <a class="reference external" href="https://github.com/scrapy/dirbot">https://github.com/scrapy/dirbot</a></li>
<li>Removed support for default field values in Scrapy items (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2616">r2616</a>)</li>
<li>Removed experimental crawlspider v2 (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2632">r2632</a>)</li>
<li>Removed scheduler middleware to simplify architecture. Duplicates filter is now done in the scheduler itself, using the same dupe fltering class as before (<cite>DUPEFILTER_CLASS</cite> setting) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2640">r2640</a>)</li>
<li>Removed support for passing urls to <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">crawl</span></code> command (use <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">parse</span></code> instead) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2704">r2704</a>)</li>
<li>Removed deprecated Execution Queue (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2704">r2704</a>)</li>
<li>Removed (undocumented) spider context extension (from scrapy.contrib.spidercontext) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2780">r2780</a>)</li>
<li>removed <code class="docutils literal"><span class="pre">CONCURRENT_SPIDERS</span></code> setting (use scrapyd maxproc instead) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2789">r2789</a>)</li>
<li>Renamed attributes of core components: downloader.sites -&gt; downloader.slots, scraper.sites -&gt; scraper.slots (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2717">r2717</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2718">r2718</a>)</li>
<li>Renamed setting <code class="docutils literal"><span class="pre">CLOSESPIDER_ITEMPASSED</span></code> to <a class="reference internal" href="topics/extensions.html#std:setting-CLOSESPIDER_ITEMCOUNT"><code class="xref std std-setting docutils literal"><span class="pre">CLOSESPIDER_ITEMCOUNT</span></code></a> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2655">r2655</a>). Backwards compatibility kept.</li>
</ul>
</div>
</div>
<div class="section" id="scrapy-0-12">
<h2>Scrapy 0.12<a class="headerlink" href="#scrapy-0-12" title="Permalink to this headline">¶</a></h2>
<p>The numbers like #NNN reference tickets in the old issue tracker (Trac) which is no longer available.</p>
<div class="section" id="new-features-and-improvements">
<h3>New features and improvements<a class="headerlink" href="#new-features-and-improvements" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Passed item is now sent in the <code class="docutils literal"><span class="pre">item</span></code> argument of the <code class="xref std std-signal docutils literal"><span class="pre">item_passed</span></code> (#273)</li>
<li>Added verbose option to <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">version</span></code> command, useful for bug reports (#298)</li>
<li>HTTP cache now stored by default in the project data dir (#279)</li>
<li>Added project data storage directory (#276, #277)</li>
<li>Documented file structure of Scrapy projects (see command-line tool doc)</li>
<li>New lxml backend for XPath selectors (#147)</li>
<li>Per-spider settings (#245)</li>
<li>Support exit codes to signal errors in Scrapy commands (#248)</li>
<li>Added <code class="docutils literal"><span class="pre">-c</span></code> argument to <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">shell</span></code> command</li>
<li>Made <code class="docutils literal"><span class="pre">libxml2</span></code> optional (#260)</li>
<li>New <code class="docutils literal"><span class="pre">deploy</span></code> command (#261)</li>
<li>Added <a class="reference internal" href="topics/extensions.html#std:setting-CLOSESPIDER_PAGECOUNT"><code class="xref std std-setting docutils literal"><span class="pre">CLOSESPIDER_PAGECOUNT</span></code></a> setting (#253)</li>
<li>Added <a class="reference internal" href="topics/extensions.html#std:setting-CLOSESPIDER_ERRORCOUNT"><code class="xref std std-setting docutils literal"><span class="pre">CLOSESPIDER_ERRORCOUNT</span></code></a> setting (#254)</li>
</ul>
</div>
<div class="section" id="scrapyd-changes">
<h3>Scrapyd changes<a class="headerlink" href="#scrapyd-changes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Scrapyd now uses one process per spider</li>
<li>It stores one log file per spider run, and rotate them keeping the lastest 5 logs per spider (by default)</li>
<li>A minimal web ui was added, available at <a class="reference external" href="http://localhost:6800">http://localhost:6800</a> by default</li>
<li>There is now a <cite>scrapy server</cite> command to start a Scrapyd server of the current project</li>
</ul>
</div>
<div class="section" id="changes-to-settings">
<h3>Changes to settings<a class="headerlink" href="#changes-to-settings" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>added <cite>HTTPCACHE_ENABLED</cite> setting (False by default) to enable HTTP cache middleware</li>
<li>changed <cite>HTTPCACHE_EXPIRATION_SECS</cite> semantics: now zero means “never expire”.</li>
</ul>
</div>
<div class="section" id="deprecated-obsoleted-functionality">
<h3>Deprecated/obsoleted functionality<a class="headerlink" href="#deprecated-obsoleted-functionality" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Deprecated <code class="docutils literal"><span class="pre">runserver</span></code> command in favor of <code class="docutils literal"><span class="pre">server</span></code> command which starts a Scrapyd server. See also: Scrapyd changes</li>
<li>Deprecated <code class="docutils literal"><span class="pre">queue</span></code> command in favor of using Scrapyd <code class="docutils literal"><span class="pre">schedule.json</span></code> API. See also: Scrapyd changes</li>
<li>Removed the !LxmlItemLoader (experimental contrib which never graduated to main contrib)</li>
</ul>
</div>
</div>
<div class="section" id="scrapy-0-10">
<h2>Scrapy 0.10<a class="headerlink" href="#scrapy-0-10" title="Permalink to this headline">¶</a></h2>
<p>The numbers like #NNN reference tickets in the old issue tracker (Trac) which is no longer available.</p>
<div class="section" id="id16">
<h3>New features and improvements<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>New Scrapy service called <code class="docutils literal"><span class="pre">scrapyd</span></code> for deploying Scrapy crawlers in production (#218) (documentation available)</li>
<li>Simplified Images pipeline usage which doesn’t require subclassing your own images pipeline now (#217)</li>
<li>Scrapy shell now shows the Scrapy log by default (#206)</li>
<li>Refactored execution queue in a common base code and pluggable backends called “spider queues” (#220)</li>
<li>New persistent spider queue (based on SQLite) (#198), available by default, which allows to start Scrapy in server mode and then schedule spiders to run.</li>
<li>Added documentation for Scrapy command-line tool and all its available sub-commands. (documentation available)</li>
<li>Feed exporters with pluggable backends (#197) (documentation available)</li>
<li>Deferred signals (#193)</li>
<li>Added two new methods to item pipeline open_spider(), close_spider() with deferred support (#195)</li>
<li>Support for overriding default request headers per spider (#181)</li>
<li>Replaced default Spider Manager with one with similar functionality but not depending on Twisted Plugins (#186)</li>
<li>Splitted Debian package into two packages - the library and the service (#187)</li>
<li>Scrapy log refactoring (#188)</li>
<li>New extension for keeping persistent spider contexts among different runs (#203)</li>
<li>Added <cite>dont_redirect</cite> request.meta key for avoiding redirects (#233)</li>
<li>Added <cite>dont_retry</cite> request.meta key for avoiding retries (#234)</li>
</ul>
</div>
<div class="section" id="command-line-tool-changes">
<h3>Command-line tool changes<a class="headerlink" href="#command-line-tool-changes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>New <cite>scrapy</cite> command which replaces the old <cite>scrapy-ctl.py</cite> (#199)
- there is only one global <cite>scrapy</cite> command now, instead of one <cite>scrapy-ctl.py</cite> per project
- Added <cite>scrapy.bat</cite> script for running more conveniently from Windows</li>
<li>Added bash completion to command-line tool (#210)</li>
<li>Renamed command <cite>start</cite> to <cite>runserver</cite> (#209)</li>
</ul>
</div>
<div class="section" id="api-changes">
<h3>API changes<a class="headerlink" href="#api-changes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">url</span></code> and <code class="docutils literal"><span class="pre">body</span></code> attributes of Request objects are now read-only (#230)</li>
<li><code class="docutils literal"><span class="pre">Request.copy()</span></code> and <code class="docutils literal"><span class="pre">Request.replace()</span></code> now also copies their <code class="docutils literal"><span class="pre">callback</span></code> and <code class="docutils literal"><span class="pre">errback</span></code> attributes (#231)</li>
<li>Removed <code class="docutils literal"><span class="pre">UrlFilterMiddleware</span></code> from <code class="docutils literal"><span class="pre">scrapy.contrib</span></code> (already disabled by default)</li>
<li>Offsite middelware doesn’t filter out any request coming from a spider that doesn’t have a allowed_domains attribute (#225)</li>
<li>Removed Spider Manager <code class="docutils literal"><span class="pre">load()</span></code> method. Now spiders are loaded in the constructor itself.</li>
<li><dl class="first docutils">
<dt>Changes to Scrapy Manager (now called “Crawler”):</dt>
<dd><ul class="first last">
<li><code class="docutils literal"><span class="pre">scrapy.core.manager.ScrapyManager</span></code> class renamed to <code class="docutils literal"><span class="pre">scrapy.crawler.Crawler</span></code></li>
<li><code class="docutils literal"><span class="pre">scrapy.core.manager.scrapymanager</span></code> singleton moved to <code class="docutils literal"><span class="pre">scrapy.project.crawler</span></code></li>
</ul>
</dd>
</dl>
</li>
<li>Moved module: <code class="docutils literal"><span class="pre">scrapy.contrib.spidermanager</span></code> to <code class="docutils literal"><span class="pre">scrapy.spidermanager</span></code></li>
<li>Spider Manager singleton moved from <code class="docutils literal"><span class="pre">scrapy.spider.spiders</span></code> to the <code class="docutils literal"><span class="pre">spiders`</span> <span class="pre">attribute</span> <span class="pre">of</span> <span class="pre">``scrapy.project.crawler</span></code> singleton.</li>
<li><dl class="first docutils">
<dt>moved Stats Collector classes: (#204)</dt>
<dd><ul class="first last">
<li><code class="docutils literal"><span class="pre">scrapy.stats.collector.StatsCollector</span></code> to <code class="docutils literal"><span class="pre">scrapy.statscol.StatsCollector</span></code></li>
<li><code class="docutils literal"><span class="pre">scrapy.stats.collector.SimpledbStatsCollector</span></code> to <code class="docutils literal"><span class="pre">scrapy.contrib.statscol.SimpledbStatsCollector</span></code></li>
</ul>
</dd>
</dl>
</li>
<li>default per-command settings are now specified in the <code class="docutils literal"><span class="pre">default_settings</span></code> attribute of command object class (#201)</li>
<li><dl class="first docutils">
<dt>changed arguments of Item pipeline <code class="docutils literal"><span class="pre">process_item()</span></code> method from <code class="docutils literal"><span class="pre">(spider,</span> <span class="pre">item)</span></code> to <code class="docutils literal"><span class="pre">(item,</span> <span class="pre">spider)</span></code></dt>
<dd><ul class="first last">
<li>backwards compatibility kept (with deprecation warning)</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>moved <code class="docutils literal"><span class="pre">scrapy.core.signals</span></code> module to <code class="docutils literal"><span class="pre">scrapy.signals</span></code></dt>
<dd><ul class="first last">
<li>backwards compatibility kept (with deprecation warning)</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>moved <code class="docutils literal"><span class="pre">scrapy.core.exceptions</span></code> module to <code class="docutils literal"><span class="pre">scrapy.exceptions</span></code></dt>
<dd><ul class="first last">
<li>backwards compatibility kept (with deprecation warning)</li>
</ul>
</dd>
</dl>
</li>
<li>added <code class="docutils literal"><span class="pre">handles_request()</span></code> class method to <code class="docutils literal"><span class="pre">BaseSpider</span></code></li>
<li>dropped <code class="docutils literal"><span class="pre">scrapy.log.exc()</span></code> function (use <code class="docutils literal"><span class="pre">scrapy.log.err()</span></code> instead)</li>
<li>dropped <code class="docutils literal"><span class="pre">component</span></code> argument of <code class="docutils literal"><span class="pre">scrapy.log.msg()</span></code> function</li>
<li>dropped <code class="docutils literal"><span class="pre">scrapy.log.log_level</span></code> attribute</li>
<li>Added <code class="docutils literal"><span class="pre">from_settings()</span></code> class methods to Spider Manager, and Item Pipeline Manager</li>
</ul>
</div>
<div class="section" id="id17">
<h3>Changes to settings<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Added <code class="docutils literal"><span class="pre">HTTPCACHE_IGNORE_SCHEMES</span></code> setting to ignore certain schemes on !HttpCacheMiddleware (#225)</li>
<li>Added <code class="docutils literal"><span class="pre">SPIDER_QUEUE_CLASS</span></code> setting which defines the spider queue to use (#220)</li>
<li>Added <code class="docutils literal"><span class="pre">KEEP_ALIVE</span></code> setting (#220)</li>
<li>Removed <code class="docutils literal"><span class="pre">SERVICE_QUEUE</span></code> setting (#220)</li>
<li>Removed <code class="docutils literal"><span class="pre">COMMANDS_SETTINGS_MODULE</span></code> setting (#201)</li>
<li>Renamed <code class="docutils literal"><span class="pre">REQUEST_HANDLERS</span></code> to <code class="docutils literal"><span class="pre">DOWNLOAD_HANDLERS</span></code> and make download handlers classes (instead of functions)</li>
</ul>
</div>
</div>
<div class="section" id="scrapy-0-9">
<h2>Scrapy 0.9<a class="headerlink" href="#scrapy-0-9" title="Permalink to this headline">¶</a></h2>
<p>The numbers like #NNN reference tickets in the old issue tracker (Trac) which is no longer available.</p>
<div class="section" id="id18">
<h3>New features and improvements<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Added SMTP-AUTH support to scrapy.mail</li>
<li>New settings added: <code class="docutils literal"><span class="pre">MAIL_USER</span></code>, <code class="docutils literal"><span class="pre">MAIL_PASS</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2065">r2065</a> | #149)</li>
<li>Added new scrapy-ctl view command - To view URL in the browser, as seen by Scrapy (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2039">r2039</a>)</li>
<li>Added web service for controlling Scrapy process (this also deprecates the web console. (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2053">r2053</a> | #167)</li>
<li>Support for running Scrapy as a service, for production systems (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1988">r1988</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2054">r2054</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2055">r2055</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2056">r2056</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2057">r2057</a> | #168)</li>
<li>Added wrapper induction library (documentation only available in source code for now). (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2011">r2011</a>)</li>
<li>Simplified and improved response encoding support (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1961">r1961</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1969">r1969</a>)</li>
<li>Added <code class="docutils literal"><span class="pre">LOG_ENCODING</span></code> setting (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1956">r1956</a>, documentation available)</li>
<li>Added <code class="docutils literal"><span class="pre">RANDOMIZE_DOWNLOAD_DELAY</span></code> setting (enabled by default) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1923">r1923</a>, doc available)</li>
<li><code class="docutils literal"><span class="pre">MailSender</span></code> is no longer IO-blocking (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1955">r1955</a> | #146)</li>
<li>Linkextractors and new Crawlspider now handle relative base tag urls (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1960">r1960</a> | #148)</li>
<li>Several improvements to Item Loaders and processors (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2022">r2022</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2023">r2023</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2024">r2024</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2025">r2025</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2026">r2026</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2027">r2027</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2028">r2028</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2029">r2029</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2030">r2030</a>)</li>
<li>Added support for adding variables to telnet console (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2047">r2047</a> | #165)</li>
<li>Support for requests without callbacks (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2050">r2050</a> | #166)</li>
</ul>
</div>
<div class="section" id="id19">
<h3>API changes<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Change <code class="docutils literal"><span class="pre">Spider.domain_name</span></code> to <code class="docutils literal"><span class="pre">Spider.name</span></code> (SEP-012, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1975">r1975</a>)</li>
<li><code class="docutils literal"><span class="pre">Response.encoding</span></code> is now the detected encoding (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1961">r1961</a>)</li>
<li><code class="docutils literal"><span class="pre">HttpErrorMiddleware</span></code> now returns None or raises an exception (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2006">r2006</a> | #157)</li>
<li><code class="docutils literal"><span class="pre">scrapy.command</span></code> modules relocation (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2035">r2035</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2036">r2036</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2037">r2037</a>)</li>
<li>Added <code class="docutils literal"><span class="pre">ExecutionQueue</span></code> for feeding spiders to scrape (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2034">r2034</a>)</li>
<li>Removed <code class="docutils literal"><span class="pre">ExecutionEngine</span></code> singleton (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2039">r2039</a>)</li>
<li>Ported <code class="docutils literal"><span class="pre">S3ImagesStore</span></code> (images pipeline) to use boto and threads (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2033">r2033</a>)</li>
<li>Moved module: <code class="docutils literal"><span class="pre">scrapy.management.telnet</span></code> to <code class="docutils literal"><span class="pre">scrapy.telnet</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2047">r2047</a>)</li>
</ul>
</div>
<div class="section" id="changes-to-default-settings">
<h3>Changes to default settings<a class="headerlink" href="#changes-to-default-settings" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Changed default <code class="docutils literal"><span class="pre">SCHEDULER_ORDER</span></code> to <code class="docutils literal"><span class="pre">DFO</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1939">r1939</a>)</li>
</ul>
</div>
</div>
<div class="section" id="scrapy-0-8">
<h2>Scrapy 0.8<a class="headerlink" href="#scrapy-0-8" title="Permalink to this headline">¶</a></h2>
<p>The numbers like #NNN reference tickets in the old issue tracker (Trac) which is no longer available.</p>
<div class="section" id="id20">
<h3>New features<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Added DEFAULT_RESPONSE_ENCODING setting (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1809">r1809</a>)</li>
<li>Added <code class="docutils literal"><span class="pre">dont_click</span></code> argument to <code class="docutils literal"><span class="pre">FormRequest.from_response()</span></code> method (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1813">r1813</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1816">r1816</a>)</li>
<li>Added <code class="docutils literal"><span class="pre">clickdata</span></code> argument to <code class="docutils literal"><span class="pre">FormRequest.from_response()</span></code> method (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1802">r1802</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1803">r1803</a>)</li>
<li>Added support for HTTP proxies (<code class="docutils literal"><span class="pre">HttpProxyMiddleware</span></code>) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1781">r1781</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1785">r1785</a>)</li>
<li>Offsite spider middleware now logs messages when filtering out requests (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1841">r1841</a>)</li>
</ul>
</div>
<div class="section" id="backwards-incompatible-changes">
<h3>Backwards-incompatible changes<a class="headerlink" href="#backwards-incompatible-changes" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Changed <code class="docutils literal"><span class="pre">scrapy.utils.response.get_meta_refresh()</span></code> signature (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1804">r1804</a>)</li>
<li>Removed deprecated <code class="docutils literal"><span class="pre">scrapy.item.ScrapedItem</span></code> class - use <code class="docutils literal"><span class="pre">scrapy.item.Item</span> <span class="pre">instead</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1838">r1838</a>)</li>
<li>Removed deprecated <code class="docutils literal"><span class="pre">scrapy.xpath</span></code> module - use <code class="docutils literal"><span class="pre">scrapy.selector</span></code> instead. (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1836">r1836</a>)</li>
<li>Removed deprecated <code class="docutils literal"><span class="pre">core.signals.domain_open</span></code> signal - use <code class="docutils literal"><span class="pre">core.signals.domain_opened</span></code> instead (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1822">r1822</a>)</li>
<li><dl class="first docutils">
<dt><code class="docutils literal"><span class="pre">log.msg()</span></code> now receives a <code class="docutils literal"><span class="pre">spider</span></code> argument (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1822">r1822</a>)</dt>
<dd><ul class="first last">
<li>Old domain argument has been deprecated and will be removed in 0.9. For spiders, you should always use the <code class="docutils literal"><span class="pre">spider</span></code> argument and pass spider references. If you really want to pass a string, use the <code class="docutils literal"><span class="pre">component</span></code> argument instead.</li>
</ul>
</dd>
</dl>
</li>
<li>Changed core signals <code class="docutils literal"><span class="pre">domain_opened</span></code>, <code class="docutils literal"><span class="pre">domain_closed</span></code>, <code class="docutils literal"><span class="pre">domain_idle</span></code></li>
<li><dl class="first docutils">
<dt>Changed Item pipeline to use spiders instead of domains</dt>
<dd><ul class="first last">
<li>The <code class="docutils literal"><span class="pre">domain</span></code> argument of  <code class="docutils literal"><span class="pre">process_item()</span></code> item pipeline method was changed to  <code class="docutils literal"><span class="pre">spider</span></code>, the new signature is: <code class="docutils literal"><span class="pre">process_item(spider,</span> <span class="pre">item)</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1827">r1827</a> | #105)</li>
<li>To quickly port your code (to work with Scrapy 0.8) just use <code class="docutils literal"><span class="pre">spider.domain_name</span></code> where you previously used <code class="docutils literal"><span class="pre">domain</span></code>.</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Changed Stats API to use spiders instead of domains (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1849">r1849</a> | #113)</dt>
<dd><ul class="first last">
<li><code class="docutils literal"><span class="pre">StatsCollector</span></code> was changed to receive spider references (instead of domains) in its methods (<code class="docutils literal"><span class="pre">set_value</span></code>, <code class="docutils literal"><span class="pre">inc_value</span></code>, etc).</li>
<li>added <code class="docutils literal"><span class="pre">StatsCollector.iter_spider_stats()</span></code> method</li>
<li>removed <code class="docutils literal"><span class="pre">StatsCollector.list_domains()</span></code> method</li>
<li>Also, Stats signals were renamed and now pass around spider references (instead of domains). Here’s a summary of the changes:</li>
<li>To quickly port your code (to work with Scrapy 0.8) just use <code class="docutils literal"><span class="pre">spider.domain_name</span></code> where you previously used <code class="docutils literal"><span class="pre">domain</span></code>. <code class="docutils literal"><span class="pre">spider_stats</span></code> contains exactly the same data as <code class="docutils literal"><span class="pre">domain_stats</span></code>.</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><code class="docutils literal"><span class="pre">CloseDomain</span></code> extension moved to <code class="docutils literal"><span class="pre">scrapy.contrib.closespider.CloseSpider</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1833">r1833</a>)</dt>
<dd><ul class="first last">
<li><dl class="first docutils">
<dt>Its settings were also renamed:</dt>
<dd><ul class="first last">
<li><code class="docutils literal"><span class="pre">CLOSEDOMAIN_TIMEOUT</span></code> to <code class="docutils literal"><span class="pre">CLOSESPIDER_TIMEOUT</span></code></li>
<li><code class="docutils literal"><span class="pre">CLOSEDOMAIN_ITEMCOUNT</span></code> to <code class="docutils literal"><span class="pre">CLOSESPIDER_ITEMCOUNT</span></code></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li>Removed deprecated <code class="docutils literal"><span class="pre">SCRAPYSETTINGS_MODULE</span></code> environment variable - use <code class="docutils literal"><span class="pre">SCRAPY_SETTINGS_MODULE</span></code> instead (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1840">r1840</a>)</li>
<li>Renamed setting: <code class="docutils literal"><span class="pre">REQUESTS_PER_DOMAIN</span></code> to <code class="docutils literal"><span class="pre">CONCURRENT_REQUESTS_PER_SPIDER</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1830">r1830</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1844">r1844</a>)</li>
<li>Renamed setting: <code class="docutils literal"><span class="pre">CONCURRENT_DOMAINS</span></code> to <code class="docutils literal"><span class="pre">CONCURRENT_SPIDERS</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1830">r1830</a>)</li>
<li>Refactored HTTP Cache middleware</li>
<li>HTTP Cache middleware has been heavilty refactored, retaining the same functionality except for the domain sectorization which was removed. (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1843">r1843</a> )</li>
<li>Renamed exception: <code class="docutils literal"><span class="pre">DontCloseDomain</span></code> to <code class="docutils literal"><span class="pre">DontCloseSpider</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1859">r1859</a> | #120)</li>
<li>Renamed extension: <code class="docutils literal"><span class="pre">DelayedCloseDomain</span></code> to <code class="docutils literal"><span class="pre">SpiderCloseDelay</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1861">r1861</a> | #121)</li>
<li>Removed obsolete <code class="docutils literal"><span class="pre">scrapy.utils.markup.remove_escape_chars</span></code> function - use <code class="docutils literal"><span class="pre">scrapy.utils.markup.replace_escape_chars</span></code> instead (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1865">r1865</a>)</li>
</ul>
</div>
</div>
<div class="section" id="scrapy-0-7">
<h2>Scrapy 0.7<a class="headerlink" href="#scrapy-0-7" title="Permalink to this headline">¶</a></h2>
<p>First release of Scrapy.</p>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="contributing.html" class="btn btn-neutral float-right" title="Contributing to Scrapy" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="topics/exporters.html" class="btn btn-neutral" title="Item Exporters" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr /><div><div id="rtd-cqgng86p" class="ethical-rtd"></div></div>

  <div role="contentinfo">
    <p>
        © Copyright 2008-2016, Scrapy developers.
      
        <span class="commit">
          Revision <code>bfd23f42</code>.
        </span>
      

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: 1.2
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions"><!-- Inserted RTD Footer -->
<div class="injected">

  

      
      
      
      <dl>
        <dt>Versions</dt>
        
        
        <dd><a href="https://docs.scrapy.org/en/latest/news.html">latest</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.6/news.html">1.6</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.5/news.html">1.5</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.4/news.html">1.4</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.3/news.html">1.3</a></dd>
        
        
         <strong> 
        <dd><a href="https://docs.scrapy.org/en/1.2/news.html">1.2</a></dd>
         </strong> 
        
        
        <dd><a href="https://docs.scrapy.org/en/1.1/news.html">1.1</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.0/news.html">1.0</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.24/news.html">0.24</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.22/news.html">0.22</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.20/news.html">0.20</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/master/news.html">master</a></dd>
        
        
      </dl>
      
      

      
      
      <dl>
        <dt>Downloads</dt>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/pdf/1.2/">PDF</a></dd>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/htmlzip/1.2/">HTML</a></dd>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/epub/1.2/">Epub</a></dd>
        
      </dl>
      
      

      
      <dl>
        <!-- These are kept as relative links for internal installs that are http -->
        <dt>On Read the Docs</dt>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/">Project Home</a>
        </dd>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/builds/">Builds</a>
        </dd>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/downloads/">Downloads</a>
        </dd>
      </dl>
      

      

      
      <dl>
        <dt>On GitHub</dt>
        <dd>
          <a href="https://github.com/scrapy/scrapy/blob/1.2/docs/news.rst">View</a>
        </dd>
        
        <dd>
          <a href="https://github.com/scrapy/scrapy/edit/1.2/docs/news.rst">Edit</a>
        </dd>
        
      </dl>
      
      

      
      <dl>
        <dt>Search</dt>
        <dd>
          <div style="padding: 6px;">
            <form id="flyout-search-form" class="wy-form" target="_blank" action="//readthedocs.org/projects/scrapy/search/" method="get">
              <input type="text" name="q" placeholder="Search docs" />
              </form>
          </div>
        </dd>
      </dl>
      



      <hr />
      
        <small>
          <span>Hosted by <a href="https://readthedocs.org">Read the Docs</a></span>
          <span> · </span>
          <a href="https://docs.readthedocs.io/page/privacy-policy.html">Privacy Policy</a>
        </small>
      

      

</div>
</div>
  </div>



  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'1.2.3',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-2.0.3.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-migrate-1.2.1.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/underscore.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/doctools.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/readthedocs-doc-embed.js"></script>

  

  
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
 
<script type="text/javascript">
!function(){var analytics=window.analytics=window.analytics||[];if(!analytics.initialize)if(analytics.invoked)window.console&amp;&amp;console.error&amp;&amp;console.error("Segment snippet included twice.");else{analytics.invoked=!0;analytics.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","page","once","off","on"];analytics.factory=function(t){return function(){var e=Array.prototype.slice.call(arguments);e.unshift(t);analytics.push(e);return analytics}};for(var t=0;t&lt;analytics.methods.length;t++){var e=analytics.methods[t];analytics[e]=analytics.factory(e)}analytics.load=function(t){var e=document.createElement("script");e.type="text/javascript";e.async=!0;e.src=("https:"===document.location.protocol?"https://":"http://")+"cdn.segment.com/analytics.js/v1/"+t+"/analytics.min.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n)};analytics.SNIPPET_VERSION="3.1.0";
analytics.load("8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA");
analytics.page();
}}();

analytics.ready(function () {
    ga('require', 'linker');
    ga('linker:autoLink', ['scrapinghub.com', 'crawlera.com']);
});
</script>



<div id="rtd-izgf9gcx"></div></body></html>