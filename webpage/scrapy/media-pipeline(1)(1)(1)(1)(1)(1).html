<!DOCTYPE html><!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]--><!--[if gt IE 8]><!--><html xmlns="http://www.w3.org/1999/xhtml" class=" js flexbox canvas canvastext webgl no-touch geolocation postmessage websqldatabase indexeddb hashchange history draganddrop websockets rgba hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients cssreflections csstransforms csstransforms3d csstransitions fontface generatedcontent video audio localstorage sessionstorage webworkers applicationcache svg inlinesvg smil svgclippaths" lang="en" style=""><!--<![endif]--><head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Downloading and processing files and images — Scrapy 1.1.3 documentation</title>
  

  
  

  

  
  
    

  

  
  

  
    <link rel="stylesheet" href="https://media.readthedocs.org/css/sphinx_rtd_theme.css" type="text/css" />
  

  
        <link rel="index" title="Index" href="../genindex.html" />
        <link rel="search" title="Search" href="../search.html" />
    <link rel="top" title="Scrapy 1.1.3 documentation" href="../index.html" />
        <link rel="next" title="Ubuntu packages" href="ubuntu.html" />
        <link rel="prev" title="Debugging memory leaks" href="leaks.html" /> 

  
  <script type="text/javascript" async="" src="https://www.google-analytics.com/plugins/ua/linkid.js"></script><script type="text/javascript" async="" src="https://www.google-analytics.com/analytics.js"></script><script type="text/javascript" async="" src="https://cdn.segment.com/analytics.js/v1/8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA/analytics.min.js"></script><script type="text/javascript" async="" src="https://ssl.google-analytics.com/ga.js"></script><script src="../_static/js/modernizr.min.js"></script>


<!-- RTD Extra Head -->

<!-- 
Always link to the latest version, as canonical.
http://docs.readthedocs.org/en/latest/canonical.html
-->
<link rel="canonical" href="http://doc.scrapy.org/en/latest/topics/media-pipeline.html" />

<link rel="stylesheet" href="https://media.readthedocs.org/css/readthedocs-doc-embed.css" type="text/css" />

<script type="text/javascript" src="../_static/readthedocs-data.js"></script>

<!-- Add page-specific data, which must exist in the page js, not global -->
<script type="text/javascript">
READTHEDOCS_DATA['page'] = 'topics/media-pipeline' 		
READTHEDOCS_DATA['source_suffix'] = '.rst'
</script>

<script type="text/javascript" src="../_static/readthedocs-dynamic-include.js"></script>

<!-- end RTD <extrahead> --></head>

<body class="wy-body-for-nav" role="document" style="">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Scrapy
          

          
          </a>

          
            
            
            
              <div class="version">
                1.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">First steps</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/overview.html">Scrapy at a glance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/install.html">Installation guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/tutorial.html">Scrapy Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/examples.html">Examples</a></li>
</ul>
<p class="caption"><span class="caption-text">Basic concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="commands.html">Command line tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="spiders.html">Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="selectors.html">Selectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="items.html">Items</a></li>
<li class="toctree-l1"><a class="reference internal" href="loaders.html">Item Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="shell.html">Scrapy shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="item-pipeline.html">Item Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="feed-exports.html">Feed exports</a></li>
<li class="toctree-l1"><a class="reference internal" href="request-response.html">Requests and Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="link-extractors.html">Link Extractors</a></li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">Exceptions</a></li>
</ul>
<p class="caption"><span class="caption-text">Built-in services</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="stats.html">Stats Collection</a></li>
<li class="toctree-l1"><a class="reference internal" href="email.html">Sending e-mail</a></li>
<li class="toctree-l1"><a class="reference internal" href="telnetconsole.html">Telnet Console</a></li>
<li class="toctree-l1"><a class="reference internal" href="webservice.html">Web Service</a></li>
</ul>
<p class="caption"><span class="caption-text">Solving specific problems</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="debug.html">Debugging Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="contracts.html">Spiders Contracts</a></li>
<li class="toctree-l1"><a class="reference internal" href="practices.html">Common Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="broad-crawls.html">Broad Crawls</a></li>
<li class="toctree-l1"><a class="reference internal" href="firefox.html">Using Firefox for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="firebug.html">Using Firebug for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="leaks.html">Debugging memory leaks</a></li>
<li class="toctree-l1 current"><a class="reference internal current" href="#"><span class="toctree-expand"></span>Downloading and processing files and images</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#using-the-files-pipeline">Using the Files Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-the-images-pipeline">Using the Images Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="#enabling-your-media-pipeline">Enabling your Media Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="#supported-storage"><span class="toctree-expand"></span>Supported Storage</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#file-system-storage">File system storage</a></li>
<li class="toctree-l3"><a class="reference internal" href="#amazon-s3-storage">Amazon S3 storage</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#usage-example">Usage example</a></li>
<li class="toctree-l2"><a class="reference internal" href="#additional-features"><span class="toctree-expand"></span>Additional features</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#file-expiration">File expiration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#thumbnail-generation-for-images">Thumbnail generation for images</a></li>
<li class="toctree-l3"><a class="reference internal" href="#filtering-out-small-images">Filtering out small images</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-scrapy.pipelines.files">Extending the Media Pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="#custom-images-pipeline-example">Custom Images pipeline example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ubuntu.html">Ubuntu packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy.html">Deploying Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="autothrottle.html">AutoThrottle extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="jobs.html">Jobs: pausing and resuming crawls</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending Scrapy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="downloader-middleware.html">Downloader Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="spider-middleware.html">Spider Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="extensions.html">Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">Core API</a></li>
<li class="toctree-l1"><a class="reference internal" href="signals.html">Signals</a></li>
<li class="toctree-l1"><a class="reference internal" href="exporters.html">Item Exporters</a></li>
</ul>
<p class="caption"><span class="caption-text">All the rest</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html">Versioning and API Stability</a></li>
</ul>

            
          
        </div>
      <div id="rtd-go8t365v" class="ethical-rtd ethical-dark-theme"></div></div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Scrapy</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> »</li>
        
      <li>Downloading and processing files and images</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/scrapy/scrapy/blob/1.1/docs/topics/media-pipeline.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr />
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article"><div class="admonition warning"> <p class="first admonition-title">Note</p> <p class="last"> You are not reading the most recent version of this documentation. <a href="/en/1.6/topics/media-pipeline.html">1.6</a> is the latest version available.</p></div>
           <div itemprop="articleBody">
            
  <div class="section" id="downloading-and-processing-files-and-images">
<span id="topics-media-pipeline"></span><h1>Downloading and processing files and images<a class="headerlink" href="#downloading-and-processing-files-and-images" title="Permalink to this headline">¶</a></h1>
<p>Scrapy provides reusable <a class="reference internal" href="item-pipeline.html"><span class="doc">item pipelines</span></a> for
downloading files attached to a particular item (for example, when you scrape
products and also want to download their images locally). These pipelines share
a bit of functionality and structure (we refer to them as media pipelines), but
typically you’ll either use the Files Pipeline or the Images Pipeline.</p>
<p>Both pipelines implement these features:</p>
<ul class="simple">
<li>Avoid re-downloading media that was downloaded recently</li>
<li>Specifying where to store the media (filesystem directory, Amazon S3 bucket)</li>
</ul>
<p>The Images Pipeline has a few extra functions for processing images:</p>
<ul class="simple">
<li>Convert all downloaded images to a common format (JPG) and mode (RGB)</li>
<li>Thumbnail generation</li>
<li>Check images width/height to make sure they meet a minimum constraint</li>
</ul>
<p>The pipelines also keep an internal queue of those media URLs which are currently
being scheduled for download, and connect those responses that arrive containing
the same media to that queue. This avoids downloading the same media more than
once when it’s shared by several items.</p>
<div class="section" id="using-the-files-pipeline">
<h2>Using the Files Pipeline<a class="headerlink" href="#using-the-files-pipeline" title="Permalink to this headline">¶</a></h2>
<p>The typical workflow, when using the <code class="xref py py-class docutils literal"><span class="pre">FilesPipeline</span></code> goes like
this:</p>
<ol class="arabic simple">
<li>In a Spider, you scrape an item and put the URLs of the desired into a
<code class="docutils literal"><span class="pre">file_urls</span></code> field.</li>
<li>The item is returned from the spider and goes to the item pipeline.</li>
<li>When the item reaches the <code class="xref py py-class docutils literal"><span class="pre">FilesPipeline</span></code>, the URLs in the
<code class="docutils literal"><span class="pre">file_urls</span></code> field are scheduled for download using the standard
Scrapy scheduler and downloader (which means the scheduler and downloader
middlewares are reused), but with a higher priority, processing them before other
pages are scraped. The item remains “locked” at that particular pipeline stage
until the files have finish downloading (or fail for some reason).</li>
<li>When the files are downloaded, another field (<code class="docutils literal"><span class="pre">files</span></code>) will be populated
with the results. This field will contain a list of dicts with information
about the downloaded files, such as the downloaded path, the original
scraped url (taken from the <code class="docutils literal"><span class="pre">file_urls</span></code> field) , and the file checksum.
The files in the list of the <code class="docutils literal"><span class="pre">files</span></code> field will retain the same order of
the original <code class="docutils literal"><span class="pre">file_urls</span></code> field. If some file failed downloading, an
error will be logged and the file won’t be present in the <code class="docutils literal"><span class="pre">files</span></code> field.</li>
</ol>
</div>
<div class="section" id="using-the-images-pipeline">
<h2>Using the Images Pipeline<a class="headerlink" href="#using-the-images-pipeline" title="Permalink to this headline">¶</a></h2>
<p>Using the <a class="reference internal" href="#scrapy.pipelines.images.ImagesPipeline" title="scrapy.pipelines.images.ImagesPipeline"><code class="xref py py-class docutils literal"><span class="pre">ImagesPipeline</span></code></a> is a lot like using the <code class="xref py py-class docutils literal"><span class="pre">FilesPipeline</span></code>,
except the default field names used are different: you use <code class="docutils literal"><span class="pre">image_urls</span></code> for
the image URLs of an item and it will populate an <code class="docutils literal"><span class="pre">images</span></code> field for the information
about the downloaded images.</p>
<p>The advantage of using the <a class="reference internal" href="#scrapy.pipelines.images.ImagesPipeline" title="scrapy.pipelines.images.ImagesPipeline"><code class="xref py py-class docutils literal"><span class="pre">ImagesPipeline</span></code></a> for image files is that you
can configure some extra functions like generating thumbnails and filtering
the images based on their size.</p>
<p>The Images Pipeline uses <a class="reference external" href="https://github.com/python-pillow/Pillow">Pillow</a> for thumbnailing and normalizing images to
JPEG/RGB format, so you need to install this library in order to use it.
<a class="reference external" href="http://www.pythonware.com/products/pil/">Python Imaging Library</a> (PIL) should also work in most cases, but it is known
to cause troubles in some setups, so we recommend to use <a class="reference external" href="https://github.com/python-pillow/Pillow">Pillow</a> instead of
PIL.</p>
</div>
<div class="section" id="enabling-your-media-pipeline">
<span id="topics-media-pipeline-enabling"></span><h2>Enabling your Media Pipeline<a class="headerlink" href="#enabling-your-media-pipeline" title="Permalink to this headline">¶</a></h2>
<span class="target" id="std:setting-IMAGES_STORE"></span><p id="std:setting-FILES_STORE">To enable your media pipeline you must first add it to your project
<a class="reference internal" href="settings.html#std:setting-ITEM_PIPELINES"><code class="xref std std-setting docutils literal"><span class="pre">ITEM_PIPELINES</span></code></a> setting.</p>
<p>For Images Pipeline, use:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'scrapy.pipelines.images.ImagesPipeline'</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
</pre></div>
</div>
<p>For Files Pipeline, use:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'scrapy.pipelines.files.FilesPipeline'</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">You can also use both the Files and Images Pipeline at the same time.</p>
</div>
<p>Then, configure the target storage setting to a valid value that will be used
for storing the downloaded images. Otherwise the pipeline will remain disabled,
even if you include it in the <a class="reference internal" href="settings.html#std:setting-ITEM_PIPELINES"><code class="xref std std-setting docutils literal"><span class="pre">ITEM_PIPELINES</span></code></a> setting.</p>
<p>For the Files Pipeline, set the <a class="reference internal" href="#std:setting-FILES_STORE"><code class="xref std std-setting docutils literal"><span class="pre">FILES_STORE</span></code></a> setting:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">FILES_STORE</span> <span class="o">=</span> <span class="s1">'/path/to/valid/dir'</span>
</pre></div>
</div>
<p>For the Images Pipeline, set the <a class="reference internal" href="#std:setting-IMAGES_STORE"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_STORE</span></code></a> setting:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">IMAGES_STORE</span> <span class="o">=</span> <span class="s1">'/path/to/valid/dir'</span>
</pre></div>
</div>
</div>
<div class="section" id="supported-storage">
<h2>Supported Storage<a class="headerlink" href="#supported-storage" title="Permalink to this headline">¶</a></h2>
<p>File system is currently the only officially supported storage, but there is
also support for storing files in <a class="reference external" href="https://aws.amazon.com/s3/">Amazon S3</a>.</p>
<div class="section" id="file-system-storage">
<h3>File system storage<a class="headerlink" href="#file-system-storage" title="Permalink to this headline">¶</a></h3>
<p>The files are stored using a <a class="reference external" href="https://en.wikipedia.org/wiki/SHA_hash_functions">SHA1 hash</a> of their URLs for the file names.</p>
<p>For example, the following image URL:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">example</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">image</span><span class="o">.</span><span class="n">jpg</span>
</pre></div>
</div>
<p>Whose <cite>SHA1 hash</cite> is:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">3</span><span class="n">afec3b4765f8f0a07b78f98c07b83f013567a0a</span>
</pre></div>
</div>
<p>Will be downloaded and stored in the following file:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">IMAGES_STORE</span><span class="o">&gt;/</span><span class="n">full</span><span class="o">/</span><span class="mi">3</span><span class="n">afec3b4765f8f0a07b78f98c07b83f013567a0a</span><span class="o">.</span><span class="n">jpg</span>
</pre></div>
</div>
<p>Where:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">&lt;IMAGES_STORE&gt;</span></code> is the directory defined in <a class="reference internal" href="#std:setting-IMAGES_STORE"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_STORE</span></code></a> setting
for the Images Pipeline.</li>
<li><code class="docutils literal"><span class="pre">full</span></code> is a sub-directory to separate full images from thumbnails (if
used). For more info see <a class="reference internal" href="#topics-images-thumbnails"><span class="std std-ref">Thumbnail generation for images</span></a>.</li>
</ul>
</div>
<div class="section" id="amazon-s3-storage">
<h3>Amazon S3 storage<a class="headerlink" href="#amazon-s3-storage" title="Permalink to this headline">¶</a></h3>
<span class="target" id="std:setting-FILES_STORE_S3_ACL"></span><p id="std:setting-IMAGES_STORE_S3_ACL"><a class="reference internal" href="#std:setting-FILES_STORE"><code class="xref std std-setting docutils literal"><span class="pre">FILES_STORE</span></code></a> and <a class="reference internal" href="#std:setting-IMAGES_STORE"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_STORE</span></code></a> can represent an Amazon S3
bucket. Scrapy will automatically upload the files to the bucket.</p>
<p>For example, this is a valid <a class="reference internal" href="#std:setting-IMAGES_STORE"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_STORE</span></code></a> value:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">IMAGES_STORE</span> <span class="o">=</span> <span class="s1">'s3://bucket/images'</span>
</pre></div>
</div>
<p>You can modify the Access Control List (ACL) policy used for the stored files,
which is defined by the <a class="reference internal" href="#std:setting-FILES_STORE_S3_ACL"><code class="xref std std-setting docutils literal"><span class="pre">FILES_STORE_S3_ACL</span></code></a> and
<a class="reference internal" href="#std:setting-IMAGES_STORE_S3_ACL"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_STORE_S3_ACL</span></code></a> settings. By default, the ACL is set to
<code class="docutils literal"><span class="pre">private</span></code>. To make the files publicly available use the <code class="docutils literal"><span class="pre">public-read</span></code>
policy:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">IMAGES_STORE_S3_ACL</span> <span class="o">=</span> <span class="s1">'public-read'</span>
</pre></div>
</div>
<p>For more information, see <a class="reference external" href="http://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl">canned ACLs</a> in the Amazon S3 Developer Guide.</p>
</div>
</div>
<div class="section" id="usage-example">
<h2>Usage example<a class="headerlink" href="#usage-example" title="Permalink to this headline">¶</a></h2>
<span class="target" id="std:setting-FILES_URLS_FIELD"></span><span class="target" id="std:setting-FILES_RESULT_FIELD"></span><span class="target" id="std:setting-IMAGES_URLS_FIELD"></span><p id="std:setting-IMAGES_RESULT_FIELD">In order to use a media pipeline first, <a class="reference internal" href="#topics-media-pipeline-enabling"><span class="std std-ref">enable it</span></a>.</p>
<p>Then, if a spider returns a dict with the URLs key (<code class="docutils literal"><span class="pre">file_urls</span></code> or
<code class="docutils literal"><span class="pre">image_urls</span></code>, for the Files or Images Pipeline respectively), the pipeline will
put the results under respective key (<code class="docutils literal"><span class="pre">files</span></code> or <code class="docutils literal"><span class="pre">images</span></code>).</p>
<p>If you prefer to use <a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><code class="xref py py-class docutils literal"><span class="pre">Item</span></code></a>, then define a custom item with the
necessary fields, like in this example for Images Pipeline:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">MyItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>

    <span class="c1"># ... other item fields ...</span>
    <span class="n">image_urls</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</pre></div>
</div>
<p>If you want to use another field name for the URLs key or for the results key,
it is also possible to override it.</p>
<p>For the Files Pipeline, set <a class="reference internal" href="#std:setting-FILES_URLS_FIELD"><code class="xref std std-setting docutils literal"><span class="pre">FILES_URLS_FIELD</span></code></a> and/or
<a class="reference internal" href="#std:setting-FILES_RESULT_FIELD"><code class="xref std std-setting docutils literal"><span class="pre">FILES_RESULT_FIELD</span></code></a> settings:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">FILES_URLS_FIELD</span> <span class="o">=</span> <span class="s1">'field_name_for_your_files_urls'</span>
<span class="n">FILES_RESULT_FIELD</span> <span class="o">=</span> <span class="s1">'field_name_for_your_processed_files'</span>
</pre></div>
</div>
<p>For the Images Pipeline, set <a class="reference internal" href="#std:setting-IMAGES_URLS_FIELD"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_URLS_FIELD</span></code></a> and/or
<a class="reference internal" href="#std:setting-IMAGES_RESULT_FIELD"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_RESULT_FIELD</span></code></a> settings:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">IMAGES_URLS_FIELD</span> <span class="o">=</span> <span class="s1">'field_name_for_your_images_urls'</span>
<span class="n">IMAGES_RESULT_FIELD</span> <span class="o">=</span> <span class="s1">'field_name_for_your_processed_images'</span>
</pre></div>
</div>
<p>If you need something more complex and want to override the custom pipeline
behaviour, see <a class="reference internal" href="#topics-media-pipeline-override"><span class="std std-ref">Extending the Media Pipelines</span></a>.</p>
<p>If you have multiple image pipelines inheriting from ImagePipeline and you want
to have different settings in different pipelines you can set setting keys
preceded with uppercase name of your pipeline class. E.g. if your pipeline is
called MyPipeline and you want to have custom IMAGES_URLS_FIELD you define
setting MYPIPELINE_IMAGES_URLS_FIELD and your custom settings will be used.</p>
</div>
<div class="section" id="additional-features">
<h2>Additional features<a class="headerlink" href="#additional-features" title="Permalink to this headline">¶</a></h2>
<div class="section" id="file-expiration">
<h3>File expiration<a class="headerlink" href="#file-expiration" title="Permalink to this headline">¶</a></h3>
<span class="target" id="std:setting-IMAGES_EXPIRES"></span><p id="std:setting-FILES_EXPIRES">The Image Pipeline avoids downloading files that were downloaded recently. To
adjust this retention delay use the <a class="reference internal" href="#std:setting-FILES_EXPIRES"><code class="xref std std-setting docutils literal"><span class="pre">FILES_EXPIRES</span></code></a> setting (or
<a class="reference internal" href="#std:setting-IMAGES_EXPIRES"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_EXPIRES</span></code></a>, in case of Images Pipeline), which
specifies the delay in number of days:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="c1"># 120 days of delay for files expiration</span>
<span class="n">FILES_EXPIRES</span> <span class="o">=</span> <span class="mi">120</span>

<span class="c1"># 30 days of delay for images expiration</span>
<span class="n">IMAGES_EXPIRES</span> <span class="o">=</span> <span class="mi">30</span>
</pre></div>
</div>
<p>The default value for both settings is 90 days.</p>
<p>If you have pipeline that subclasses FilesPipeline and you’d like to have
different setting for it you can set setting keys preceded by uppercase
class name. E.g. given pipeline class called MyPipeline you can set setting key:</p>
<blockquote>
<div>MYPIPELINE_FILES_EXPIRES = 180</div></blockquote>
<p>and pipeline class MyPipeline will have expiration time set to 180.</p>
</div>
<div class="section" id="thumbnail-generation-for-images">
<span id="topics-images-thumbnails"></span><h3>Thumbnail generation for images<a class="headerlink" href="#thumbnail-generation-for-images" title="Permalink to this headline">¶</a></h3>
<p>The Images Pipeline can automatically create thumbnails of the downloaded
images.</p>
<p id="std:setting-IMAGES_THUMBS">In order use this feature, you must set <a class="reference internal" href="#std:setting-IMAGES_THUMBS"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_THUMBS</span></code></a> to a dictionary
where the keys are the thumbnail names and the values are their dimensions.</p>
<p>For example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">IMAGES_THUMBS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'small'</span><span class="p">:</span> <span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
    <span class="s1">'big'</span><span class="p">:</span> <span class="p">(</span><span class="mi">270</span><span class="p">,</span> <span class="mi">270</span><span class="p">),</span>
<span class="p">}</span>
</pre></div>
</div>
<p>When you use this feature, the Images Pipeline will create thumbnails of the
each specified size with this format:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">IMAGES_STORE</span><span class="o">&gt;/</span><span class="n">thumbs</span><span class="o">/&lt;</span><span class="n">size_name</span><span class="o">&gt;/&lt;</span><span class="n">image_id</span><span class="o">&gt;.</span><span class="n">jpg</span>
</pre></div>
</div>
<p>Where:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">&lt;size_name&gt;</span></code> is the one specified in the <a class="reference internal" href="#std:setting-IMAGES_THUMBS"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_THUMBS</span></code></a>
dictionary keys (<code class="docutils literal"><span class="pre">small</span></code>, <code class="docutils literal"><span class="pre">big</span></code>, etc)</li>
<li><code class="docutils literal"><span class="pre">&lt;image_id&gt;</span></code> is the <a class="reference external" href="https://en.wikipedia.org/wiki/SHA_hash_functions">SHA1 hash</a> of the image url</li>
</ul>
<p>Example of image files stored using <code class="docutils literal"><span class="pre">small</span></code> and <code class="docutils literal"><span class="pre">big</span></code> thumbnail names:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">IMAGES_STORE</span><span class="o">&gt;/</span><span class="n">full</span><span class="o">/</span><span class="mi">63</span><span class="n">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class="o">.</span><span class="n">jpg</span>
<span class="o">&lt;</span><span class="n">IMAGES_STORE</span><span class="o">&gt;/</span><span class="n">thumbs</span><span class="o">/</span><span class="n">small</span><span class="o">/</span><span class="mi">63</span><span class="n">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class="o">.</span><span class="n">jpg</span>
<span class="o">&lt;</span><span class="n">IMAGES_STORE</span><span class="o">&gt;/</span><span class="n">thumbs</span><span class="o">/</span><span class="n">big</span><span class="o">/</span><span class="mi">63</span><span class="n">bbfea82b8880ed33cdb762aa11fab722a90a24</span><span class="o">.</span><span class="n">jpg</span>
</pre></div>
</div>
<p>The first one is the full image, as downloaded from the site.</p>
</div>
<div class="section" id="filtering-out-small-images">
<h3>Filtering out small images<a class="headerlink" href="#filtering-out-small-images" title="Permalink to this headline">¶</a></h3>
<span class="target" id="std:setting-IMAGES_MIN_HEIGHT"></span><p id="std:setting-IMAGES_MIN_WIDTH">When using the Images Pipeline, you can drop images which are too small, by
specifying the minimum allowed size in the <a class="reference internal" href="#std:setting-IMAGES_MIN_HEIGHT"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_MIN_HEIGHT</span></code></a> and
<a class="reference internal" href="#std:setting-IMAGES_MIN_WIDTH"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_MIN_WIDTH</span></code></a> settings.</p>
<p>For example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">IMAGES_MIN_HEIGHT</span> <span class="o">=</span> <span class="mi">110</span>
<span class="n">IMAGES_MIN_WIDTH</span> <span class="o">=</span> <span class="mi">110</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The size constraints don’t affect thumbnail generation at all.</p>
</div>
<p>It is possible to set just one size constraint or both. When setting both of
them, only images that satisfy both minimum sizes will be saved. For the
above example, images of sizes (105 x 105) or (105 x 200) or (200 x 105) will
all be dropped because at least one dimension is shorter than the constraint.</p>
<p>By default, there are no size constraints, so all images are processed.</p>
</div>
</div>
<div class="section" id="module-scrapy.pipelines.files">
<span id="extending-the-media-pipelines"></span><span id="topics-media-pipeline-override"></span><h2>Extending the Media Pipelines<a class="headerlink" href="#module-scrapy.pipelines.files" title="Permalink to this headline">¶</a></h2>
<p>See here the methods that you can override in your custom Files Pipeline:</p>
<dl class="class">
<dt id="scrapy.pipelines.files.FilesPipeline">
<em class="property">class </em><code class="descclassname">scrapy.pipelines.files.</code><code class="descname">FilesPipeline</code><a class="headerlink" href="#scrapy.pipelines.files.FilesPipeline" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="scrapy.pipelines.files.FilesPipeline.get_media_requests">
<code class="descname">get_media_requests</code><span class="sig-paren">(</span><em>item</em>, <em>info</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.pipelines.files.FilesPipeline.get_media_requests" title="Permalink to this definition">¶</a></dt>
<dd><p>As seen on the workflow, the pipeline will get the URLs of the images to
download from the item. In order to do this, you can override the
<a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.get_media_requests" title="scrapy.pipelines.files.FilesPipeline.get_media_requests"><code class="xref py py-meth docutils literal"><span class="pre">get_media_requests()</span></code></a> method and return a Request for each
file URL:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_media_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">info</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">file_url</span> <span class="ow">in</span> <span class="n">item</span><span class="p">[</span><span class="s1">'file_urls'</span><span class="p">]:</span>
        <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">file_url</span><span class="p">)</span>
</pre></div>
</div>
<p>Those requests will be processed by the pipeline and, when they have finished
downloading, the results will be sent to the
<a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.item_completed" title="scrapy.pipelines.files.FilesPipeline.item_completed"><code class="xref py py-meth docutils literal"><span class="pre">item_completed()</span></code></a> method, as a list of 2-element tuples.
Each tuple will contain <code class="docutils literal"><span class="pre">(success,</span> <span class="pre">file_info_or_error)</span></code> where:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">success</span></code> is a boolean which is <code class="docutils literal"><span class="pre">True</span></code> if the image was downloaded
successfully or <code class="docutils literal"><span class="pre">False</span></code> if it failed for some reason</li>
<li><code class="docutils literal"><span class="pre">file_info_or_error</span></code> is a dict containing the following keys (if success
is <code class="docutils literal"><span class="pre">True</span></code>) or a <a class="reference external" href="https://twistedmatrix.com/documents/current/api/twisted.python.failure.Failure.html">Twisted Failure</a> if there was a problem.<ul>
<li><code class="docutils literal"><span class="pre">url</span></code> - the url where the file was downloaded from. This is the url of
the request returned from the <a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.get_media_requests" title="scrapy.pipelines.files.FilesPipeline.get_media_requests"><code class="xref py py-meth docutils literal"><span class="pre">get_media_requests()</span></code></a>
method.</li>
<li><code class="docutils literal"><span class="pre">path</span></code> - the path (relative to <a class="reference internal" href="#std:setting-FILES_STORE"><code class="xref std std-setting docutils literal"><span class="pre">FILES_STORE</span></code></a>) where the file
was stored</li>
<li><code class="docutils literal"><span class="pre">checksum</span></code> - a <a class="reference external" href="https://en.wikipedia.org/wiki/MD5">MD5 hash</a> of the image contents</li>
</ul>
</li>
</ul>
<p>The list of tuples received by <a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.item_completed" title="scrapy.pipelines.files.FilesPipeline.item_completed"><code class="xref py py-meth docutils literal"><span class="pre">item_completed()</span></code></a> is
guaranteed to retain the same order of the requests returned from the
<a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.get_media_requests" title="scrapy.pipelines.files.FilesPipeline.get_media_requests"><code class="xref py py-meth docutils literal"><span class="pre">get_media_requests()</span></code></a> method.</p>
<p>Here’s a typical value of the <code class="docutils literal"><span class="pre">results</span></code> argument:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[(</span><span class="kc">True</span><span class="p">,</span>
  <span class="p">{</span><span class="s1">'checksum'</span><span class="p">:</span> <span class="s1">'2b00042f7481c7b056c4b410d28f33cf'</span><span class="p">,</span>
   <span class="s1">'path'</span><span class="p">:</span> <span class="s1">'full/0a79c461a4062ac383dc4fade7bc09f1384a3910.jpg'</span><span class="p">,</span>
   <span class="s1">'url'</span><span class="p">:</span> <span class="s1">'http://www.example.com/files/product1.pdf'</span><span class="p">}),</span>
 <span class="p">(</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">Failure</span><span class="p">(</span><span class="o">...</span><span class="p">))]</span>
</pre></div>
</div>
<p>By default the <a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.get_media_requests" title="scrapy.pipelines.files.FilesPipeline.get_media_requests"><code class="xref py py-meth docutils literal"><span class="pre">get_media_requests()</span></code></a> method returns <code class="docutils literal"><span class="pre">None</span></code> which
means there are no files to download for the item.</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.pipelines.files.FilesPipeline.item_completed">
<code class="descname">item_completed</code><span class="sig-paren">(</span><em>results</em>, <em>items</em>, <em>info</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.pipelines.files.FilesPipeline.item_completed" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.item_completed" title="scrapy.pipelines.files.FilesPipeline.item_completed"><code class="xref py py-meth docutils literal"><span class="pre">FilesPipeline.item_completed()</span></code></a> method called when all file
requests for a single item have completed (either finished downloading, or
failed for some reason).</p>
<p>The <a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.item_completed" title="scrapy.pipelines.files.FilesPipeline.item_completed"><code class="xref py py-meth docutils literal"><span class="pre">item_completed()</span></code></a> method must return the
output that will be sent to subsequent item pipeline stages, so you must
return (or drop) the item, as you would in any pipeline.</p>
<p>Here is an example of the <a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.item_completed" title="scrapy.pipelines.files.FilesPipeline.item_completed"><code class="xref py py-meth docutils literal"><span class="pre">item_completed()</span></code></a> method where we
store the downloaded file paths (passed in results) in the <code class="docutils literal"><span class="pre">file_paths</span></code>
item field, and we drop the item if it doesn’t contain any files:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scrapy.exceptions</span> <span class="k">import</span> <span class="n">DropItem</span>

<span class="k">def</span> <span class="nf">item_completed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">info</span><span class="p">):</span>
    <span class="n">file_paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="s1">'path'</span><span class="p">]</span> <span class="k">for</span> <span class="n">ok</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">results</span> <span class="k">if</span> <span class="n">ok</span><span class="p">]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">file_paths</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DropItem</span><span class="p">(</span><span class="s2">"Item contains no files"</span><span class="p">)</span>
    <span class="n">item</span><span class="p">[</span><span class="s1">'file_paths'</span><span class="p">]</span> <span class="o">=</span> <span class="n">file_paths</span>
    <span class="k">return</span> <span class="n">item</span>
</pre></div>
</div>
<p>By default, the <a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.item_completed" title="scrapy.pipelines.files.FilesPipeline.item_completed"><code class="xref py py-meth docutils literal"><span class="pre">item_completed()</span></code></a> method returns the item.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-scrapy.pipelines.images"></span><p>See here the methods that you can override in your custom Images Pipeline:</p>
<dl class="class">
<dt id="scrapy.pipelines.images.ImagesPipeline">
<em class="property">class </em><code class="descclassname">scrapy.pipelines.images.</code><code class="descname">ImagesPipeline</code><a class="headerlink" href="#scrapy.pipelines.images.ImagesPipeline" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div>The <a class="reference internal" href="#scrapy.pipelines.images.ImagesPipeline" title="scrapy.pipelines.images.ImagesPipeline"><code class="xref py py-class docutils literal"><span class="pre">ImagesPipeline</span></code></a> is an extension of the <code class="xref py py-class docutils literal"><span class="pre">FilesPipeline</span></code>,
customizing the field names and adding custom behavior for images.</div></blockquote>
<dl class="method">
<dt id="scrapy.pipelines.images.ImagesPipeline.get_media_requests">
<code class="descname">get_media_requests</code><span class="sig-paren">(</span><em>item</em>, <em>info</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.pipelines.images.ImagesPipeline.get_media_requests" title="Permalink to this definition">¶</a></dt>
<dd><p>Works the same way as <code class="xref py py-meth docutils literal"><span class="pre">FilesPipeline.get_media_requests()</span></code> method,
but using a different field name for image urls.</p>
<p>Must return a Request for each image URL.</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.pipelines.images.ImagesPipeline.item_completed">
<code class="descname">item_completed</code><span class="sig-paren">(</span><em>results</em>, <em>items</em>, <em>info</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.pipelines.images.ImagesPipeline.item_completed" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference internal" href="#scrapy.pipelines.images.ImagesPipeline.item_completed" title="scrapy.pipelines.images.ImagesPipeline.item_completed"><code class="xref py py-meth docutils literal"><span class="pre">ImagesPipeline.item_completed()</span></code></a> method is called when all image
requests for a single item have completed (either finished downloading, or
failed for some reason).</p>
<p>Works the same way as <code class="xref py py-meth docutils literal"><span class="pre">FilesPipeline.item_completed()</span></code> method,
but using a different field names for storing image downloading results.</p>
<p>By default, the <a class="reference internal" href="#scrapy.pipelines.images.ImagesPipeline.item_completed" title="scrapy.pipelines.images.ImagesPipeline.item_completed"><code class="xref py py-meth docutils literal"><span class="pre">item_completed()</span></code></a> method returns the item.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="custom-images-pipeline-example">
<h2>Custom Images pipeline example<a class="headerlink" href="#custom-images-pipeline-example" title="Permalink to this headline">¶</a></h2>
<p>Here is a full example of the Images Pipeline whose methods are examplified
above:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">from</span> <span class="nn">scrapy.pipelines.images</span> <span class="k">import</span> <span class="n">ImagesPipeline</span>
<span class="kn">from</span> <span class="nn">scrapy.exceptions</span> <span class="k">import</span> <span class="n">DropItem</span>

<span class="k">class</span> <span class="nc">MyImagesPipeline</span><span class="p">(</span><span class="n">ImagesPipeline</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">get_media_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">info</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">image_url</span> <span class="ow">in</span> <span class="n">item</span><span class="p">[</span><span class="s1">'image_urls'</span><span class="p">]:</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">image_url</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">item_completed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">info</span><span class="p">):</span>
        <span class="n">image_paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="s1">'path'</span><span class="p">]</span> <span class="k">for</span> <span class="n">ok</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">results</span> <span class="k">if</span> <span class="n">ok</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">image_paths</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DropItem</span><span class="p">(</span><span class="s2">"Item contains no images"</span><span class="p">)</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">'image_paths'</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_paths</span>
        <span class="k">return</span> <span class="n">item</span>
</pre></div>
</div>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="ubuntu.html" class="btn btn-neutral float-right" title="Ubuntu packages" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="leaks.html" class="btn btn-neutral" title="Debugging memory leaks" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr /><div><div id="rtd-ae4iv4o5" class="ethical-rtd"></div></div>

  <div role="contentinfo">
    <p>
        © Copyright 2008-2016, Scrapy developers.
      
        <span class="commit">
          Revision <code>b9d22807</code>.
        </span>
      

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: 1.1
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions"><!-- Inserted RTD Footer -->
<div class="injected">

  

      
      
      
      <dl>
        <dt>Versions</dt>
        
        
        <dd><a href="https://docs.scrapy.org/en/latest/topics/media-pipeline.html">latest</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.6/topics/media-pipeline.html">1.6</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.5/topics/media-pipeline.html">1.5</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.4/topics/media-pipeline.html">1.4</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.3/topics/media-pipeline.html">1.3</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/1.2/topics/media-pipeline.html">1.2</a></dd>
        
        
         <strong> 
        <dd><a href="https://docs.scrapy.org/en/1.1/topics/media-pipeline.html">1.1</a></dd>
         </strong> 
        
        
        <dd><a href="https://docs.scrapy.org/en/1.0/topics/media-pipeline.html">1.0</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.24/topics/media-pipeline.html">0.24</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.22/topics/media-pipeline.html">0.22</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/0.20/topics/media-pipeline.html">0.20</a></dd>
        
        
        
        <dd><a href="https://docs.scrapy.org/en/master/topics/media-pipeline.html">master</a></dd>
        
        
      </dl>
      
      

      
      
      <dl>
        <dt>Downloads</dt>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/pdf/1.1/">PDF</a></dd>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/htmlzip/1.1/">HTML</a></dd>
        
        <dd><a href="//readthedocs.org/projects/scrapy/downloads/epub/1.1/">Epub</a></dd>
        
      </dl>
      
      

      
      <dl>
        <!-- These are kept as relative links for internal installs that are http -->
        <dt>On Read the Docs</dt>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/">Project Home</a>
        </dd>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/builds/">Builds</a>
        </dd>
        <dd>
          <a href="//readthedocs.org/projects/scrapy/downloads/">Downloads</a>
        </dd>
      </dl>
      

      

      
      <dl>
        <dt>On GitHub</dt>
        <dd>
          <a href="https://github.com/scrapy/scrapy/blob/1.1/docs/topics/media-pipeline.rst">View</a>
        </dd>
        
        <dd>
          <a href="https://github.com/scrapy/scrapy/edit/1.1/docs/topics/media-pipeline.rst">Edit</a>
        </dd>
        
      </dl>
      
      

      
      <dl>
        <dt>Search</dt>
        <dd>
          <div style="padding: 6px;">
            <form id="flyout-search-form" class="wy-form" target="_blank" action="//readthedocs.org/projects/scrapy/search/" method="get">
              <input type="text" name="q" placeholder="Search docs" />
              </form>
          </div>
        </dd>
      </dl>
      



      <hr />
      
        <small>
          <span>Hosted by <a href="https://readthedocs.org">Read the Docs</a></span>
          <span> · </span>
          <a href="https://docs.readthedocs.io/page/privacy-policy.html">Privacy Policy</a>
        </small>
      

      

</div>
</div>
  </div>



  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'1.1.3',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-2.0.3.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-migrate-1.2.1.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/underscore.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/doctools.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/readthedocs-doc-embed.js"></script>

  

  
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
 
<script type="text/javascript">
!function(){var analytics=window.analytics=window.analytics||[];if(!analytics.initialize)if(analytics.invoked)window.console&amp;&amp;console.error&amp;&amp;console.error("Segment snippet included twice.");else{analytics.invoked=!0;analytics.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","page","once","off","on"];analytics.factory=function(t){return function(){var e=Array.prototype.slice.call(arguments);e.unshift(t);analytics.push(e);return analytics}};for(var t=0;t&lt;analytics.methods.length;t++){var e=analytics.methods[t];analytics[e]=analytics.factory(e)}analytics.load=function(t){var e=document.createElement("script");e.type="text/javascript";e.async=!0;e.src=("https:"===document.location.protocol?"https://":"http://")+"cdn.segment.com/analytics.js/v1/"+t+"/analytics.min.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(e,n)};analytics.SNIPPET_VERSION="3.1.0";
analytics.load("8UDQfnf3cyFSTsM4YANnW5sXmgZVILbA");
analytics.page();
}}();

analytics.ready(function () {
    ga('require', 'linker');
    ga('linker:autoLink', ['scrapinghub.com', 'crawlera.com']);
});
</script>



<div id="rtd-n5ilz08b"><div class="ethical-fixedfooter"><div class="ethical-content"><div class="ethical-close"><a href="javascript:$('.ethical-fixedfooter').hide()" aria-label="Close Ad">×</a></div><img src="https://readthedocs.org/sustainability/view/548/Lyl8Y4gJsREb/" class="ethical-pixel" /><div><a href="https://readthedocs.org/sustainability/click/548/Lyl8Y4gJsREb/" rel="nofollow" target="_blank"><span class="ethical-text"></span></a><a href="https://readthedocs.org/sustainability/click/548/Lyl8Y4gJsREb/" rel="nofollow" target="_blank">Hiring Python devs? Read the Docs can help!</a><span class="ethical-callout"><small><em><a href="https://docs.readthedocs.io/en/latest/ethical-advertising.html" rel="nofollow" target="_blank">ads served ethically</a></em></small></span></div></div></div></div></body></html>